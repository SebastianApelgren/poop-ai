{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc1ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f7fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_confusion_matrix(cm):\n",
    "    \"\"\"Returns a string of a nicely formatted confusion matrix with indices and highlighted diagonal.\"\"\"\n",
    "    headers = [\"\"] + [f\"Pred {i}\" for i in range(len(cm[0]))]\n",
    "    table = []\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        formatted_row = []\n",
    "        for j, val in enumerate(row):\n",
    "            if i == j:\n",
    "                formatted_row.append(f\"*{val}*\")  # Highlight diagonal\n",
    "            else:\n",
    "                formatted_row.append(str(val))\n",
    "        table.append([f\"True {i}\"] + formatted_row)\n",
    "\n",
    "    return tabulate(table, headers=headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14f9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = []\n",
    "\n",
    "def log_and_store(*msgs, table_format=False, is_confmat=False):\n",
    "    \"\"\"\n",
    "    Logs plain messages or pretty-prints confusion matrices or tables.\n",
    "    \"\"\"\n",
    "    if is_confmat and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = format_confusion_matrix(msgs[0])\n",
    "    elif table_format and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = tabulate(msgs[0], tablefmt=\"grid\")\n",
    "    else:\n",
    "        msg = \" \".join(str(m) for m in msgs)\n",
    "\n",
    "    print(msg)\n",
    "    all_logs.append(msg)\n",
    "\n",
    "def get_logs():\n",
    "    \"\"\"\n",
    "    Returnerar en lista med alla loggade meddelanden.\n",
    "    \"\"\"\n",
    "    return all_logs\n",
    "\n",
    "def clear_logs():\n",
    "    \"\"\"\n",
    "    Tömmer loggen.\n",
    "    \"\"\"\n",
    "    all_logs.clear()\n",
    "\n",
    "def save_logs_to_file(filename):\n",
    "    \"\"\"\n",
    "    Sparar loggade meddelanden till en fil.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for log in all_logs:\n",
    "            f.write(log + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79638fe9",
   "metadata": {},
   "source": [
    "# Advanced Training Pipeline\n",
    "\n",
    "This notebook implements:\n",
    "1. Stronger and more varied augmentation, including class-specific oversampling.\n",
    "2. Model-level adjustments: gradual unfreezing, EfficientNet-B0/B3, label smoothing, focal loss/class-weighted loss.\n",
    "3. Training strategies: early stopping, checkpoint ensembles, and k-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../datasets/data-loose\"  # Update this path\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd323500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoolDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(class_path, fname), idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger and more varied augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.Lambda(lambda img: img.filter(ImageFilter.FIND_EDGES))], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "340ab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing Loss (CrossEntropy with label_smoothing)\n",
    "criterion_smooth = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FocalLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f3691ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\\n    # Load pretrained EfficientNet\\n    if backbone == 'efficientnet_b0':\\n        model = models.efficientnet_b0(pretrained=True)\\n    elif backbone == 'efficientnet_b3':\\n        model = models.efficientnet_b3(pretrained=True)\\n    elif backbone == 'mobilenet_v2':\\n        model = models.mobilenet_v2(pretrained=True)\\n    elif backbone == 'mobilenet_v3_small':\\n        model = models.mobilenet_v3_small(pretrained=True)\\n    else:\\n        raise ValueError('Invalid backbone')\\n\\n    # Replace classifier head\\n    in_features = model.classifier[1].in_features\\n    model.classifier = nn.Sequential(\\n        nn.Linear(in_features, 512),\\n        nn.ReLU(inplace=True),\\n        nn.Dropout(0.4),\\n        nn.Linear(512, num_classes)\\n    )\\n\\n    # Freeze layers if specified\\n    if freeze_until_layer:\\n        for name, param in model.named_parameters():\\n            param.requires_grad = False\\n            if name.startswith(freeze_until_layer):\\n                break\\n        # Unfreeze subsequent layers\\n        unfreeze = False\\n        for name, param in model.named_parameters():\\n            if unfreeze:\\n                param.requires_grad = True\\n            if name.startswith(freeze_until_layer):\\n                unfreeze = True\\n\\n    return model.to(DEVICE)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    # Load pretrained EfficientNet\n",
    "    if backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    # Replace classifier head\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Freeze layers if specified\n",
    "    if freeze_until_layer:\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                break\n",
    "        # Unfreeze subsequent layers\n",
    "        unfreeze = False\n",
    "        for name, param in model.named_parameters():\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                unfreeze = True\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c33c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    if backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        # freeze layers\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        # Replace final classifier\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb02600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return None, None, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84c606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx):\n",
    "\n",
    "    #patience = 3\n",
    "    #counter = 0\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) # for accuracy\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) # for loss\n",
    "\n",
    "    best_acc     = 0.0\n",
    "    best_loss    = float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ── One‐Cycle LR schedule ──────────────────────────────────────────────────\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=optimizer.param_groups[0]['lr'] * 10,  # e.g. 10× your base LR\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch = val_corrects / val_total\n",
    "        # step the one‐cycle scheduler each batch‐cycle (done at epoch‐end here)\n",
    "        scheduler.step()\n",
    "\n",
    "        # keep snapshot of best‐ever validation loss (for final restore)\n",
    "        if val_loss_epoch < best_loss:\n",
    "            best_loss    = val_loss_epoch\n",
    "            best_acc     = val_acc_epoch\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f\"Fold {fold_idx}, Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        #if val_acc_epoch > best_acc:\n",
    "        #    best_acc = val_acc_epoch\n",
    "        #   best_weights = model.state_dict().copy()\n",
    "        #   counter = 0\n",
    "        #else:\n",
    "        #    counter += 1\n",
    "        #    if counter >= patience:\n",
    "        #        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #       break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Final validation metrics\n",
    "    _, _, preds, labels = evaluate_model(model, val_loader)\n",
    "    log_and_store(\"\\nClassification Report for Fold {}:\".format(fold_idx))\n",
    "    log_and_store(classification_report(labels, preds, target_names=sorted(os.listdir(DATA_DIR))))\n",
    "\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a45e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ../data-pools/data-loose: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!find ../data-pools/data-loose -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a1e6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cf9c6",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c234e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(\n",
    "    data_dir,\n",
    "    backbone='mobilenet_v2',\n",
    "    freeze_until_layer=None,\n",
    "    criterion_fn=None,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    k_folds=3,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "\n",
    "    # Class weights for full dataset (optional, for balance insights)\n",
    "    all_labels_full = [label for _, label in full_dataset]\n",
    "    class_counts = np.bincount(all_labels_full)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights_full = [class_weights[label] for label in all_labels_full]\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    fold_models = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices), 1):\n",
    "        print(f\"\\n======= Fold {fold_idx} =======\")\n",
    "\n",
    "        # Subset + transforms\n",
    "        train_ds = torch.utils.data.Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "        val_ds   = torch.utils.data.Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "        # Weighted sampler\n",
    "        train_labels_fold = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "        class_sample_count_fold = np.array([train_labels_fold.count(i) for i in range(num_classes)])\n",
    "        print(f\"Class sample counts: {class_sample_count_fold}\")\n",
    "        class_weights_fold = 1.0 / class_sample_count_fold\n",
    "        sample_weights_fold = np.array([class_weights_fold[label] for label in train_labels_fold])\n",
    "        sample_weights_fold = torch.from_numpy(sample_weights_fold.astype(np.double))\n",
    "        sampler_fold = WeightedRandomSampler(sample_weights_fold, num_samples=len(sample_weights_fold), replacement=True)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler_fold)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(backbone=backbone, freeze_until_layer=freeze_until_layer)\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # Loss\n",
    "        criterion = criterion_fn if criterion_fn is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train\n",
    "        best_model, best_acc = train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx)\n",
    "        fold_models.append(best_model)\n",
    "        fold_accuracies.append(best_acc)\n",
    "\n",
    "        # Evaluate and log\n",
    "        best_model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = best_model(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(yb.numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        crpt = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Confusion Matrix ---\")\n",
    "        log_and_store(cm, is_confmat=True)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Classification Report ---\")\n",
    "        log_and_store(crpt)\n",
    "\n",
    "    log_and_store([\"\\nFold Models:\", [f\"Fold {i+1}\" for i in range(len(fold_models))]])\n",
    "    log_and_store([\"Fold Accuracies:\", fold_accuracies])\n",
    "    log_and_store([\"Mean Accuracy:\", np.mean(fold_accuracies)])\n",
    "\n",
    "    return fold_models, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_split(\n",
    "    data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "):\n",
    "    print(\"======= Single Split Training =======\")\n",
    "\n",
    "    # Full dataset\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    all_labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=val_split, random_state=seed, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Create datasets with transforms\n",
    "    train_ds = Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "    val_ds = Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "    # Weighted sampler for class imbalance\n",
    "    train_labels = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "    class_sample_counts = np.array([train_labels.count(i) for i in range(NUM_CLASSES)])\n",
    "    print(f\"Class sample counts: {class_sample_counts}\")\n",
    "    class_weights = 1.0 / class_sample_counts\n",
    "    sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights.astype(np.double))\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = create_model(backbone=model_name, freeze_until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    if criterion == 'focal':\n",
    "        loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    elif criterion == 'smooth':\n",
    "        loss_fn = criterion_smooth\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "    # Train\n",
    "    best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx=None)\n",
    "\n",
    "    # Evaluation\n",
    "    best_model.eval()\n",
    "    all_preds, all_labels_eval = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = best_model(xb).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_eval.extend(yb.numpy())\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels_eval, all_preds)\n",
    "    cr = classification_report(all_labels_eval, all_preds, digits=4)\n",
    "\n",
    "    log_and_store(\"--- Confusion Matrix ---\")\n",
    "    log_and_store(cm, is_confmat=True)\n",
    "    log_and_store(\"--- Classification Report ---\")\n",
    "    log_and_store(cr)\n",
    "\n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19280109",
   "metadata": {},
   "source": [
    "# Training ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b24a86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logs()  # Clear logs if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5b2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "backbone = 'efficientnet_b3'  # or 'mobilenet_v2', 'mobilenet_v3_small', efficientnet_b3, efficientnet_b0.\n",
    "freeze_until = 'features.4'  # e.g., 'features.4'\n",
    "criterion = 'focal' # 'focal' or 'smooth'\n",
    "num_epochs = 20\n",
    "batch_size = 16 # This represents the batch size for training and validation which is the number of samples processed before the model is updated.\n",
    "lr = 1e-4  # Learning rate\n",
    "\n",
    "val_split = 0.2  # Fraction of data to use for validation\n",
    "\n",
    "k_folds = 3\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f938440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [32 68]\n",
      "Fold 1, Epoch 1/15 - Train Loss: 0.1967, Train Acc: 0.4400 - Val Loss: 0.1633, Val Acc: 0.6800\n",
      "Fold 1, Epoch 2/15 - Train Loss: 0.1777, Train Acc: 0.5500 - Val Loss: 0.1592, Val Acc: 0.6400\n",
      "Fold 1, Epoch 3/15 - Train Loss: 0.1735, Train Acc: 0.5400 - Val Loss: 0.1568, Val Acc: 0.6400\n",
      "Fold 1, Epoch 4/15 - Train Loss: 0.1740, Train Acc: 0.5700 - Val Loss: 0.1590, Val Acc: 0.6000\n",
      "Fold 1, Epoch 5/15 - Train Loss: 0.1674, Train Acc: 0.5800 - Val Loss: 0.1577, Val Acc: 0.6800\n",
      "Fold 1, Epoch 6/15 - Train Loss: 0.1671, Train Acc: 0.6700 - Val Loss: 0.1498, Val Acc: 0.7200\n",
      "Fold 1, Epoch 7/15 - Train Loss: 0.1639, Train Acc: 0.6200 - Val Loss: 0.1439, Val Acc: 0.7600\n",
      "Fold 1, Epoch 8/15 - Train Loss: 0.1583, Train Acc: 0.6100 - Val Loss: 0.1360, Val Acc: 0.8000\n",
      "Fold 1, Epoch 9/15 - Train Loss: 0.1368, Train Acc: 0.7600 - Val Loss: 0.1308, Val Acc: 0.8000\n",
      "Fold 1, Epoch 10/15 - Train Loss: 0.1387, Train Acc: 0.7300 - Val Loss: 0.1280, Val Acc: 0.7600\n",
      "Fold 1, Epoch 11/15 - Train Loss: 0.1110, Train Acc: 0.8500 - Val Loss: 0.1218, Val Acc: 0.8000\n",
      "Fold 1, Epoch 12/15 - Train Loss: 0.1172, Train Acc: 0.7900 - Val Loss: 0.1172, Val Acc: 0.8400\n",
      "Fold 1, Epoch 13/15 - Train Loss: 0.1093, Train Acc: 0.8000 - Val Loss: 0.1095, Val Acc: 0.8400\n",
      "Fold 1, Epoch 14/15 - Train Loss: 0.0947, Train Acc: 0.8400 - Val Loss: 0.1090, Val Acc: 0.8000\n",
      "Fold 1, Epoch 15/15 - Train Loss: 0.1325, Train Acc: 0.7400 - Val Loss: 0.1072, Val Acc: 0.8400\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       1.00      0.60      0.75        10\n",
      "      type-7       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.89      0.80      0.82        25\n",
      "weighted avg       0.87      0.84      0.83        25\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.6000    0.7500        10\n",
      "           1     0.7895    1.0000    0.8824        15\n",
      "\n",
      "    accuracy                         0.8400        25\n",
      "   macro avg     0.8947    0.8000    0.8162        25\n",
      "weighted avg     0.8737    0.8400    0.8294        25\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [32 68]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/15 - Train Loss: 0.1817, Train Acc: 0.5900 - Val Loss: 0.1412, Val Acc: 0.7600\n",
      "Fold 2, Epoch 2/15 - Train Loss: 0.1733, Train Acc: 0.5500 - Val Loss: 0.1428, Val Acc: 0.7600\n",
      "Fold 2, Epoch 3/15 - Train Loss: 0.1687, Train Acc: 0.6200 - Val Loss: 0.1435, Val Acc: 0.7600\n",
      "Fold 2, Epoch 4/15 - Train Loss: 0.1582, Train Acc: 0.6600 - Val Loss: 0.1493, Val Acc: 0.7200\n",
      "Fold 2, Epoch 5/15 - Train Loss: 0.1643, Train Acc: 0.6600 - Val Loss: 0.1517, Val Acc: 0.7200\n",
      "Fold 2, Epoch 6/15 - Train Loss: 0.1580, Train Acc: 0.6500 - Val Loss: 0.1467, Val Acc: 0.7200\n",
      "Fold 2, Epoch 7/15 - Train Loss: 0.1516, Train Acc: 0.7200 - Val Loss: 0.1438, Val Acc: 0.8000\n",
      "Fold 2, Epoch 8/15 - Train Loss: 0.1663, Train Acc: 0.6300 - Val Loss: 0.1363, Val Acc: 0.8000\n",
      "Fold 2, Epoch 9/15 - Train Loss: 0.1520, Train Acc: 0.6900 - Val Loss: 0.1287, Val Acc: 0.8000\n",
      "Fold 2, Epoch 10/15 - Train Loss: 0.1260, Train Acc: 0.8300 - Val Loss: 0.1254, Val Acc: 0.7200\n",
      "Fold 2, Epoch 11/15 - Train Loss: 0.1093, Train Acc: 0.7900 - Val Loss: 0.1209, Val Acc: 0.7200\n",
      "Fold 2, Epoch 12/15 - Train Loss: 0.1291, Train Acc: 0.7500 - Val Loss: 0.1164, Val Acc: 0.8000\n",
      "Fold 2, Epoch 13/15 - Train Loss: 0.1184, Train Acc: 0.7900 - Val Loss: 0.1177, Val Acc: 0.8400\n",
      "Fold 2, Epoch 14/15 - Train Loss: 0.1218, Train Acc: 0.7800 - Val Loss: 0.1121, Val Acc: 0.7600\n",
      "Fold 2, Epoch 15/15 - Train Loss: 0.1102, Train Acc: 0.7800 - Val Loss: 0.1093, Val Acc: 0.7600\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       0.83      0.50      0.62        10\n",
      "      type-7       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.79      0.72      0.72        25\n",
      "weighted avg       0.78      0.76      0.74        25\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 5  5]\n",
      " [ 1 14]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.5000    0.6250        10\n",
      "           1     0.7368    0.9333    0.8235        15\n",
      "\n",
      "    accuracy                         0.7600        25\n",
      "   macro avg     0.7851    0.7167    0.7243        25\n",
      "weighted avg     0.7754    0.7600    0.7441        25\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [31 69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/15 - Train Loss: 0.1851, Train Acc: 0.4900 - Val Loss: 0.1863, Val Acc: 0.4400\n",
      "Fold 3, Epoch 2/15 - Train Loss: 0.1874, Train Acc: 0.5000 - Val Loss: 0.1824, Val Acc: 0.5200\n",
      "Fold 3, Epoch 3/15 - Train Loss: 0.1815, Train Acc: 0.5700 - Val Loss: 0.1794, Val Acc: 0.5600\n",
      "Fold 3, Epoch 4/15 - Train Loss: 0.1607, Train Acc: 0.6200 - Val Loss: 0.1778, Val Acc: 0.5200\n",
      "Fold 3, Epoch 5/15 - Train Loss: 0.1631, Train Acc: 0.6700 - Val Loss: 0.1739, Val Acc: 0.5600\n",
      "Fold 3, Epoch 6/15 - Train Loss: 0.1751, Train Acc: 0.5700 - Val Loss: 0.1676, Val Acc: 0.7600\n",
      "Fold 3, Epoch 7/15 - Train Loss: 0.1659, Train Acc: 0.6400 - Val Loss: 0.1640, Val Acc: 0.6800\n",
      "Fold 3, Epoch 8/15 - Train Loss: 0.1450, Train Acc: 0.6800 - Val Loss: 0.1534, Val Acc: 0.7600\n",
      "Fold 3, Epoch 9/15 - Train Loss: 0.1350, Train Acc: 0.7500 - Val Loss: 0.1464, Val Acc: 0.6800\n",
      "Fold 3, Epoch 10/15 - Train Loss: 0.1305, Train Acc: 0.8100 - Val Loss: 0.1464, Val Acc: 0.7200\n",
      "Fold 3, Epoch 11/15 - Train Loss: 0.1270, Train Acc: 0.7600 - Val Loss: 0.1388, Val Acc: 0.7600\n",
      "Fold 3, Epoch 12/15 - Train Loss: 0.1225, Train Acc: 0.7600 - Val Loss: 0.1269, Val Acc: 0.8000\n",
      "Fold 3, Epoch 13/15 - Train Loss: 0.1034, Train Acc: 0.8200 - Val Loss: 0.1235, Val Acc: 0.7600\n",
      "Fold 3, Epoch 14/15 - Train Loss: 0.0894, Train Acc: 0.8800 - Val Loss: 0.1200, Val Acc: 0.8000\n",
      "Fold 3, Epoch 15/15 - Train Loss: 0.0983, Train Acc: 0.8500 - Val Loss: 0.1221, Val Acc: 0.8000\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       0.88      0.64      0.74        11\n",
      "      type-7       0.76      0.93      0.84        14\n",
      "\n",
      "    accuracy                           0.80        25\n",
      "   macro avg       0.82      0.78      0.79        25\n",
      "weighted avg       0.81      0.80      0.79        25\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 7  4]\n",
      " [ 1 13]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.6364    0.7368        11\n",
      "           1     0.7647    0.9286    0.8387        14\n",
      "\n",
      "    accuracy                         0.8000        25\n",
      "   macro avg     0.8199    0.7825    0.7878        25\n",
      "weighted avg     0.8132    0.8000    0.7939        25\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [39 61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/15 - Train Loss: 0.1775, Train Acc: 0.5400 - Val Loss: 0.2008, Val Acc: 0.4000\n",
      "Fold 4, Epoch 2/15 - Train Loss: 0.1908, Train Acc: 0.4500 - Val Loss: 0.2015, Val Acc: 0.4000\n",
      "Fold 4, Epoch 3/15 - Train Loss: 0.1888, Train Acc: 0.5100 - Val Loss: 0.1986, Val Acc: 0.3600\n",
      "Fold 4, Epoch 4/15 - Train Loss: 0.1867, Train Acc: 0.5000 - Val Loss: 0.1801, Val Acc: 0.4800\n",
      "Fold 4, Epoch 5/15 - Train Loss: 0.1714, Train Acc: 0.5700 - Val Loss: 0.1803, Val Acc: 0.4400\n",
      "Fold 4, Epoch 6/15 - Train Loss: 0.1790, Train Acc: 0.4900 - Val Loss: 0.1670, Val Acc: 0.6000\n",
      "Fold 4, Epoch 7/15 - Train Loss: 0.1665, Train Acc: 0.5900 - Val Loss: 0.1677, Val Acc: 0.5600\n",
      "Fold 4, Epoch 8/15 - Train Loss: 0.1526, Train Acc: 0.7300 - Val Loss: 0.1576, Val Acc: 0.6000\n",
      "Fold 4, Epoch 9/15 - Train Loss: 0.1501, Train Acc: 0.6700 - Val Loss: 0.1408, Val Acc: 0.7600\n",
      "Fold 4, Epoch 10/15 - Train Loss: 0.1244, Train Acc: 0.7600 - Val Loss: 0.1276, Val Acc: 0.8400\n",
      "Fold 4, Epoch 11/15 - Train Loss: 0.1317, Train Acc: 0.7100 - Val Loss: 0.1277, Val Acc: 0.8400\n",
      "Fold 4, Epoch 12/15 - Train Loss: 0.1130, Train Acc: 0.8000 - Val Loss: 0.1117, Val Acc: 0.8400\n",
      "Fold 4, Epoch 13/15 - Train Loss: 0.0932, Train Acc: 0.8700 - Val Loss: 0.1056, Val Acc: 0.8400\n",
      "Fold 4, Epoch 14/15 - Train Loss: 0.1074, Train Acc: 0.8500 - Val Loss: 0.1123, Val Acc: 0.8400\n",
      "Fold 4, Epoch 15/15 - Train Loss: 0.0791, Train Acc: 0.8600 - Val Loss: 0.1261, Val Acc: 0.7600\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       0.40      0.67      0.50         3\n",
      "      type-7       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.68      0.77      0.70        25\n",
      "weighted avg       0.88      0.84      0.86        25\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 2  1]\n",
      " [ 3 19]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4000    0.6667    0.5000         3\n",
      "           1     0.9500    0.8636    0.9048        22\n",
      "\n",
      "    accuracy                         0.8400        25\n",
      "   macro avg     0.6750    0.7652    0.7024        25\n",
      "weighted avg     0.8840    0.8400    0.8562        25\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [34 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/15 - Train Loss: 0.1925, Train Acc: 0.4800 - Val Loss: 0.2119, Val Acc: 0.3200\n",
      "Fold 5, Epoch 2/15 - Train Loss: 0.1891, Train Acc: 0.5100 - Val Loss: 0.2108, Val Acc: 0.3200\n",
      "Fold 5, Epoch 3/15 - Train Loss: 0.1982, Train Acc: 0.4800 - Val Loss: 0.2121, Val Acc: 0.4000\n",
      "Fold 5, Epoch 4/15 - Train Loss: 0.1663, Train Acc: 0.5900 - Val Loss: 0.2160, Val Acc: 0.3600\n",
      "Fold 5, Epoch 5/15 - Train Loss: 0.1724, Train Acc: 0.6000 - Val Loss: 0.2223, Val Acc: 0.5200\n",
      "Fold 5, Epoch 6/15 - Train Loss: 0.1751, Train Acc: 0.5300 - Val Loss: 0.2229, Val Acc: 0.4400\n",
      "Fold 5, Epoch 7/15 - Train Loss: 0.1639, Train Acc: 0.6600 - Val Loss: 0.2068, Val Acc: 0.5200\n",
      "Fold 5, Epoch 8/15 - Train Loss: 0.1622, Train Acc: 0.5700 - Val Loss: 0.1854, Val Acc: 0.6000\n",
      "Fold 5, Epoch 9/15 - Train Loss: 0.1583, Train Acc: 0.6200 - Val Loss: 0.1717, Val Acc: 0.6800\n",
      "Fold 5, Epoch 10/15 - Train Loss: 0.1379, Train Acc: 0.7000 - Val Loss: 0.1570, Val Acc: 0.6800\n",
      "Fold 5, Epoch 11/15 - Train Loss: 0.1335, Train Acc: 0.7600 - Val Loss: 0.1452, Val Acc: 0.6800\n",
      "Fold 5, Epoch 12/15 - Train Loss: 0.1227, Train Acc: 0.7600 - Val Loss: 0.1391, Val Acc: 0.7200\n",
      "Fold 5, Epoch 13/15 - Train Loss: 0.1426, Train Acc: 0.7300 - Val Loss: 0.1252, Val Acc: 0.7200\n",
      "Fold 5, Epoch 14/15 - Train Loss: 0.1332, Train Acc: 0.7600 - Val Loss: 0.0900, Val Acc: 0.9200\n",
      "Fold 5, Epoch 15/15 - Train Loss: 0.1354, Train Acc: 0.7500 - Val Loss: 0.0754, Val Acc: 0.9600\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       0.89      1.00      0.94         8\n",
      "      type-7       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.96        25\n",
      "   macro avg       0.94      0.97      0.96        25\n",
      "weighted avg       0.96      0.96      0.96        25\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 8  0]\n",
      " [ 1 16]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    1.0000    0.9412         8\n",
      "           1     1.0000    0.9412    0.9697        17\n",
      "\n",
      "    accuracy                         0.9600        25\n",
      "   macro avg     0.9444    0.9706    0.9554        25\n",
      "weighted avg     0.9644    0.9600    0.9606        25\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.84, 0.76, 0.8, 0.84, 0.96]]\n",
      "['Mean Accuracy:', np.float64(0.8400000000000001)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b3',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer='features.4',  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=15,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59cf2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../datasets/data-loose -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4979a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [34 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 0.1892, Train Acc: 0.4700 - Val Loss: 0.1807, Val Acc: 0.5600\n",
      "Fold None, Epoch 2/15 - Train Loss: 0.1965, Train Acc: 0.4700 - Val Loss: 0.1836, Val Acc: 0.5600\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.1823, Train Acc: 0.5400 - Val Loss: 0.1856, Val Acc: 0.5200\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.1808, Train Acc: 0.5000 - Val Loss: 0.1876, Val Acc: 0.4800\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.1751, Train Acc: 0.5500 - Val Loss: 0.1772, Val Acc: 0.5200\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.1722, Train Acc: 0.6100 - Val Loss: 0.1708, Val Acc: 0.6800\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.1594, Train Acc: 0.6800 - Val Loss: 0.1701, Val Acc: 0.6400\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.1501, Train Acc: 0.7200 - Val Loss: 0.1630, Val Acc: 0.6400\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.1441, Train Acc: 0.6700 - Val Loss: 0.1541, Val Acc: 0.6800\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.1294, Train Acc: 0.7600 - Val Loss: 0.1375, Val Acc: 0.8000\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.1143, Train Acc: 0.8400 - Val Loss: 0.1285, Val Acc: 0.8400\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.1268, Train Acc: 0.7500 - Val Loss: 0.1267, Val Acc: 0.8000\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.1246, Train Acc: 0.7700 - Val Loss: 0.1186, Val Acc: 0.8800\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.1047, Train Acc: 0.8300 - Val Loss: 0.1142, Val Acc: 0.8800\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.1186, Train Acc: 0.7700 - Val Loss: 0.1073, Val Acc: 0.9200\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-6       0.88      0.88      0.88         8\n",
      "      type-7       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.91      0.91      0.91        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 7  1]\n",
      " [ 1 16]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.8750    0.8750         8\n",
      "           1     0.9412    0.9412    0.9412        17\n",
      "\n",
      "    accuracy                         0.9200        25\n",
      "   macro avg     0.9081    0.9081    0.9081        25\n",
      "weighted avg     0.9200    0.9200    0.9200        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until='features.4',  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323635fe",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d8adc",
   "metadata": {},
   "source": [
    "### Save as .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to stool_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. Define where to save\n",
    "SAVE_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "# 2. Save the state_dict\n",
    "#torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"Model weights saved to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd490f",
   "metadata": {},
   "source": [
    "### Save as .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfcdfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX export completed: stool_model.onnx\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Create dummy input for ONNX export (batch_size=1, 3 channels, IMG_SIZE x IMG_SIZE)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,                               # your trained model\n",
    "    dummy_input,                         # input tensor\n",
    "    \"stool_model.onnx\",                  # output file name\n",
    "    export_params=True,                  # store weights inside the model file\n",
    "    opset_version=11,                    # ONNX opset version\n",
    "    do_constant_folding=True,            # fold constant values for optimization\n",
    "    input_names=['input'],               # name for the input layer\n",
    "    output_names=['output'],             # name for the output layer\n",
    "    dynamic_axes={                      # allow variable input sizes\n",
    "        'input': {0: 'batch_size'},     \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ ONNX export completed: stool_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
