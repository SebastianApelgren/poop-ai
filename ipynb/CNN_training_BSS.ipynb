{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc1ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f7fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_confusion_matrix(cm):\n",
    "    \"\"\"Returns a string of a nicely formatted confusion matrix with indices and highlighted diagonal.\"\"\"\n",
    "    headers = [\"\"] + [f\"Pred {i}\" for i in range(len(cm[0]))]\n",
    "    table = []\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        formatted_row = []\n",
    "        for j, val in enumerate(row):\n",
    "            if i == j:\n",
    "                formatted_row.append(f\"*{val}*\")  # Highlight diagonal\n",
    "            else:\n",
    "                formatted_row.append(str(val))\n",
    "        table.append([f\"True {i}\"] + formatted_row)\n",
    "\n",
    "    return tabulate(table, headers=headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14f9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = []\n",
    "\n",
    "def log_and_store(*msgs, table_format=False, is_confmat=False):\n",
    "    \"\"\"\n",
    "    Logs plain messages or pretty-prints confusion matrices or tables.\n",
    "    \"\"\"\n",
    "    if is_confmat and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = format_confusion_matrix(msgs[0])\n",
    "    elif table_format and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = tabulate(msgs[0], tablefmt=\"grid\")\n",
    "    else:\n",
    "        msg = \" \".join(str(m) for m in msgs)\n",
    "\n",
    "    print(msg)\n",
    "    all_logs.append(msg)\n",
    "\n",
    "def get_logs():\n",
    "    \"\"\"\n",
    "    Returnerar en lista med alla loggade meddelanden.\n",
    "    \"\"\"\n",
    "    return all_logs\n",
    "\n",
    "def clear_logs():\n",
    "    \"\"\"\n",
    "    Tömmer loggen.\n",
    "    \"\"\"\n",
    "    all_logs.clear()\n",
    "\n",
    "def save_logs_to_file(filename):\n",
    "    \"\"\"\n",
    "    Sparar loggade meddelanden till en fil.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for log in all_logs:\n",
    "            f.write(log + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79638fe9",
   "metadata": {},
   "source": [
    "# Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../datasets/data-BSS\"  # Update this path\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd323500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoolDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(class_path, fname), idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.Lambda(lambda img: img.filter(ImageFilter.FIND_EDGES))], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340ab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing Loss (CrossEntropy with label_smoothing)\n",
    "criterion_smooth = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FocalLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c33c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    if backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        # freeze layers\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        # Replace final classifier\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb02600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return None, None, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx):\n",
    "\n",
    "    #patience = 3\n",
    "    #counter = 0\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) # for accuracy\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) # for loss\n",
    "\n",
    "    best_acc     = 0.0\n",
    "    best_loss    = float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ── One‐Cycle LR schedule ──────────────────────────────────────────────────\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=optimizer.param_groups[0]['lr'] * 10,  # e.g. 10× your base LR\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch = val_corrects / val_total\n",
    "        \n",
    "        \n",
    "\n",
    "        # keep snapshot of best‐ever validation loss (for final restore)\n",
    "        #if val_loss_epoch < best_loss:\n",
    "        #    best_loss    = val_loss_epoch\n",
    "        #    best_acc     = val_acc_epoch\n",
    "        #    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if val_acc_epoch > best_acc:\n",
    "            best_loss = val_loss_epoch\n",
    "            best_acc = val_acc_epoch\n",
    "            best_weights = model.state_dict().copy()\n",
    "        elif val_acc_epoch == best_acc:\n",
    "            # If accuracy is the same, prefer lower loss\n",
    "            if val_loss_epoch < best_loss:\n",
    "                best_loss = val_loss_epoch\n",
    "                best_weights = model.state_dict().copy()\n",
    "\n",
    "        print(f\"Fold {fold_idx}, Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        #if val_acc_epoch > best_acc:\n",
    "        #    best_acc = val_acc_epoch\n",
    "        #   best_weights = model.state_dict().copy()\n",
    "        #   counter = 0\n",
    "        #else:\n",
    "        #    counter += 1\n",
    "        #    if counter >= patience:\n",
    "        #        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #       break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Final validation metrics\n",
    "    _, _, preds, labels = evaluate_model(model, val_loader)\n",
    "    log_and_store(\"\\nClassification Report for Fold {}:\".format(fold_idx))\n",
    "    log_and_store(classification_report(labels, preds, target_names=sorted(os.listdir(DATA_DIR))))\n",
    "\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a45e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../datasets/data-BSS -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1e6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cf9c6",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c234e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(\n",
    "    data_dir,\n",
    "    backbone='mobilenet_v2',\n",
    "    freeze_until_layer=None,\n",
    "    criterion_fn=None,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    k_folds=3,\n",
    "    batch_size=32,\n",
    "    train_transforms=None,\n",
    "    val_transforms=None,\n",
    "    seed=42,\n",
    "    num_classes=7,\n",
    "    use_stratified_kfold=False\n",
    "):\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "\n",
    "    # Class weights for full dataset (optional, for balance insights)\n",
    "    all_labels_full = [label for _, label in full_dataset]\n",
    "    class_counts = np.bincount(all_labels_full)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights_full = [class_weights[label] for label in all_labels_full]\n",
    "\n",
    "    if use_stratified_kfold:\n",
    "        kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_models = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    #for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices, all_labels_full), 1):   # For stratified KFold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices), 1):                     # For normal KFold\n",
    "\n",
    "\n",
    "        print(f\"\\n======= Fold {fold_idx} =======\")\n",
    "\n",
    "        # Subset + transforms\n",
    "        train_ds = torch.utils.data.Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "        val_ds   = torch.utils.data.Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "        # Weighted sampler\n",
    "        train_labels_fold = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "        class_sample_count_fold = np.array([train_labels_fold.count(i) for i in range(num_classes)])\n",
    "        print(f\"Class sample counts: {class_sample_count_fold}\")\n",
    "        class_weights_fold = 1.0 / class_sample_count_fold\n",
    "        sample_weights_fold = np.array([class_weights_fold[label] for label in train_labels_fold])\n",
    "        sample_weights_fold = torch.from_numpy(sample_weights_fold.astype(np.double))\n",
    "        sampler_fold = WeightedRandomSampler(sample_weights_fold, num_samples=len(sample_weights_fold), replacement=True)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler_fold)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(backbone=backbone, freeze_until_layer=freeze_until_layer)\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # Loss\n",
    "        criterion = criterion_fn if criterion_fn is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train\n",
    "        best_model, best_acc = train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx)\n",
    "        fold_models.append(best_model)\n",
    "        fold_accuracies.append(best_acc)\n",
    "\n",
    "        # Evaluate and log\n",
    "        best_model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = best_model(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(yb.numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        crpt = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Confusion Matrix ---\")\n",
    "        log_and_store(cm, is_confmat=True)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Classification Report ---\")\n",
    "        log_and_store(crpt)\n",
    "\n",
    "    log_and_store([\"\\nFold Models:\", [f\"Fold {i+1}\" for i in range(len(fold_models))]])\n",
    "    log_and_store([\"Fold Accuracies:\", fold_accuracies])\n",
    "    log_and_store([\"Mean Accuracy:\", np.mean(fold_accuracies)])\n",
    "\n",
    "    return fold_models, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_split(\n",
    "    data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "):\n",
    "    print(\"======= Single Split Training =======\")\n",
    "\n",
    "    # Full dataset\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    all_labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=val_split, random_state=seed, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Create datasets with transforms\n",
    "    train_ds = Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "    val_ds = Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "    # Weighted sampler for class imbalance\n",
    "    train_labels = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "    class_sample_counts = np.array([train_labels.count(i) for i in range(NUM_CLASSES)])\n",
    "    print(f\"Class sample counts: {class_sample_counts}\")\n",
    "    class_weights = 1.0 / class_sample_counts\n",
    "    sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights.astype(np.double))\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = create_model(backbone=model_name, freeze_until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    if criterion == 'focal':\n",
    "        loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    elif criterion == 'smooth':\n",
    "        loss_fn = criterion_smooth\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "    # Train\n",
    "    best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx=None)\n",
    "\n",
    "    # Evaluation\n",
    "    best_model.eval()\n",
    "    all_preds, all_labels_eval = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = best_model(xb).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_eval.extend(yb.numpy())\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels_eval, all_preds)\n",
    "    cr = classification_report(all_labels_eval, all_preds, digits=4)\n",
    "\n",
    "    log_and_store(\"--- Confusion Matrix ---\")\n",
    "    log_and_store(cm, is_confmat=True)\n",
    "    log_and_store(\"--- Classification Report ---\")\n",
    "    log_and_store(cr)\n",
    "\n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eafa3b",
   "metadata": {},
   "source": [
    "## Save K-folds model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a44e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingEnsemble(nn.Module):\n",
    "    def __init__(self, models, weights=None):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        if weights is None:\n",
    "            self.register_buffer(\"weights\", torch.ones(len(models)) / len(models))\n",
    "        else:\n",
    "            w = torch.tensor(weights, dtype=torch.float32)\n",
    "            self.register_buffer(\"weights\", w / w.sum())\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [m(x) for m in self.models]                  # list of [B, C]\n",
    "        stacked = torch.stack(outs, dim=0)                  # [K, B, C]\n",
    "        weighted = stacked * self.weights.view(-1, 1, 1)    # broadcast weights\n",
    "        return weighted.sum(dim=0)                          # [B, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4be3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ensemble_to_onnx(kf_models, accs=None, output_path=\"ensemble.onnx\"):\n",
    "    \"\"\"\n",
    "    Saves the ensemble of models to an ONNX file.\n",
    "    \"\"\"\n",
    "    for m in kf_models:\n",
    "        m.eval()\n",
    "        m.to(\"cpu\")\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    ensemble = AveragingEnsemble(kf_models, weights=accs)  # or None for equal weights\n",
    "    ensemble.eval()\n",
    "    \n",
    "    dummy = torch.randn(1, 3, 224, 224)  # adapt shape/channels\n",
    "\n",
    "    torch.onnx.export(\n",
    "        ensemble,\n",
    "        dummy,\n",
    "        output_path,\n",
    "        opset_version=13,\n",
    "        input_names=[\"image\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes={\"image\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "        do_constant_folding=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19280109",
   "metadata": {},
   "source": [
    "# Training ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b24a86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logs()  # Clear logs if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d5b2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "backbone = 'efficientnet_b3'  # or 'mobilenet_v2', 'mobilenet_v3_small', efficientnet_b3, efficientnet_b0.\n",
    "freeze_until = 'features.4'  # e.g., 'features.4'\n",
    "criterion = 'focal' # 'focal' or 'smooth'\n",
    "num_epochs = 20\n",
    "batch_size = 16 # This represents the batch size for training and validation which is the number of samples processed before the model is updated.\n",
    "lr = 1e-4  # Learning rate\n",
    "\n",
    "val_split = 0.2  # Fraction of data to use for validation\n",
    "\n",
    "k_folds = 3\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f824e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [ 59  69 253 256  33  37  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/25 - Train Loss: 1.3776, Train Acc: 0.2281 - Val Loss: 1.3564, Val Acc: 0.2010\n",
      "Fold 1, Epoch 2/25 - Train Loss: 1.2646, Train Acc: 0.3518 - Val Loss: 1.2806, Val Acc: 0.2784\n",
      "Fold 1, Epoch 3/25 - Train Loss: 1.1507, Train Acc: 0.4098 - Val Loss: 1.2037, Val Acc: 0.3351\n",
      "Fold 1, Epoch 4/25 - Train Loss: 1.0891, Train Acc: 0.4446 - Val Loss: 1.1164, Val Acc: 0.3608\n",
      "Fold 1, Epoch 5/25 - Train Loss: 0.9749, Train Acc: 0.5013 - Val Loss: 1.0451, Val Acc: 0.3711\n",
      "Fold 1, Epoch 6/25 - Train Loss: 0.9001, Train Acc: 0.5541 - Val Loss: 0.9591, Val Acc: 0.3918\n",
      "Fold 1, Epoch 7/25 - Train Loss: 0.8822, Train Acc: 0.5374 - Val Loss: 0.9146, Val Acc: 0.4278\n",
      "Fold 1, Epoch 8/25 - Train Loss: 0.7857, Train Acc: 0.5889 - Val Loss: 0.8467, Val Acc: 0.4536\n",
      "Fold 1, Epoch 9/25 - Train Loss: 0.7370, Train Acc: 0.6031 - Val Loss: 0.7725, Val Acc: 0.4639\n",
      "Fold 1, Epoch 10/25 - Train Loss: 0.6656, Train Acc: 0.6276 - Val Loss: 0.7172, Val Acc: 0.4588\n",
      "Fold 1, Epoch 11/25 - Train Loss: 0.6016, Train Acc: 0.6611 - Val Loss: 0.6717, Val Acc: 0.5103\n",
      "Fold 1, Epoch 12/25 - Train Loss: 0.5798, Train Acc: 0.6649 - Val Loss: 0.6661, Val Acc: 0.4948\n",
      "Fold 1, Epoch 13/25 - Train Loss: 0.5320, Train Acc: 0.7088 - Val Loss: 0.6128, Val Acc: 0.5000\n",
      "Fold 1, Epoch 14/25 - Train Loss: 0.5012, Train Acc: 0.6933 - Val Loss: 0.6201, Val Acc: 0.5206\n",
      "Fold 1, Epoch 15/25 - Train Loss: 0.4552, Train Acc: 0.7113 - Val Loss: 0.5722, Val Acc: 0.5412\n",
      "Fold 1, Epoch 16/25 - Train Loss: 0.4326, Train Acc: 0.7448 - Val Loss: 0.5515, Val Acc: 0.5670\n",
      "Fold 1, Epoch 17/25 - Train Loss: 0.3953, Train Acc: 0.7500 - Val Loss: 0.5394, Val Acc: 0.5825\n",
      "Fold 1, Epoch 18/25 - Train Loss: 0.3975, Train Acc: 0.7397 - Val Loss: 0.5396, Val Acc: 0.5773\n",
      "Fold 1, Epoch 19/25 - Train Loss: 0.3140, Train Acc: 0.7951 - Val Loss: 0.5116, Val Acc: 0.5722\n",
      "Fold 1, Epoch 20/25 - Train Loss: 0.3011, Train Acc: 0.7874 - Val Loss: 0.5288, Val Acc: 0.5928\n",
      "Fold 1, Epoch 21/25 - Train Loss: 0.2931, Train Acc: 0.8041 - Val Loss: 0.4619, Val Acc: 0.6186\n",
      "Fold 1, Epoch 22/25 - Train Loss: 0.2488, Train Acc: 0.8351 - Val Loss: 0.4712, Val Acc: 0.6031\n",
      "Fold 1, Epoch 23/25 - Train Loss: 0.2619, Train Acc: 0.8067 - Val Loss: 0.4534, Val Acc: 0.6082\n",
      "Fold 1, Epoch 24/25 - Train Loss: 0.2399, Train Acc: 0.8415 - Val Loss: 0.4767, Val Acc: 0.6031\n",
      "Fold 1, Epoch 25/25 - Train Loss: 0.2342, Train Acc: 0.8286 - Val Loss: 0.4809, Val Acc: 0.6082\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.50      0.50      0.50         6\n",
      "      type-2       0.40      0.43      0.42        23\n",
      "      type-3       0.59      0.59      0.59        70\n",
      "      type-4       0.66      0.66      0.66        70\n",
      "      type-5       1.00      0.33      0.50         6\n",
      "      type-6       0.50      0.40      0.44         5\n",
      "      type-7       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.61       194\n",
      "   macro avg       0.64      0.56      0.57       194\n",
      "weighted avg       0.61      0.61      0.61       194\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 3  2  1  0  0  0  0]\n",
      " [ 2 10  8  3  0  0  0]\n",
      " [ 0  8 41 20  0  0  1]\n",
      " [ 1  5 18 46  0  0  0]\n",
      " [ 0  0  1  1  2  2  0]\n",
      " [ 0  0  1  0  0  2  2]\n",
      " [ 0  0  0  0  0  0 14]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         6\n",
      "           1     0.4000    0.4348    0.4167        23\n",
      "           2     0.5857    0.5857    0.5857        70\n",
      "           3     0.6571    0.6571    0.6571        70\n",
      "           4     1.0000    0.3333    0.5000         6\n",
      "           5     0.5000    0.4000    0.4444         5\n",
      "           6     0.8235    1.0000    0.9032        14\n",
      "\n",
      "    accuracy                         0.6082       194\n",
      "   macro avg     0.6381    0.5587    0.5725       194\n",
      "weighted avg     0.6146    0.6082    0.6054       194\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [ 51  77 259 262  29  33  65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/25 - Train Loss: 1.4164, Train Acc: 0.1765 - Val Loss: 1.3181, Val Acc: 0.2629\n",
      "Fold 2, Epoch 2/25 - Train Loss: 1.2979, Train Acc: 0.2861 - Val Loss: 1.2614, Val Acc: 0.3247\n",
      "Fold 2, Epoch 3/25 - Train Loss: 1.1793, Train Acc: 0.4137 - Val Loss: 1.1880, Val Acc: 0.3918\n",
      "Fold 2, Epoch 4/25 - Train Loss: 1.1074, Train Acc: 0.4356 - Val Loss: 1.1112, Val Acc: 0.4124\n",
      "Fold 2, Epoch 5/25 - Train Loss: 0.9949, Train Acc: 0.5129 - Val Loss: 1.0661, Val Acc: 0.4227\n",
      "Fold 2, Epoch 6/25 - Train Loss: 0.9249, Train Acc: 0.5374 - Val Loss: 0.9946, Val Acc: 0.4227\n",
      "Fold 2, Epoch 7/25 - Train Loss: 0.8254, Train Acc: 0.5812 - Val Loss: 0.9406, Val Acc: 0.4330\n",
      "Fold 2, Epoch 8/25 - Train Loss: 0.7799, Train Acc: 0.5709 - Val Loss: 0.9157, Val Acc: 0.4536\n",
      "Fold 2, Epoch 9/25 - Train Loss: 0.7059, Train Acc: 0.6070 - Val Loss: 0.8429, Val Acc: 0.4691\n",
      "Fold 2, Epoch 10/25 - Train Loss: 0.6692, Train Acc: 0.6108 - Val Loss: 0.7879, Val Acc: 0.4948\n",
      "Fold 2, Epoch 11/25 - Train Loss: 0.5603, Train Acc: 0.6830 - Val Loss: 0.7751, Val Acc: 0.4691\n",
      "Fold 2, Epoch 12/25 - Train Loss: 0.5293, Train Acc: 0.6907 - Val Loss: 0.7551, Val Acc: 0.4588\n",
      "Fold 2, Epoch 13/25 - Train Loss: 0.5219, Train Acc: 0.6856 - Val Loss: 0.7231, Val Acc: 0.5155\n",
      "Fold 2, Epoch 14/25 - Train Loss: 0.4204, Train Acc: 0.7552 - Val Loss: 0.7021, Val Acc: 0.4948\n",
      "Fold 2, Epoch 15/25 - Train Loss: 0.4069, Train Acc: 0.7384 - Val Loss: 0.7195, Val Acc: 0.4639\n",
      "Fold 2, Epoch 16/25 - Train Loss: 0.3890, Train Acc: 0.7410 - Val Loss: 0.6747, Val Acc: 0.5103\n",
      "Fold 2, Epoch 17/25 - Train Loss: 0.3534, Train Acc: 0.7629 - Val Loss: 0.6733, Val Acc: 0.5103\n",
      "Fold 2, Epoch 18/25 - Train Loss: 0.3394, Train Acc: 0.7758 - Val Loss: 0.6767, Val Acc: 0.4948\n",
      "Fold 2, Epoch 19/25 - Train Loss: 0.3090, Train Acc: 0.8170 - Val Loss: 0.6572, Val Acc: 0.5052\n",
      "Fold 2, Epoch 20/25 - Train Loss: 0.2945, Train Acc: 0.8028 - Val Loss: 0.6669, Val Acc: 0.5361\n",
      "Fold 2, Epoch 21/25 - Train Loss: 0.2683, Train Acc: 0.8286 - Val Loss: 0.6588, Val Acc: 0.5515\n",
      "Fold 2, Epoch 22/25 - Train Loss: 0.2702, Train Acc: 0.8196 - Val Loss: 0.6684, Val Acc: 0.5619\n",
      "Fold 2, Epoch 23/25 - Train Loss: 0.2096, Train Acc: 0.8570 - Val Loss: 0.6529, Val Acc: 0.5670\n",
      "Fold 2, Epoch 24/25 - Train Loss: 0.2113, Train Acc: 0.8312 - Val Loss: 0.7002, Val Acc: 0.5515\n",
      "Fold 2, Epoch 25/25 - Train Loss: 0.2187, Train Acc: 0.8505 - Val Loss: 0.6779, Val Acc: 0.5515\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.50      0.64      0.56        14\n",
      "      type-2       0.33      0.33      0.33        15\n",
      "      type-3       0.51      0.55      0.53        64\n",
      "      type-4       0.62      0.55      0.58        64\n",
      "      type-5       0.55      0.60      0.57        10\n",
      "      type-6       0.40      0.44      0.42         9\n",
      "      type-7       0.87      0.72      0.79        18\n",
      "\n",
      "    accuracy                           0.55       194\n",
      "   macro avg       0.54      0.55      0.54       194\n",
      "weighted avg       0.56      0.55      0.55       194\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 9  2  3  0  0  0  0]\n",
      " [ 1  5  6  1  1  0  1]\n",
      " [ 4  8 35 14  0  2  1]\n",
      " [ 2  0 25 35  1  1  0]\n",
      " [ 0  0  0  4  6  0  0]\n",
      " [ 0  0  0  2  3  4  0]\n",
      " [ 2  0  0  0  0  3 13]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.6429    0.5625        14\n",
      "           1     0.3333    0.3333    0.3333        15\n",
      "           2     0.5072    0.5469    0.5263        64\n",
      "           3     0.6250    0.5469    0.5833        64\n",
      "           4     0.5455    0.6000    0.5714        10\n",
      "           5     0.4000    0.4444    0.4211         9\n",
      "           6     0.8667    0.7222    0.7879        18\n",
      "\n",
      "    accuracy                         0.5515       194\n",
      "   macro avg     0.5397    0.5481    0.5408       194\n",
      "weighted avg     0.5625    0.5515    0.5545       194\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [ 51  73 255 270  30  33  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/25 - Train Loss: 1.4264, Train Acc: 0.1649 - Val Loss: 1.3768, Val Acc: 0.2526\n",
      "Fold 3, Epoch 2/25 - Train Loss: 1.3184, Train Acc: 0.2912 - Val Loss: 1.2894, Val Acc: 0.3144\n",
      "Fold 3, Epoch 3/25 - Train Loss: 1.2279, Train Acc: 0.3763 - Val Loss: 1.2307, Val Acc: 0.3402\n",
      "Fold 3, Epoch 4/25 - Train Loss: 1.1396, Train Acc: 0.4175 - Val Loss: 1.1810, Val Acc: 0.3763\n",
      "Fold 3, Epoch 5/25 - Train Loss: 1.0278, Train Acc: 0.4820 - Val Loss: 1.1148, Val Acc: 0.4021\n",
      "Fold 3, Epoch 6/25 - Train Loss: 0.9602, Train Acc: 0.5064 - Val Loss: 1.0675, Val Acc: 0.4330\n",
      "Fold 3, Epoch 7/25 - Train Loss: 0.8723, Train Acc: 0.5490 - Val Loss: 1.0013, Val Acc: 0.4278\n",
      "Fold 3, Epoch 8/25 - Train Loss: 0.8066, Train Acc: 0.5825 - Val Loss: 0.9390, Val Acc: 0.4794\n",
      "Fold 3, Epoch 9/25 - Train Loss: 0.7468, Train Acc: 0.6044 - Val Loss: 0.8584, Val Acc: 0.4845\n",
      "Fold 3, Epoch 10/25 - Train Loss: 0.6747, Train Acc: 0.6546 - Val Loss: 0.8049, Val Acc: 0.4845\n",
      "Fold 3, Epoch 11/25 - Train Loss: 0.6233, Train Acc: 0.6740 - Val Loss: 0.7730, Val Acc: 0.4845\n",
      "Fold 3, Epoch 12/25 - Train Loss: 0.5673, Train Acc: 0.6843 - Val Loss: 0.7431, Val Acc: 0.4948\n",
      "Fold 3, Epoch 13/25 - Train Loss: 0.5084, Train Acc: 0.7010 - Val Loss: 0.7276, Val Acc: 0.5000\n",
      "Fold 3, Epoch 14/25 - Train Loss: 0.4660, Train Acc: 0.7010 - Val Loss: 0.7345, Val Acc: 0.4742\n",
      "Fold 3, Epoch 15/25 - Train Loss: 0.4264, Train Acc: 0.7358 - Val Loss: 0.7005, Val Acc: 0.5206\n",
      "Fold 3, Epoch 16/25 - Train Loss: 0.4079, Train Acc: 0.7436 - Val Loss: 0.6841, Val Acc: 0.5258\n",
      "Fold 3, Epoch 17/25 - Train Loss: 0.3691, Train Acc: 0.7745 - Val Loss: 0.6708, Val Acc: 0.5258\n",
      "Fold 3, Epoch 18/25 - Train Loss: 0.3567, Train Acc: 0.7693 - Val Loss: 0.6662, Val Acc: 0.5155\n",
      "Fold 3, Epoch 19/25 - Train Loss: 0.2892, Train Acc: 0.8260 - Val Loss: 0.6552, Val Acc: 0.5773\n",
      "Fold 3, Epoch 20/25 - Train Loss: 0.2953, Train Acc: 0.8183 - Val Loss: 0.6822, Val Acc: 0.5052\n",
      "Fold 3, Epoch 21/25 - Train Loss: 0.2485, Train Acc: 0.8402 - Val Loss: 0.6712, Val Acc: 0.5309\n",
      "Fold 3, Epoch 22/25 - Train Loss: 0.2554, Train Acc: 0.8351 - Val Loss: 0.6958, Val Acc: 0.5052\n",
      "Fold 3, Epoch 23/25 - Train Loss: 0.2340, Train Acc: 0.8441 - Val Loss: 0.6697, Val Acc: 0.5670\n",
      "Fold 3, Epoch 24/25 - Train Loss: 0.2137, Train Acc: 0.8518 - Val Loss: 0.7096, Val Acc: 0.5258\n",
      "Fold 3, Epoch 25/25 - Train Loss: 0.2310, Train Acc: 0.8376 - Val Loss: 0.6641, Val Acc: 0.5722\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.56      0.36      0.43        14\n",
      "      type-2       0.21      0.26      0.23        19\n",
      "      type-3       0.56      0.62      0.59        68\n",
      "      type-4       0.61      0.61      0.61        56\n",
      "      type-5       0.88      0.78      0.82         9\n",
      "      type-6       0.78      0.78      0.78         9\n",
      "      type-7       0.85      0.58      0.69        19\n",
      "\n",
      "    accuracy                           0.57       194\n",
      "   macro avg       0.63      0.57      0.59       194\n",
      "weighted avg       0.59      0.57      0.58       194\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 5  5  3  0  0  0  1]\n",
      " [ 3  5  7  4  0  0  0]\n",
      " [ 0  8 42 16  1  1  0]\n",
      " [ 0  3 19 34  0  0  0]\n",
      " [ 0  1  0  1  7  0  0]\n",
      " [ 0  0  0  1  0  7  1]\n",
      " [ 1  2  4  0  0  1 11]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.3571    0.4348        14\n",
      "           1     0.2083    0.2632    0.2326        19\n",
      "           2     0.5600    0.6176    0.5874        68\n",
      "           3     0.6071    0.6071    0.6071        56\n",
      "           4     0.8750    0.7778    0.8235         9\n",
      "           5     0.7778    0.7778    0.7778         9\n",
      "           6     0.8462    0.5789    0.6875        19\n",
      "\n",
      "    accuracy                         0.5722       194\n",
      "   macro avg     0.6329    0.5685    0.5930       194\n",
      "weighted avg     0.5916    0.5722    0.5769       194\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [ 52  73 259 265  30  30  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/25 - Train Loss: 1.4224, Train Acc: 0.1714 - Val Loss: 1.3602, Val Acc: 0.2629\n",
      "Fold 4, Epoch 2/25 - Train Loss: 1.3248, Train Acc: 0.2577 - Val Loss: 1.2828, Val Acc: 0.2990\n",
      "Fold 4, Epoch 3/25 - Train Loss: 1.1827, Train Acc: 0.3956 - Val Loss: 1.2051, Val Acc: 0.3505\n",
      "Fold 4, Epoch 4/25 - Train Loss: 1.1078, Train Acc: 0.4343 - Val Loss: 1.1395, Val Acc: 0.3557\n",
      "Fold 4, Epoch 5/25 - Train Loss: 1.0699, Train Acc: 0.4497 - Val Loss: 1.0709, Val Acc: 0.3969\n",
      "Fold 4, Epoch 6/25 - Train Loss: 0.9814, Train Acc: 0.5090 - Val Loss: 1.0123, Val Acc: 0.4072\n",
      "Fold 4, Epoch 7/25 - Train Loss: 0.9193, Train Acc: 0.5129 - Val Loss: 0.9323, Val Acc: 0.4433\n",
      "Fold 4, Epoch 8/25 - Train Loss: 0.8158, Train Acc: 0.5902 - Val Loss: 0.8692, Val Acc: 0.4433\n",
      "Fold 4, Epoch 9/25 - Train Loss: 0.7729, Train Acc: 0.5979 - Val Loss: 0.8064, Val Acc: 0.4433\n",
      "Fold 4, Epoch 10/25 - Train Loss: 0.6602, Train Acc: 0.6765 - Val Loss: 0.7431, Val Acc: 0.4588\n",
      "Fold 4, Epoch 11/25 - Train Loss: 0.6736, Train Acc: 0.6508 - Val Loss: 0.6986, Val Acc: 0.5258\n",
      "Fold 4, Epoch 12/25 - Train Loss: 0.6084, Train Acc: 0.6753 - Val Loss: 0.6731, Val Acc: 0.5361\n",
      "Fold 4, Epoch 13/25 - Train Loss: 0.5306, Train Acc: 0.7268 - Val Loss: 0.6283, Val Acc: 0.5773\n",
      "Fold 4, Epoch 14/25 - Train Loss: 0.4729, Train Acc: 0.7345 - Val Loss: 0.6136, Val Acc: 0.5464\n",
      "Fold 4, Epoch 15/25 - Train Loss: 0.4263, Train Acc: 0.7629 - Val Loss: 0.6040, Val Acc: 0.5515\n",
      "Fold 4, Epoch 16/25 - Train Loss: 0.3652, Train Acc: 0.7835 - Val Loss: 0.6265, Val Acc: 0.5670\n",
      "Fold 4, Epoch 17/25 - Train Loss: 0.3774, Train Acc: 0.7680 - Val Loss: 0.5828, Val Acc: 0.5722\n",
      "Fold 4, Epoch 18/25 - Train Loss: 0.3362, Train Acc: 0.7706 - Val Loss: 0.5824, Val Acc: 0.5876\n",
      "Fold 4, Epoch 19/25 - Train Loss: 0.3283, Train Acc: 0.7938 - Val Loss: 0.6019, Val Acc: 0.5722\n",
      "Fold 4, Epoch 20/25 - Train Loss: 0.2899, Train Acc: 0.8041 - Val Loss: 0.6100, Val Acc: 0.5619\n",
      "Fold 4, Epoch 21/25 - Train Loss: 0.2631, Train Acc: 0.8222 - Val Loss: 0.5747, Val Acc: 0.5619\n",
      "Fold 4, Epoch 22/25 - Train Loss: 0.2640, Train Acc: 0.8235 - Val Loss: 0.5972, Val Acc: 0.5309\n",
      "Fold 4, Epoch 23/25 - Train Loss: 0.2550, Train Acc: 0.8441 - Val Loss: 0.5907, Val Acc: 0.5515\n",
      "Fold 4, Epoch 24/25 - Train Loss: 0.2337, Train Acc: 0.8376 - Val Loss: 0.6011, Val Acc: 0.5155\n",
      "Fold 4, Epoch 25/25 - Train Loss: 0.2060, Train Acc: 0.8531 - Val Loss: 0.5875, Val Acc: 0.5412\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.42      0.38      0.40        13\n",
      "      type-2       0.29      0.42      0.34        19\n",
      "      type-3       0.51      0.50      0.50        64\n",
      "      type-4       0.69      0.62      0.66        61\n",
      "      type-5       0.38      0.33      0.35         9\n",
      "      type-6       0.50      0.50      0.50        12\n",
      "      type-7       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.54       194\n",
      "   macro avg       0.51      0.51      0.51       194\n",
      "weighted avg       0.56      0.54      0.55       194\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 5  5  0  1  0  0  2]\n",
      " [ 5  8  3  2  0  0  1]\n",
      " [ 1 14 32 13  3  1  0]\n",
      " [ 0  0 21 38  0  2  0]\n",
      " [ 0  1  3  0  3  2  0]\n",
      " [ 0  0  3  1  2  6  0]\n",
      " [ 1  0  1  0  0  1 13]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4167    0.3846    0.4000        13\n",
      "           1     0.2857    0.4211    0.3404        19\n",
      "           2     0.5079    0.5000    0.5039        64\n",
      "           3     0.6909    0.6230    0.6552        61\n",
      "           4     0.3750    0.3333    0.3529         9\n",
      "           5     0.5000    0.5000    0.5000        12\n",
      "           6     0.8125    0.8125    0.8125        16\n",
      "\n",
      "    accuracy                         0.5412       194\n",
      "   macro avg     0.5127    0.5106    0.5093       194\n",
      "weighted avg     0.5560    0.5412    0.5467       194\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [ 47  76 266 251  34  35  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/25 - Train Loss: 1.4025, Train Acc: 0.2023 - Val Loss: 1.3759, Val Acc: 0.1701\n",
      "Fold 5, Epoch 2/25 - Train Loss: 1.3083, Train Acc: 0.2925 - Val Loss: 1.3112, Val Acc: 0.2680\n",
      "Fold 5, Epoch 3/25 - Train Loss: 1.2016, Train Acc: 0.3776 - Val Loss: 1.2521, Val Acc: 0.3093\n",
      "Fold 5, Epoch 4/25 - Train Loss: 1.1231, Train Acc: 0.4394 - Val Loss: 1.1936, Val Acc: 0.3557\n",
      "Fold 5, Epoch 5/25 - Train Loss: 1.0249, Train Acc: 0.5077 - Val Loss: 1.1051, Val Acc: 0.3763\n",
      "Fold 5, Epoch 6/25 - Train Loss: 0.9277, Train Acc: 0.5348 - Val Loss: 1.0351, Val Acc: 0.3918\n",
      "Fold 5, Epoch 7/25 - Train Loss: 0.8888, Train Acc: 0.5399 - Val Loss: 0.9994, Val Acc: 0.4330\n",
      "Fold 5, Epoch 8/25 - Train Loss: 0.8019, Train Acc: 0.6018 - Val Loss: 0.8968, Val Acc: 0.4639\n",
      "Fold 5, Epoch 9/25 - Train Loss: 0.7444, Train Acc: 0.6031 - Val Loss: 0.8283, Val Acc: 0.5206\n",
      "Fold 5, Epoch 10/25 - Train Loss: 0.6757, Train Acc: 0.6469 - Val Loss: 0.7550, Val Acc: 0.5464\n",
      "Fold 5, Epoch 11/25 - Train Loss: 0.6352, Train Acc: 0.6456 - Val Loss: 0.7366, Val Acc: 0.5258\n",
      "Fold 5, Epoch 12/25 - Train Loss: 0.5685, Train Acc: 0.6856 - Val Loss: 0.6796, Val Acc: 0.5567\n",
      "Fold 5, Epoch 13/25 - Train Loss: 0.4881, Train Acc: 0.7062 - Val Loss: 0.6501, Val Acc: 0.5567\n",
      "Fold 5, Epoch 14/25 - Train Loss: 0.4982, Train Acc: 0.7049 - Val Loss: 0.6360, Val Acc: 0.5464\n",
      "Fold 5, Epoch 15/25 - Train Loss: 0.4696, Train Acc: 0.7204 - Val Loss: 0.5916, Val Acc: 0.6031\n",
      "Fold 5, Epoch 16/25 - Train Loss: 0.4383, Train Acc: 0.7410 - Val Loss: 0.6163, Val Acc: 0.5722\n",
      "Fold 5, Epoch 17/25 - Train Loss: 0.3752, Train Acc: 0.7848 - Val Loss: 0.6013, Val Acc: 0.6082\n",
      "Fold 5, Epoch 18/25 - Train Loss: 0.3429, Train Acc: 0.7951 - Val Loss: 0.5381, Val Acc: 0.6392\n",
      "Fold 5, Epoch 19/25 - Train Loss: 0.3481, Train Acc: 0.7732 - Val Loss: 0.5320, Val Acc: 0.6237\n",
      "Fold 5, Epoch 20/25 - Train Loss: 0.2803, Train Acc: 0.8080 - Val Loss: 0.5172, Val Acc: 0.6546\n",
      "Fold 5, Epoch 21/25 - Train Loss: 0.2665, Train Acc: 0.8338 - Val Loss: 0.5172, Val Acc: 0.6443\n",
      "Fold 5, Epoch 22/25 - Train Loss: 0.2472, Train Acc: 0.8363 - Val Loss: 0.5239, Val Acc: 0.6237\n",
      "Fold 5, Epoch 23/25 - Train Loss: 0.2528, Train Acc: 0.8389 - Val Loss: 0.5061, Val Acc: 0.6495\n",
      "Fold 5, Epoch 24/25 - Train Loss: 0.2540, Train Acc: 0.8338 - Val Loss: 0.4850, Val Acc: 0.7062\n",
      "Fold 5, Epoch 25/25 - Train Loss: 0.2027, Train Acc: 0.8621 - Val Loss: 0.4878, Val Acc: 0.6856\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.79      0.61      0.69        18\n",
      "      type-2       0.24      0.31      0.27        16\n",
      "      type-3       0.63      0.65      0.64        57\n",
      "      type-4       0.80      0.80      0.80        75\n",
      "      type-5       0.75      0.60      0.67         5\n",
      "      type-6       0.57      0.57      0.57         7\n",
      "      type-7       0.93      0.81      0.87        16\n",
      "\n",
      "    accuracy                           0.69       194\n",
      "   macro avg       0.67      0.62      0.64       194\n",
      "weighted avg       0.70      0.69      0.69       194\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[11  4  1  1  0  0  1]\n",
      " [ 1  5  7  3  0  0  0]\n",
      " [ 0  9 37  9  0  2  0]\n",
      " [ 0  2 12 60  0  1  0]\n",
      " [ 1  0  1  0  3  0  0]\n",
      " [ 0  0  1  1  1  4  0]\n",
      " [ 1  1  0  1  0  0 13]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7857    0.6111    0.6875        18\n",
      "           1     0.2381    0.3125    0.2703        16\n",
      "           2     0.6271    0.6491    0.6379        57\n",
      "           3     0.8000    0.8000    0.8000        75\n",
      "           4     0.7500    0.6000    0.6667         5\n",
      "           5     0.5714    0.5714    0.5714         7\n",
      "           6     0.9286    0.8125    0.8667        16\n",
      "\n",
      "    accuracy                         0.6856       194\n",
      "   macro avg     0.6716    0.6224    0.6429       194\n",
      "weighted avg     0.7026    0.6856    0.6921       194\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.6185567010309279, 0.5670103092783505, 0.5773195876288659, 0.5876288659793815, 0.7061855670103093]]\n",
      "['Mean Accuracy:', np.float64(0.6113402061855671)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=25,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    seed=4,\n",
    "    num_classes=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4802c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [ 59  69 253 256  33  37  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/25 - Train Loss: 1.3823, Train Acc: 0.2307 - Val Loss: 1.2970, Val Acc: 0.2887\n",
      "Fold 1, Epoch 2/25 - Train Loss: 1.2000, Train Acc: 0.3338 - Val Loss: 1.0495, Val Acc: 0.3918\n",
      "Fold 1, Epoch 3/25 - Train Loss: 0.8807, Train Acc: 0.5322 - Val Loss: 0.7509, Val Acc: 0.4948\n",
      "Fold 1, Epoch 4/25 - Train Loss: 0.5837, Train Acc: 0.6521 - Val Loss: 0.6776, Val Acc: 0.5258\n",
      "Fold 1, Epoch 5/25 - Train Loss: 0.4241, Train Acc: 0.7191 - Val Loss: 0.6709, Val Acc: 0.5000\n",
      "Fold 1, Epoch 6/25 - Train Loss: 0.3943, Train Acc: 0.7320 - Val Loss: 0.8821, Val Acc: 0.4433\n",
      "Fold 1, Epoch 7/25 - Train Loss: 0.4104, Train Acc: 0.7320 - Val Loss: 0.9212, Val Acc: 0.4691\n",
      "Fold 1, Epoch 8/25 - Train Loss: 0.3927, Train Acc: 0.7552 - Val Loss: 0.7064, Val Acc: 0.5258\n",
      "Fold 1, Epoch 9/25 - Train Loss: 0.4100, Train Acc: 0.7345 - Val Loss: 0.6916, Val Acc: 0.5515\n",
      "Fold 1, Epoch 10/25 - Train Loss: 0.3312, Train Acc: 0.7552 - Val Loss: 0.6847, Val Acc: 0.5464\n",
      "Fold 1, Epoch 11/25 - Train Loss: 0.3774, Train Acc: 0.7629 - Val Loss: 0.7078, Val Acc: 0.5412\n",
      "Fold 1, Epoch 12/25 - Train Loss: 0.2303, Train Acc: 0.8041 - Val Loss: 0.6517, Val Acc: 0.5567\n",
      "Fold 1, Epoch 13/25 - Train Loss: 0.2151, Train Acc: 0.8492 - Val Loss: 0.7331, Val Acc: 0.6031\n",
      "Fold 1, Epoch 14/25 - Train Loss: 0.1795, Train Acc: 0.8647 - Val Loss: 0.6375, Val Acc: 0.5825\n",
      "Fold 1, Epoch 15/25 - Train Loss: 0.1430, Train Acc: 0.8995 - Val Loss: 0.8006, Val Acc: 0.5412\n",
      "Fold 1, Epoch 16/25 - Train Loss: 0.1865, Train Acc: 0.8570 - Val Loss: 0.7688, Val Acc: 0.5619\n",
      "Fold 1, Epoch 17/25 - Train Loss: 0.1403, Train Acc: 0.8827 - Val Loss: 0.7429, Val Acc: 0.5722\n",
      "Fold 1, Epoch 18/25 - Train Loss: 0.1307, Train Acc: 0.8802 - Val Loss: 0.6708, Val Acc: 0.6186\n",
      "Fold 1, Epoch 19/25 - Train Loss: 0.0901, Train Acc: 0.9278 - Val Loss: 0.6782, Val Acc: 0.6082\n",
      "Fold 1, Epoch 20/25 - Train Loss: 0.0886, Train Acc: 0.9330 - Val Loss: 0.6750, Val Acc: 0.6134\n",
      "Fold 1, Epoch 21/25 - Train Loss: 0.0787, Train Acc: 0.9330 - Val Loss: 0.6938, Val Acc: 0.6289\n",
      "Fold 1, Epoch 22/25 - Train Loss: 0.0859, Train Acc: 0.9137 - Val Loss: 0.6890, Val Acc: 0.6237\n",
      "Fold 1, Epoch 23/25 - Train Loss: 0.0789, Train Acc: 0.9214 - Val Loss: 0.6838, Val Acc: 0.6443\n",
      "Fold 1, Epoch 24/25 - Train Loss: 0.0623, Train Acc: 0.9523 - Val Loss: 0.6795, Val Acc: 0.6495\n",
      "Fold 1, Epoch 25/25 - Train Loss: 0.0695, Train Acc: 0.9433 - Val Loss: 0.6980, Val Acc: 0.6495\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.57      0.67      0.62         6\n",
      "      type-2       0.56      0.39      0.46        23\n",
      "      type-3       0.62      0.76      0.68        70\n",
      "      type-4       0.73      0.61      0.67        70\n",
      "      type-5       1.00      0.17      0.29         6\n",
      "      type-6       0.40      0.40      0.40         5\n",
      "      type-7       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.65       194\n",
      "   macro avg       0.65      0.57      0.56       194\n",
      "weighted avg       0.66      0.65      0.64       194\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 4  2  0  0  0  0  0]\n",
      " [ 1  9  9  2  0  0  2]\n",
      " [ 0  3 53 13  0  0  1]\n",
      " [ 2  1 23 43  0  0  1]\n",
      " [ 0  1  0  1  1  3  0]\n",
      " [ 0  0  1  0  0  2  2]\n",
      " [ 0  0  0  0  0  0 14]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5714    0.6667    0.6154         6\n",
      "           1     0.5625    0.3913    0.4615        23\n",
      "           2     0.6163    0.7571    0.6795        70\n",
      "           3     0.7288    0.6143    0.6667        70\n",
      "           4     1.0000    0.1667    0.2857         6\n",
      "           5     0.4000    0.4000    0.4000         5\n",
      "           6     0.7000    1.0000    0.8235        14\n",
      "\n",
      "    accuracy                         0.6495       194\n",
      "   macro avg     0.6541    0.5709    0.5618       194\n",
      "weighted avg     0.6615    0.6495    0.6381       194\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [ 51  77 259 262  29  33  65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/25 - Train Loss: 1.3728, Train Acc: 0.2178 - Val Loss: 1.2785, Val Acc: 0.2732\n",
      "Fold 2, Epoch 2/25 - Train Loss: 1.1615, Train Acc: 0.4162 - Val Loss: 1.0269, Val Acc: 0.3918\n",
      "Fold 2, Epoch 3/25 - Train Loss: 0.8142, Train Acc: 0.5825 - Val Loss: 0.7789, Val Acc: 0.4794\n",
      "Fold 2, Epoch 4/25 - Train Loss: 0.5528, Train Acc: 0.6946 - Val Loss: 0.7195, Val Acc: 0.5515\n",
      "Fold 2, Epoch 5/25 - Train Loss: 0.4100, Train Acc: 0.7320 - Val Loss: 0.9017, Val Acc: 0.4794\n",
      "Fold 2, Epoch 6/25 - Train Loss: 0.4232, Train Acc: 0.7229 - Val Loss: 0.8168, Val Acc: 0.5619\n",
      "Fold 2, Epoch 7/25 - Train Loss: 0.4539, Train Acc: 0.7036 - Val Loss: 0.8671, Val Acc: 0.5515\n",
      "Fold 2, Epoch 8/25 - Train Loss: 0.3933, Train Acc: 0.7448 - Val Loss: 0.8307, Val Acc: 0.4485\n",
      "Fold 2, Epoch 9/25 - Train Loss: 0.3682, Train Acc: 0.7320 - Val Loss: 1.0555, Val Acc: 0.5206\n",
      "Fold 2, Epoch 10/25 - Train Loss: 0.3853, Train Acc: 0.7204 - Val Loss: 0.9526, Val Acc: 0.4897\n",
      "Fold 2, Epoch 11/25 - Train Loss: 0.3029, Train Acc: 0.7899 - Val Loss: 0.8724, Val Acc: 0.5206\n",
      "Fold 2, Epoch 12/25 - Train Loss: 0.2512, Train Acc: 0.8222 - Val Loss: 0.8519, Val Acc: 0.4845\n",
      "Fold 2, Epoch 13/25 - Train Loss: 0.2013, Train Acc: 0.8454 - Val Loss: 0.8165, Val Acc: 0.6031\n",
      "Fold 2, Epoch 14/25 - Train Loss: 0.1645, Train Acc: 0.8737 - Val Loss: 0.8947, Val Acc: 0.5670\n",
      "Fold 2, Epoch 15/25 - Train Loss: 0.1850, Train Acc: 0.8608 - Val Loss: 0.9197, Val Acc: 0.5361\n",
      "Fold 2, Epoch 16/25 - Train Loss: 0.1672, Train Acc: 0.8711 - Val Loss: 0.8689, Val Acc: 0.5876\n",
      "Fold 2, Epoch 17/25 - Train Loss: 0.1364, Train Acc: 0.8814 - Val Loss: 0.9324, Val Acc: 0.5309\n",
      "Fold 2, Epoch 18/25 - Train Loss: 0.1385, Train Acc: 0.8840 - Val Loss: 0.9946, Val Acc: 0.4948\n",
      "Fold 2, Epoch 19/25 - Train Loss: 0.0984, Train Acc: 0.9227 - Val Loss: 0.8444, Val Acc: 0.5928\n",
      "Fold 2, Epoch 20/25 - Train Loss: 0.0944, Train Acc: 0.9214 - Val Loss: 0.8716, Val Acc: 0.6134\n",
      "Fold 2, Epoch 21/25 - Train Loss: 0.0930, Train Acc: 0.9085 - Val Loss: 0.8369, Val Acc: 0.6134\n",
      "Fold 2, Epoch 22/25 - Train Loss: 0.0684, Train Acc: 0.9472 - Val Loss: 0.8639, Val Acc: 0.6082\n",
      "Fold 2, Epoch 23/25 - Train Loss: 0.0748, Train Acc: 0.9369 - Val Loss: 0.9001, Val Acc: 0.5928\n",
      "Fold 2, Epoch 24/25 - Train Loss: 0.0775, Train Acc: 0.9356 - Val Loss: 0.8409, Val Acc: 0.6082\n",
      "Fold 2, Epoch 25/25 - Train Loss: 0.0612, Train Acc: 0.9420 - Val Loss: 0.8349, Val Acc: 0.6289\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.62      0.57      0.59        14\n",
      "      type-2       0.40      0.27      0.32        15\n",
      "      type-3       0.57      0.77      0.65        64\n",
      "      type-4       0.68      0.61      0.64        64\n",
      "      type-5       0.75      0.30      0.43        10\n",
      "      type-6       0.80      0.44      0.57         9\n",
      "      type-7       0.79      0.83      0.81        18\n",
      "\n",
      "    accuracy                           0.63       194\n",
      "   macro avg       0.66      0.54      0.57       194\n",
      "weighted avg       0.64      0.63      0.62       194\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 8  2  3  0  0  0  1]\n",
      " [ 2  4  8  0  0  0  1]\n",
      " [ 0  1 49 13  0  0  1]\n",
      " [ 2  2 21 39  0  0  0]\n",
      " [ 0  1  2  3  3  0  1]\n",
      " [ 0  0  2  2  1  4  0]\n",
      " [ 1  0  1  0  0  1 15]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6154    0.5714    0.5926        14\n",
      "           1     0.4000    0.2667    0.3200        15\n",
      "           2     0.5698    0.7656    0.6533        64\n",
      "           3     0.6842    0.6094    0.6446        64\n",
      "           4     0.7500    0.3000    0.4286        10\n",
      "           5     0.8000    0.4444    0.5714         9\n",
      "           6     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.6289       194\n",
      "   macro avg     0.6584    0.5416    0.5745       194\n",
      "weighted avg     0.6380    0.6289    0.6195       194\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [ 51  73 255 270  30  33  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/25 - Train Loss: 1.3915, Train Acc: 0.2088 - Val Loss: 1.3067, Val Acc: 0.3093\n",
      "Fold 3, Epoch 2/25 - Train Loss: 1.1732, Train Acc: 0.3660 - Val Loss: 1.1437, Val Acc: 0.2938\n",
      "Fold 3, Epoch 3/25 - Train Loss: 0.8355, Train Acc: 0.5490 - Val Loss: 0.9404, Val Acc: 0.4330\n",
      "Fold 3, Epoch 4/25 - Train Loss: 0.5375, Train Acc: 0.6727 - Val Loss: 0.7854, Val Acc: 0.5258\n",
      "Fold 3, Epoch 5/25 - Train Loss: 0.4436, Train Acc: 0.7023 - Val Loss: 0.9011, Val Acc: 0.4845\n",
      "Fold 3, Epoch 6/25 - Train Loss: 0.3825, Train Acc: 0.7371 - Val Loss: 0.9993, Val Acc: 0.4897\n",
      "Fold 3, Epoch 7/25 - Train Loss: 0.4385, Train Acc: 0.7023 - Val Loss: 0.9486, Val Acc: 0.4433\n",
      "Fold 3, Epoch 8/25 - Train Loss: 0.3456, Train Acc: 0.7745 - Val Loss: 0.8357, Val Acc: 0.5258\n",
      "Fold 3, Epoch 9/25 - Train Loss: 0.3598, Train Acc: 0.7294 - Val Loss: 1.0647, Val Acc: 0.4691\n",
      "Fold 3, Epoch 10/25 - Train Loss: 0.3744, Train Acc: 0.7603 - Val Loss: 1.2267, Val Acc: 0.3969\n",
      "Fold 3, Epoch 11/25 - Train Loss: 0.3029, Train Acc: 0.7835 - Val Loss: 1.0181, Val Acc: 0.4433\n",
      "Fold 3, Epoch 12/25 - Train Loss: 0.2635, Train Acc: 0.8015 - Val Loss: 0.9981, Val Acc: 0.4845\n",
      "Fold 3, Epoch 13/25 - Train Loss: 0.2268, Train Acc: 0.8093 - Val Loss: 0.9157, Val Acc: 0.5258\n",
      "Fold 3, Epoch 14/25 - Train Loss: 0.2044, Train Acc: 0.8402 - Val Loss: 0.9497, Val Acc: 0.5052\n",
      "Fold 3, Epoch 15/25 - Train Loss: 0.1397, Train Acc: 0.8892 - Val Loss: 0.9113, Val Acc: 0.5464\n",
      "Fold 3, Epoch 16/25 - Train Loss: 0.1224, Train Acc: 0.9008 - Val Loss: 0.8835, Val Acc: 0.5619\n",
      "Fold 3, Epoch 17/25 - Train Loss: 0.1169, Train Acc: 0.9021 - Val Loss: 0.9361, Val Acc: 0.5464\n",
      "Fold 3, Epoch 18/25 - Train Loss: 0.1283, Train Acc: 0.8905 - Val Loss: 0.8812, Val Acc: 0.5773\n",
      "Fold 3, Epoch 19/25 - Train Loss: 0.1145, Train Acc: 0.9072 - Val Loss: 0.9256, Val Acc: 0.5928\n",
      "Fold 3, Epoch 20/25 - Train Loss: 0.0984, Train Acc: 0.9149 - Val Loss: 0.9328, Val Acc: 0.5773\n",
      "Fold 3, Epoch 21/25 - Train Loss: 0.0849, Train Acc: 0.9304 - Val Loss: 0.9071, Val Acc: 0.6082\n",
      "Fold 3, Epoch 22/25 - Train Loss: 0.0821, Train Acc: 0.9381 - Val Loss: 0.9144, Val Acc: 0.5773\n",
      "Fold 3, Epoch 23/25 - Train Loss: 0.0815, Train Acc: 0.9330 - Val Loss: 0.8860, Val Acc: 0.6031\n",
      "Fold 3, Epoch 24/25 - Train Loss: 0.0814, Train Acc: 0.9317 - Val Loss: 0.9419, Val Acc: 0.5928\n",
      "Fold 3, Epoch 25/25 - Train Loss: 0.0819, Train Acc: 0.9291 - Val Loss: 0.8806, Val Acc: 0.5722\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.43      0.43      0.43        14\n",
      "      type-2       0.39      0.37      0.38        19\n",
      "      type-3       0.55      0.63      0.59        68\n",
      "      type-4       0.64      0.61      0.62        56\n",
      "      type-5       0.71      0.56      0.62         9\n",
      "      type-6       0.64      0.78      0.70         9\n",
      "      type-7       0.69      0.47      0.56        19\n",
      "\n",
      "    accuracy                           0.57       194\n",
      "   macro avg       0.58      0.55      0.56       194\n",
      "weighted avg       0.58      0.57      0.57       194\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 6  4  3  1  0  0  0]\n",
      " [ 2  7  6  2  1  0  1]\n",
      " [ 4  3 43 15  0  1  2]\n",
      " [ 1  1 19 34  0  1  0]\n",
      " [ 0  1  0  1  5  1  1]\n",
      " [ 0  0  1  0  1  7  0]\n",
      " [ 1  2  6  0  0  1  9]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4286    0.4286    0.4286        14\n",
      "           1     0.3889    0.3684    0.3784        19\n",
      "           2     0.5513    0.6324    0.5890        68\n",
      "           3     0.6415    0.6071    0.6239        56\n",
      "           4     0.7143    0.5556    0.6250         9\n",
      "           5     0.6364    0.7778    0.7000         9\n",
      "           6     0.6923    0.4737    0.5625        19\n",
      "\n",
      "    accuracy                         0.5722       194\n",
      "   macro avg     0.5790    0.5491    0.5582       194\n",
      "weighted avg     0.5779    0.5722    0.5711       194\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [ 52  73 259 265  30  30  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/25 - Train Loss: 1.3958, Train Acc: 0.2023 - Val Loss: 1.3032, Val Acc: 0.3196\n",
      "Fold 4, Epoch 2/25 - Train Loss: 1.1905, Train Acc: 0.3698 - Val Loss: 1.0997, Val Acc: 0.4330\n",
      "Fold 4, Epoch 3/25 - Train Loss: 0.8920, Train Acc: 0.5477 - Val Loss: 0.7115, Val Acc: 0.5670\n",
      "Fold 4, Epoch 4/25 - Train Loss: 0.5234, Train Acc: 0.6933 - Val Loss: 0.6587, Val Acc: 0.5052\n",
      "Fold 4, Epoch 5/25 - Train Loss: 0.4255, Train Acc: 0.7204 - Val Loss: 0.8763, Val Acc: 0.4381\n",
      "Fold 4, Epoch 6/25 - Train Loss: 0.4228, Train Acc: 0.7165 - Val Loss: 0.9313, Val Acc: 0.5052\n",
      "Fold 4, Epoch 7/25 - Train Loss: 0.4672, Train Acc: 0.6791 - Val Loss: 0.9494, Val Acc: 0.5206\n",
      "Fold 4, Epoch 8/25 - Train Loss: 0.4222, Train Acc: 0.7139 - Val Loss: 0.8091, Val Acc: 0.6186\n",
      "Fold 4, Epoch 9/25 - Train Loss: 0.3289, Train Acc: 0.7577 - Val Loss: 0.9251, Val Acc: 0.4845\n",
      "Fold 4, Epoch 10/25 - Train Loss: 0.2584, Train Acc: 0.8054 - Val Loss: 1.0692, Val Acc: 0.4897\n",
      "Fold 4, Epoch 11/25 - Train Loss: 0.3297, Train Acc: 0.7796 - Val Loss: 0.9381, Val Acc: 0.5000\n",
      "Fold 4, Epoch 12/25 - Train Loss: 0.2540, Train Acc: 0.8260 - Val Loss: 0.9697, Val Acc: 0.5412\n",
      "Fold 4, Epoch 13/25 - Train Loss: 0.1930, Train Acc: 0.8531 - Val Loss: 0.8764, Val Acc: 0.5515\n",
      "Fold 4, Epoch 14/25 - Train Loss: 0.1702, Train Acc: 0.8686 - Val Loss: 0.8265, Val Acc: 0.5928\n",
      "Fold 4, Epoch 15/25 - Train Loss: 0.1670, Train Acc: 0.8750 - Val Loss: 0.9653, Val Acc: 0.5258\n",
      "Fold 4, Epoch 16/25 - Train Loss: 0.1648, Train Acc: 0.8853 - Val Loss: 0.9413, Val Acc: 0.5567\n",
      "Fold 4, Epoch 17/25 - Train Loss: 0.1143, Train Acc: 0.9111 - Val Loss: 0.8467, Val Acc: 0.5567\n",
      "Fold 4, Epoch 18/25 - Train Loss: 0.0972, Train Acc: 0.9149 - Val Loss: 0.7485, Val Acc: 0.5928\n",
      "Fold 4, Epoch 19/25 - Train Loss: 0.0990, Train Acc: 0.9214 - Val Loss: 0.7799, Val Acc: 0.6082\n",
      "Fold 4, Epoch 20/25 - Train Loss: 0.0841, Train Acc: 0.9343 - Val Loss: 0.8151, Val Acc: 0.5876\n",
      "Fold 4, Epoch 21/25 - Train Loss: 0.0924, Train Acc: 0.9291 - Val Loss: 0.8170, Val Acc: 0.5722\n",
      "Fold 4, Epoch 22/25 - Train Loss: 0.0792, Train Acc: 0.9369 - Val Loss: 0.7953, Val Acc: 0.5670\n",
      "Fold 4, Epoch 23/25 - Train Loss: 0.0878, Train Acc: 0.9278 - Val Loss: 0.7792, Val Acc: 0.5876\n",
      "Fold 4, Epoch 24/25 - Train Loss: 0.0715, Train Acc: 0.9420 - Val Loss: 0.8122, Val Acc: 0.5825\n",
      "Fold 4, Epoch 25/25 - Train Loss: 0.0686, Train Acc: 0.9433 - Val Loss: 0.8012, Val Acc: 0.5825\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.43      0.23      0.30        13\n",
      "      type-2       0.21      0.26      0.23        19\n",
      "      type-3       0.55      0.55      0.55        64\n",
      "      type-4       0.73      0.77      0.75        61\n",
      "      type-5       0.62      0.56      0.59         9\n",
      "      type-6       0.50      0.42      0.45        12\n",
      "      type-7       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.58       194\n",
      "   macro avg       0.54      0.51      0.52       194\n",
      "weighted avg       0.58      0.58      0.58       194\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 3  6  2  0  0  1  1]\n",
      " [ 3  5  8  2  1  0  0]\n",
      " [ 0 12 35 14  0  2  1]\n",
      " [ 0  0 13 47  0  1  0]\n",
      " [ 0  1  2  1  5  0  0]\n",
      " [ 0  0  3  0  2  5  2]\n",
      " [ 1  0  1  0  0  1 13]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4286    0.2308    0.3000        13\n",
      "           1     0.2083    0.2632    0.2326        19\n",
      "           2     0.5469    0.5469    0.5469        64\n",
      "           3     0.7344    0.7705    0.7520        61\n",
      "           4     0.6250    0.5556    0.5882         9\n",
      "           5     0.5000    0.4167    0.4545        12\n",
      "           6     0.7647    0.8125    0.7879        16\n",
      "\n",
      "    accuracy                         0.5825       194\n",
      "   macro avg     0.5440    0.5137    0.5232       194\n",
      "weighted avg     0.5834    0.5825    0.5801       194\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [ 47  76 266 251  34  35  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/25 - Train Loss: 1.4060, Train Acc: 0.1869 - Val Loss: 1.3736, Val Acc: 0.1907\n",
      "Fold 5, Epoch 2/25 - Train Loss: 1.2156, Train Acc: 0.3338 - Val Loss: 1.0753, Val Acc: 0.4175\n",
      "Fold 5, Epoch 3/25 - Train Loss: 0.8750, Train Acc: 0.5477 - Val Loss: 0.7829, Val Acc: 0.5052\n",
      "Fold 5, Epoch 4/25 - Train Loss: 0.5752, Train Acc: 0.6469 - Val Loss: 0.6388, Val Acc: 0.5876\n",
      "Fold 5, Epoch 5/25 - Train Loss: 0.4322, Train Acc: 0.7307 - Val Loss: 0.8446, Val Acc: 0.4227\n",
      "Fold 5, Epoch 6/25 - Train Loss: 0.4459, Train Acc: 0.7139 - Val Loss: 1.0763, Val Acc: 0.4845\n",
      "Fold 5, Epoch 7/25 - Train Loss: 0.4152, Train Acc: 0.7126 - Val Loss: 0.8602, Val Acc: 0.4742\n",
      "Fold 5, Epoch 8/25 - Train Loss: 0.4540, Train Acc: 0.7010 - Val Loss: 0.8985, Val Acc: 0.5206\n",
      "Fold 5, Epoch 9/25 - Train Loss: 0.3188, Train Acc: 0.7642 - Val Loss: 0.8181, Val Acc: 0.4948\n",
      "Fold 5, Epoch 10/25 - Train Loss: 0.3433, Train Acc: 0.7603 - Val Loss: 0.9865, Val Acc: 0.5464\n",
      "Fold 5, Epoch 11/25 - Train Loss: 0.3499, Train Acc: 0.7796 - Val Loss: 0.8034, Val Acc: 0.5825\n",
      "Fold 5, Epoch 12/25 - Train Loss: 0.2233, Train Acc: 0.8479 - Val Loss: 0.8392, Val Acc: 0.5361\n",
      "Fold 5, Epoch 13/25 - Train Loss: 0.2231, Train Acc: 0.8299 - Val Loss: 0.7578, Val Acc: 0.5825\n",
      "Fold 5, Epoch 14/25 - Train Loss: 0.1707, Train Acc: 0.8686 - Val Loss: 0.7390, Val Acc: 0.6289\n",
      "Fold 5, Epoch 15/25 - Train Loss: 0.1313, Train Acc: 0.8853 - Val Loss: 0.7378, Val Acc: 0.6031\n",
      "Fold 5, Epoch 16/25 - Train Loss: 0.1646, Train Acc: 0.8673 - Val Loss: 0.7604, Val Acc: 0.5515\n",
      "Fold 5, Epoch 17/25 - Train Loss: 0.1259, Train Acc: 0.8995 - Val Loss: 0.7618, Val Acc: 0.5876\n",
      "Fold 5, Epoch 18/25 - Train Loss: 0.1213, Train Acc: 0.9098 - Val Loss: 0.7127, Val Acc: 0.5876\n",
      "Fold 5, Epoch 19/25 - Train Loss: 0.0915, Train Acc: 0.9240 - Val Loss: 0.7393, Val Acc: 0.6340\n",
      "Fold 5, Epoch 20/25 - Train Loss: 0.0815, Train Acc: 0.9253 - Val Loss: 0.7509, Val Acc: 0.6186\n",
      "Fold 5, Epoch 21/25 - Train Loss: 0.0868, Train Acc: 0.9253 - Val Loss: 0.7425, Val Acc: 0.6186\n",
      "Fold 5, Epoch 22/25 - Train Loss: 0.0839, Train Acc: 0.9175 - Val Loss: 0.7601, Val Acc: 0.6082\n",
      "Fold 5, Epoch 23/25 - Train Loss: 0.0847, Train Acc: 0.9330 - Val Loss: 0.7693, Val Acc: 0.6082\n",
      "Fold 5, Epoch 24/25 - Train Loss: 0.0818, Train Acc: 0.9343 - Val Loss: 0.7537, Val Acc: 0.6237\n",
      "Fold 5, Epoch 25/25 - Train Loss: 0.0756, Train Acc: 0.9317 - Val Loss: 0.7804, Val Acc: 0.6031\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.57      0.44      0.50        18\n",
      "      type-2       0.18      0.12      0.15        16\n",
      "      type-3       0.51      0.63      0.57        57\n",
      "      type-4       0.74      0.75      0.74        75\n",
      "      type-5       0.25      0.20      0.22         5\n",
      "      type-6       0.50      0.29      0.36         7\n",
      "      type-7       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.60       194\n",
      "   macro avg       0.51      0.45      0.47       194\n",
      "weighted avg       0.59      0.60      0.59       194\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 8  3  3  2  0  0  2]\n",
      " [ 3  2  9  1  1  0  0]\n",
      " [ 1  5 36 14  0  1  0]\n",
      " [ 0  1 17 56  0  1  0]\n",
      " [ 1  0  1  1  1  0  1]\n",
      " [ 0  0  2  1  2  2  0]\n",
      " [ 1  0  2  1  0  0 12]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5714    0.4444    0.5000        18\n",
      "           1     0.1818    0.1250    0.1481        16\n",
      "           2     0.5143    0.6316    0.5669        57\n",
      "           3     0.7368    0.7467    0.7417        75\n",
      "           4     0.2500    0.2000    0.2222         5\n",
      "           5     0.5000    0.2857    0.3636         7\n",
      "           6     0.8000    0.7500    0.7742        16\n",
      "\n",
      "    accuracy                         0.6031       194\n",
      "   macro avg     0.5078    0.4548    0.4738       194\n",
      "weighted avg     0.5944    0.6031    0.5946       194\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.6494845360824743, 0.6288659793814433, 0.6082474226804123, 0.6185567010309279, 0.634020618556701]]\n",
      "['Mean Accuracy:', np.float64(0.6278350515463917)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=25,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    seed=4,\n",
    "    num_classes=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bc00cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ensemble_to_onnx(kf_models, accs, output_path=\"kf_stool_classification_628.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065696c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [ 52  73 259 260  32  33  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/25 - Train Loss: 1.3756, Train Acc: 0.2294 - Val Loss: 1.3141, Val Acc: 0.2784\n",
      "Fold 1, Epoch 2/25 - Train Loss: 1.1767, Train Acc: 0.3879 - Val Loss: 1.0766, Val Acc: 0.4278\n",
      "Fold 1, Epoch 3/25 - Train Loss: 0.8377, Train Acc: 0.5515 - Val Loss: 0.7173, Val Acc: 0.5515\n",
      "Fold 1, Epoch 4/25 - Train Loss: 0.5271, Train Acc: 0.6804 - Val Loss: 0.6111, Val Acc: 0.6186\n",
      "Fold 1, Epoch 5/25 - Train Loss: 0.4792, Train Acc: 0.7101 - Val Loss: 0.6823, Val Acc: 0.5412\n",
      "Fold 1, Epoch 6/25 - Train Loss: 0.3562, Train Acc: 0.7461 - Val Loss: 0.8677, Val Acc: 0.4536\n",
      "Fold 1, Epoch 7/25 - Train Loss: 0.4022, Train Acc: 0.7307 - Val Loss: 0.9467, Val Acc: 0.5000\n",
      "Fold 1, Epoch 8/25 - Train Loss: 0.3518, Train Acc: 0.7436 - Val Loss: 0.8142, Val Acc: 0.5052\n",
      "Fold 1, Epoch 9/25 - Train Loss: 0.3345, Train Acc: 0.8067 - Val Loss: 0.8755, Val Acc: 0.5670\n",
      "Fold 1, Epoch 10/25 - Train Loss: 0.3056, Train Acc: 0.7835 - Val Loss: 0.8323, Val Acc: 0.5722\n",
      "Fold 1, Epoch 11/25 - Train Loss: 0.3283, Train Acc: 0.7835 - Val Loss: 0.8211, Val Acc: 0.5825\n",
      "Fold 1, Epoch 12/25 - Train Loss: 0.3145, Train Acc: 0.7693 - Val Loss: 0.7908, Val Acc: 0.5206\n",
      "Fold 1, Epoch 13/25 - Train Loss: 0.2198, Train Acc: 0.8260 - Val Loss: 0.7790, Val Acc: 0.5258\n",
      "Fold 1, Epoch 14/25 - Train Loss: 0.1800, Train Acc: 0.8608 - Val Loss: 0.8620, Val Acc: 0.5773\n",
      "Fold 1, Epoch 15/25 - Train Loss: 0.1470, Train Acc: 0.8789 - Val Loss: 0.7848, Val Acc: 0.5825\n",
      "Fold 1, Epoch 16/25 - Train Loss: 0.1409, Train Acc: 0.8969 - Val Loss: 0.7421, Val Acc: 0.5722\n",
      "Fold 1, Epoch 17/25 - Train Loss: 0.1255, Train Acc: 0.9034 - Val Loss: 0.7295, Val Acc: 0.5928\n",
      "Fold 1, Epoch 18/25 - Train Loss: 0.1376, Train Acc: 0.8866 - Val Loss: 0.7324, Val Acc: 0.5825\n",
      "Fold 1, Epoch 19/25 - Train Loss: 0.0878, Train Acc: 0.9034 - Val Loss: 0.7936, Val Acc: 0.5876\n",
      "Fold 1, Epoch 20/25 - Train Loss: 0.0776, Train Acc: 0.9356 - Val Loss: 0.7751, Val Acc: 0.5825\n",
      "Fold 1, Epoch 21/25 - Train Loss: 0.0997, Train Acc: 0.9124 - Val Loss: 0.7840, Val Acc: 0.5876\n",
      "Fold 1, Epoch 22/25 - Train Loss: 0.0706, Train Acc: 0.9356 - Val Loss: 0.7943, Val Acc: 0.6031\n",
      "Fold 1, Epoch 23/25 - Train Loss: 0.0752, Train Acc: 0.9407 - Val Loss: 0.7739, Val Acc: 0.5876\n",
      "Fold 1, Epoch 24/25 - Train Loss: 0.0602, Train Acc: 0.9510 - Val Loss: 0.8017, Val Acc: 0.6031\n",
      "Fold 1, Epoch 25/25 - Train Loss: 0.0752, Train Acc: 0.9420 - Val Loss: 0.7840, Val Acc: 0.5979\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.64      0.54      0.58        13\n",
      "      type-2       0.29      0.32      0.30        19\n",
      "      type-3       0.59      0.66      0.62        64\n",
      "      type-4       0.69      0.67      0.68        66\n",
      "      type-5       0.45      0.71      0.56         7\n",
      "      type-6       0.60      0.33      0.43         9\n",
      "      type-7       0.82      0.56      0.67        16\n",
      "\n",
      "    accuracy                           0.60       194\n",
      "   macro avg       0.58      0.54      0.55       194\n",
      "weighted avg       0.61      0.60      0.60       194\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 7  3  2  0  0  0  1]\n",
      " [ 1  6  7  4  1  0  0]\n",
      " [ 2  5 42 14  0  1  0]\n",
      " [ 0  4 17 44  1  0  0]\n",
      " [ 0  0  0  1  5  1  0]\n",
      " [ 0  0  1  1  3  3  1]\n",
      " [ 1  3  2  0  1  0  9]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.5385    0.5833        13\n",
      "           1     0.2857    0.3158    0.3000        19\n",
      "           2     0.5915    0.6562    0.6222        64\n",
      "           3     0.6875    0.6667    0.6769        66\n",
      "           4     0.4545    0.7143    0.5556         7\n",
      "           5     0.6000    0.3333    0.4286         9\n",
      "           6     0.8182    0.5625    0.6667        16\n",
      "\n",
      "    accuracy                         0.5979       194\n",
      "   macro avg     0.5820    0.5410    0.5476       194\n",
      "weighted avg     0.6114    0.5979    0.5989       194\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [ 52  73 259 261  31  33  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/25 - Train Loss: 1.3980, Train Acc: 0.2023 - Val Loss: 1.2908, Val Acc: 0.3144\n",
      "Fold 2, Epoch 2/25 - Train Loss: 1.1496, Train Acc: 0.4046 - Val Loss: 1.0972, Val Acc: 0.3763\n",
      "Fold 2, Epoch 3/25 - Train Loss: 0.8543, Train Acc: 0.5361 - Val Loss: 0.8160, Val Acc: 0.4330\n",
      "Fold 2, Epoch 4/25 - Train Loss: 0.5247, Train Acc: 0.6933 - Val Loss: 0.7821, Val Acc: 0.4742\n",
      "Fold 2, Epoch 5/25 - Train Loss: 0.4114, Train Acc: 0.7320 - Val Loss: 0.8323, Val Acc: 0.4897\n",
      "Fold 2, Epoch 6/25 - Train Loss: 0.3788, Train Acc: 0.7384 - Val Loss: 0.9684, Val Acc: 0.4897\n",
      "Fold 2, Epoch 7/25 - Train Loss: 0.4745, Train Acc: 0.6881 - Val Loss: 0.7645, Val Acc: 0.4897\n",
      "Fold 2, Epoch 8/25 - Train Loss: 0.4042, Train Acc: 0.7113 - Val Loss: 0.9564, Val Acc: 0.4897\n",
      "Fold 2, Epoch 9/25 - Train Loss: 0.3264, Train Acc: 0.7771 - Val Loss: 0.8084, Val Acc: 0.5515\n",
      "Fold 2, Epoch 10/25 - Train Loss: 0.3530, Train Acc: 0.7603 - Val Loss: 1.1132, Val Acc: 0.5052\n",
      "Fold 2, Epoch 11/25 - Train Loss: 0.2716, Train Acc: 0.8093 - Val Loss: 0.7807, Val Acc: 0.5258\n",
      "Fold 2, Epoch 12/25 - Train Loss: 0.2205, Train Acc: 0.8363 - Val Loss: 0.7759, Val Acc: 0.5567\n",
      "Fold 2, Epoch 13/25 - Train Loss: 0.2024, Train Acc: 0.8492 - Val Loss: 0.8996, Val Acc: 0.5773\n",
      "Fold 2, Epoch 14/25 - Train Loss: 0.1515, Train Acc: 0.8737 - Val Loss: 0.9432, Val Acc: 0.4639\n",
      "Fold 2, Epoch 15/25 - Train Loss: 0.1907, Train Acc: 0.8570 - Val Loss: 0.8001, Val Acc: 0.5258\n",
      "Fold 2, Epoch 16/25 - Train Loss: 0.1420, Train Acc: 0.8802 - Val Loss: 0.7860, Val Acc: 0.5825\n",
      "Fold 2, Epoch 17/25 - Train Loss: 0.1239, Train Acc: 0.8982 - Val Loss: 0.8042, Val Acc: 0.5825\n",
      "Fold 2, Epoch 18/25 - Train Loss: 0.1170, Train Acc: 0.9085 - Val Loss: 0.8426, Val Acc: 0.5619\n",
      "Fold 2, Epoch 19/25 - Train Loss: 0.0934, Train Acc: 0.9227 - Val Loss: 0.7846, Val Acc: 0.5825\n",
      "Fold 2, Epoch 20/25 - Train Loss: 0.1127, Train Acc: 0.9085 - Val Loss: 0.7954, Val Acc: 0.6186\n",
      "Fold 2, Epoch 21/25 - Train Loss: 0.0907, Train Acc: 0.9240 - Val Loss: 0.8312, Val Acc: 0.6082\n",
      "Fold 2, Epoch 22/25 - Train Loss: 0.0712, Train Acc: 0.9369 - Val Loss: 0.7936, Val Acc: 0.6031\n",
      "Fold 2, Epoch 23/25 - Train Loss: 0.0782, Train Acc: 0.9433 - Val Loss: 0.8299, Val Acc: 0.5979\n",
      "Fold 2, Epoch 24/25 - Train Loss: 0.0671, Train Acc: 0.9446 - Val Loss: 0.8148, Val Acc: 0.6031\n",
      "Fold 2, Epoch 25/25 - Train Loss: 0.0712, Train Acc: 0.9446 - Val Loss: 0.8232, Val Acc: 0.5979\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.55      0.46      0.50        13\n",
      "      type-2       0.43      0.32      0.36        19\n",
      "      type-3       0.57      0.53      0.55        64\n",
      "      type-4       0.62      0.77      0.69        65\n",
      "      type-5       0.57      0.50      0.53         8\n",
      "      type-6       0.80      0.44      0.57         9\n",
      "      type-7       0.71      0.75      0.73        16\n",
      "\n",
      "    accuracy                           0.60       194\n",
      "   macro avg       0.61      0.54      0.56       194\n",
      "weighted avg       0.59      0.60      0.59       194\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 6  0  4  2  0  1  0]\n",
      " [ 1  6  5  5  0  0  2]\n",
      " [ 3  4 34 21  1  0  1]\n",
      " [ 0  3 11 50  1  0  0]\n",
      " [ 1  0  2  1  4  0  0]\n",
      " [ 0  0  2  0  1  4  2]\n",
      " [ 0  1  2  1  0  0 12]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5455    0.4615    0.5000        13\n",
      "           1     0.4286    0.3158    0.3636        19\n",
      "           2     0.5667    0.5312    0.5484        64\n",
      "           3     0.6250    0.7692    0.6897        65\n",
      "           4     0.5714    0.5000    0.5333         8\n",
      "           5     0.8000    0.4444    0.5714         9\n",
      "           6     0.7059    0.7500    0.7273        16\n",
      "\n",
      "    accuracy                         0.5979       194\n",
      "   macro avg     0.6061    0.5389    0.5620       194\n",
      "weighted avg     0.5938    0.5979    0.5896       194\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [ 52  74 258 261  31  34  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/25 - Train Loss: 1.3840, Train Acc: 0.2126 - Val Loss: 1.3560, Val Acc: 0.2268\n",
      "Fold 3, Epoch 2/25 - Train Loss: 1.1630, Train Acc: 0.3814 - Val Loss: 1.1077, Val Acc: 0.3969\n",
      "Fold 3, Epoch 3/25 - Train Loss: 0.8489, Train Acc: 0.5309 - Val Loss: 0.7344, Val Acc: 0.5103\n",
      "Fold 3, Epoch 4/25 - Train Loss: 0.5519, Train Acc: 0.6443 - Val Loss: 0.7401, Val Acc: 0.5052\n",
      "Fold 3, Epoch 5/25 - Train Loss: 0.4707, Train Acc: 0.6830 - Val Loss: 0.8345, Val Acc: 0.4381\n",
      "Fold 3, Epoch 6/25 - Train Loss: 0.4366, Train Acc: 0.7178 - Val Loss: 0.9859, Val Acc: 0.4742\n",
      "Fold 3, Epoch 7/25 - Train Loss: 0.4110, Train Acc: 0.7320 - Val Loss: 0.9613, Val Acc: 0.4433\n",
      "Fold 3, Epoch 8/25 - Train Loss: 0.3986, Train Acc: 0.7281 - Val Loss: 1.0289, Val Acc: 0.4021\n",
      "Fold 3, Epoch 9/25 - Train Loss: 0.3593, Train Acc: 0.7539 - Val Loss: 1.1150, Val Acc: 0.4227\n",
      "Fold 3, Epoch 10/25 - Train Loss: 0.3458, Train Acc: 0.7784 - Val Loss: 1.3536, Val Acc: 0.4227\n",
      "Fold 3, Epoch 11/25 - Train Loss: 0.3036, Train Acc: 0.7771 - Val Loss: 0.9557, Val Acc: 0.5000\n",
      "Fold 3, Epoch 12/25 - Train Loss: 0.2240, Train Acc: 0.8376 - Val Loss: 0.8849, Val Acc: 0.4639\n",
      "Fold 3, Epoch 13/25 - Train Loss: 0.2194, Train Acc: 0.8415 - Val Loss: 0.8295, Val Acc: 0.5515\n",
      "Fold 3, Epoch 14/25 - Train Loss: 0.1701, Train Acc: 0.8750 - Val Loss: 0.7554, Val Acc: 0.5155\n",
      "Fold 3, Epoch 15/25 - Train Loss: 0.1497, Train Acc: 0.8840 - Val Loss: 0.7844, Val Acc: 0.5515\n",
      "Fold 3, Epoch 16/25 - Train Loss: 0.1020, Train Acc: 0.9111 - Val Loss: 0.8451, Val Acc: 0.5619\n",
      "Fold 3, Epoch 17/25 - Train Loss: 0.1145, Train Acc: 0.9021 - Val Loss: 0.8053, Val Acc: 0.5619\n",
      "Fold 3, Epoch 18/25 - Train Loss: 0.1142, Train Acc: 0.9085 - Val Loss: 0.8427, Val Acc: 0.5619\n",
      "Fold 3, Epoch 19/25 - Train Loss: 0.1231, Train Acc: 0.9111 - Val Loss: 0.8321, Val Acc: 0.5619\n",
      "Fold 3, Epoch 20/25 - Train Loss: 0.0876, Train Acc: 0.9278 - Val Loss: 0.7978, Val Acc: 0.5928\n",
      "Fold 3, Epoch 21/25 - Train Loss: 0.0900, Train Acc: 0.9317 - Val Loss: 0.7628, Val Acc: 0.6031\n",
      "Fold 3, Epoch 22/25 - Train Loss: 0.0724, Train Acc: 0.9433 - Val Loss: 0.8003, Val Acc: 0.5928\n",
      "Fold 3, Epoch 23/25 - Train Loss: 0.0696, Train Acc: 0.9356 - Val Loss: 0.7784, Val Acc: 0.5722\n",
      "Fold 3, Epoch 24/25 - Train Loss: 0.0800, Train Acc: 0.9369 - Val Loss: 0.7631, Val Acc: 0.6031\n",
      "Fold 3, Epoch 25/25 - Train Loss: 0.0626, Train Acc: 0.9510 - Val Loss: 0.7592, Val Acc: 0.5928\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.56      0.38      0.45        13\n",
      "      type-2       0.13      0.11      0.12        18\n",
      "      type-3       0.54      0.58      0.56        65\n",
      "      type-4       0.66      0.74      0.70        65\n",
      "      type-5       0.57      0.50      0.53         8\n",
      "      type-6       0.67      0.50      0.57         8\n",
      "      type-7       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.59       194\n",
      "   macro avg       0.59      0.52      0.55       194\n",
      "weighted avg       0.59      0.59      0.59       194\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 5  2  3  3  0  0  0]\n",
      " [ 3  2  9  2  1  1  0]\n",
      " [ 1  9 38 17  0  0  0]\n",
      " [ 0  0 17 48  0  0  0]\n",
      " [ 0  1  1  1  4  1  0]\n",
      " [ 0  1  0  1  2  4  0]\n",
      " [ 0  0  2  1  0  0 14]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.3846    0.4545        13\n",
      "           1     0.1333    0.1111    0.1212        18\n",
      "           2     0.5429    0.5846    0.5630        65\n",
      "           3     0.6575    0.7385    0.6957        65\n",
      "           4     0.5714    0.5000    0.5333         8\n",
      "           5     0.6667    0.5000    0.5714         8\n",
      "           6     1.0000    0.8235    0.9032        17\n",
      "\n",
      "    accuracy                         0.5928       194\n",
      "   macro avg     0.5896    0.5203    0.5489       194\n",
      "weighted avg     0.5905    0.5928    0.5881       194\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [ 52  74 258 261  31  34  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/25 - Train Loss: 1.3900, Train Acc: 0.2062 - Val Loss: 1.3364, Val Acc: 0.2938\n",
      "Fold 4, Epoch 2/25 - Train Loss: 1.2279, Train Acc: 0.3325 - Val Loss: 1.1436, Val Acc: 0.3969\n",
      "Fold 4, Epoch 3/25 - Train Loss: 0.8911, Train Acc: 0.5477 - Val Loss: 0.8206, Val Acc: 0.4639\n",
      "Fold 4, Epoch 4/25 - Train Loss: 0.5951, Train Acc: 0.6418 - Val Loss: 0.7679, Val Acc: 0.5052\n",
      "Fold 4, Epoch 5/25 - Train Loss: 0.4700, Train Acc: 0.6740 - Val Loss: 0.7459, Val Acc: 0.5000\n",
      "Fold 4, Epoch 6/25 - Train Loss: 0.3926, Train Acc: 0.7384 - Val Loss: 0.7240, Val Acc: 0.4897\n",
      "Fold 4, Epoch 7/25 - Train Loss: 0.4050, Train Acc: 0.7487 - Val Loss: 1.3564, Val Acc: 0.3711\n",
      "Fold 4, Epoch 8/25 - Train Loss: 0.4645, Train Acc: 0.7049 - Val Loss: 0.9451, Val Acc: 0.5361\n",
      "Fold 4, Epoch 9/25 - Train Loss: 0.3793, Train Acc: 0.7539 - Val Loss: 0.8502, Val Acc: 0.5052\n",
      "Fold 4, Epoch 10/25 - Train Loss: 0.3415, Train Acc: 0.7668 - Val Loss: 0.7081, Val Acc: 0.5464\n",
      "Fold 4, Epoch 11/25 - Train Loss: 0.2825, Train Acc: 0.8067 - Val Loss: 0.8220, Val Acc: 0.5258\n",
      "Fold 4, Epoch 12/25 - Train Loss: 0.2666, Train Acc: 0.8041 - Val Loss: 0.7644, Val Acc: 0.5258\n",
      "Fold 4, Epoch 13/25 - Train Loss: 0.2449, Train Acc: 0.8222 - Val Loss: 0.7236, Val Acc: 0.5670\n",
      "Fold 4, Epoch 14/25 - Train Loss: 0.1912, Train Acc: 0.8647 - Val Loss: 0.6707, Val Acc: 0.5567\n",
      "Fold 4, Epoch 15/25 - Train Loss: 0.1568, Train Acc: 0.8840 - Val Loss: 0.8389, Val Acc: 0.5412\n",
      "Fold 4, Epoch 16/25 - Train Loss: 0.1508, Train Acc: 0.8789 - Val Loss: 0.6947, Val Acc: 0.5670\n",
      "Fold 4, Epoch 17/25 - Train Loss: 0.1087, Train Acc: 0.9085 - Val Loss: 0.6440, Val Acc: 0.6031\n",
      "Fold 4, Epoch 18/25 - Train Loss: 0.1150, Train Acc: 0.9046 - Val Loss: 0.6466, Val Acc: 0.6031\n",
      "Fold 4, Epoch 19/25 - Train Loss: 0.0859, Train Acc: 0.9291 - Val Loss: 0.6521, Val Acc: 0.6134\n",
      "Fold 4, Epoch 20/25 - Train Loss: 0.0860, Train Acc: 0.9291 - Val Loss: 0.6729, Val Acc: 0.5979\n",
      "Fold 4, Epoch 21/25 - Train Loss: 0.0755, Train Acc: 0.9407 - Val Loss: 0.7157, Val Acc: 0.5979\n",
      "Fold 4, Epoch 22/25 - Train Loss: 0.0873, Train Acc: 0.9227 - Val Loss: 0.7274, Val Acc: 0.6031\n",
      "Fold 4, Epoch 23/25 - Train Loss: 0.0751, Train Acc: 0.9291 - Val Loss: 0.7433, Val Acc: 0.5825\n",
      "Fold 4, Epoch 24/25 - Train Loss: 0.0703, Train Acc: 0.9369 - Val Loss: 0.7138, Val Acc: 0.5979\n",
      "Fold 4, Epoch 25/25 - Train Loss: 0.0664, Train Acc: 0.9381 - Val Loss: 0.7152, Val Acc: 0.5825\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.55      0.46      0.50        13\n",
      "      type-2       0.29      0.22      0.25        18\n",
      "      type-3       0.55      0.63      0.59        65\n",
      "      type-4       0.66      0.68      0.67        65\n",
      "      type-5       0.60      0.38      0.46         8\n",
      "      type-6       0.67      0.50      0.57         8\n",
      "      type-7       0.65      0.65      0.65        17\n",
      "\n",
      "    accuracy                           0.58       194\n",
      "   macro avg       0.57      0.50      0.53       194\n",
      "weighted avg       0.58      0.58      0.58       194\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 6  3  3  0  0  0  1]\n",
      " [ 2  4  9  1  1  0  1]\n",
      " [ 1  3 41 18  0  1  1]\n",
      " [ 0  2 18 44  0  0  1]\n",
      " [ 1  0  1  2  3  1  0]\n",
      " [ 0  0  0  2  0  4  2]\n",
      " [ 1  2  2  0  1  0 11]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5455    0.4615    0.5000        13\n",
      "           1     0.2857    0.2222    0.2500        18\n",
      "           2     0.5541    0.6308    0.5899        65\n",
      "           3     0.6567    0.6769    0.6667        65\n",
      "           4     0.6000    0.3750    0.4615         8\n",
      "           5     0.6667    0.5000    0.5714         8\n",
      "           6     0.6471    0.6471    0.6471        17\n",
      "\n",
      "    accuracy                         0.5825       194\n",
      "   macro avg     0.5651    0.5019    0.5267       194\n",
      "weighted avg     0.5777    0.5825    0.5770       194\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [ 52  74 258 261  31  34  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/25 - Train Loss: 1.3950, Train Acc: 0.2165 - Val Loss: 1.4098, Val Acc: 0.1701\n",
      "Fold 5, Epoch 2/25 - Train Loss: 1.1728, Train Acc: 0.3918 - Val Loss: 1.1307, Val Acc: 0.2938\n",
      "Fold 5, Epoch 3/25 - Train Loss: 0.8415, Train Acc: 0.5374 - Val Loss: 0.7345, Val Acc: 0.4742\n",
      "Fold 5, Epoch 4/25 - Train Loss: 0.5415, Train Acc: 0.6817 - Val Loss: 0.7465, Val Acc: 0.5000\n",
      "Fold 5, Epoch 5/25 - Train Loss: 0.4403, Train Acc: 0.7229 - Val Loss: 0.8767, Val Acc: 0.5052\n",
      "Fold 5, Epoch 6/25 - Train Loss: 0.4470, Train Acc: 0.7139 - Val Loss: 0.8672, Val Acc: 0.4691\n",
      "Fold 5, Epoch 7/25 - Train Loss: 0.3846, Train Acc: 0.7513 - Val Loss: 0.8845, Val Acc: 0.5567\n",
      "Fold 5, Epoch 8/25 - Train Loss: 0.3884, Train Acc: 0.7526 - Val Loss: 0.8226, Val Acc: 0.5309\n",
      "Fold 5, Epoch 9/25 - Train Loss: 0.3648, Train Acc: 0.7307 - Val Loss: 0.7887, Val Acc: 0.5258\n",
      "Fold 5, Epoch 10/25 - Train Loss: 0.3075, Train Acc: 0.7835 - Val Loss: 0.8836, Val Acc: 0.5309\n",
      "Fold 5, Epoch 11/25 - Train Loss: 0.2728, Train Acc: 0.8080 - Val Loss: 0.9590, Val Acc: 0.4845\n",
      "Fold 5, Epoch 12/25 - Train Loss: 0.2087, Train Acc: 0.8492 - Val Loss: 0.9602, Val Acc: 0.4897\n",
      "Fold 5, Epoch 13/25 - Train Loss: 0.1936, Train Acc: 0.8557 - Val Loss: 0.9019, Val Acc: 0.5619\n",
      "Fold 5, Epoch 14/25 - Train Loss: 0.2301, Train Acc: 0.8389 - Val Loss: 0.8648, Val Acc: 0.5567\n",
      "Fold 5, Epoch 15/25 - Train Loss: 0.1885, Train Acc: 0.8557 - Val Loss: 0.9252, Val Acc: 0.5412\n",
      "Fold 5, Epoch 16/25 - Train Loss: 0.1503, Train Acc: 0.8686 - Val Loss: 0.9010, Val Acc: 0.5670\n",
      "Fold 5, Epoch 17/25 - Train Loss: 0.1168, Train Acc: 0.9175 - Val Loss: 0.8295, Val Acc: 0.5722\n",
      "Fold 5, Epoch 18/25 - Train Loss: 0.0971, Train Acc: 0.9343 - Val Loss: 0.7759, Val Acc: 0.5979\n",
      "Fold 5, Epoch 19/25 - Train Loss: 0.1055, Train Acc: 0.9175 - Val Loss: 0.7954, Val Acc: 0.6082\n",
      "Fold 5, Epoch 20/25 - Train Loss: 0.0824, Train Acc: 0.9381 - Val Loss: 0.8386, Val Acc: 0.5619\n",
      "Fold 5, Epoch 21/25 - Train Loss: 0.0701, Train Acc: 0.9343 - Val Loss: 0.8769, Val Acc: 0.5773\n",
      "Fold 5, Epoch 22/25 - Train Loss: 0.0807, Train Acc: 0.9343 - Val Loss: 0.8568, Val Acc: 0.5670\n",
      "Fold 5, Epoch 23/25 - Train Loss: 0.0773, Train Acc: 0.9356 - Val Loss: 0.8471, Val Acc: 0.5876\n",
      "Fold 5, Epoch 24/25 - Train Loss: 0.0759, Train Acc: 0.9446 - Val Loss: 0.8459, Val Acc: 0.5773\n",
      "Fold 5, Epoch 25/25 - Train Loss: 0.0808, Train Acc: 0.9420 - Val Loss: 0.8516, Val Acc: 0.5773\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.69      0.69      0.69        13\n",
      "      type-2       0.33      0.22      0.27        18\n",
      "      type-3       0.53      0.57      0.55        65\n",
      "      type-4       0.61      0.71      0.65        65\n",
      "      type-5       0.25      0.12      0.17         8\n",
      "      type-6       0.50      0.12      0.20         8\n",
      "      type-7       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.58       194\n",
      "   macro avg       0.53      0.47      0.48       194\n",
      "weighted avg       0.56      0.58      0.56       194\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 9  3  1  0  0  0  0]\n",
      " [ 2  4 11  1  0  0  0]\n",
      " [ 0  2 37 25  1  0  0]\n",
      " [ 0  2 17 46  0  0  0]\n",
      " [ 1  1  2  2  1  0  1]\n",
      " [ 0  0  1  2  2  1  2]\n",
      " [ 1  0  1  0  0  1 14]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.6923    0.6923        13\n",
      "           1     0.3333    0.2222    0.2667        18\n",
      "           2     0.5286    0.5692    0.5481        65\n",
      "           3     0.6053    0.7077    0.6525        65\n",
      "           4     0.2500    0.1250    0.1667         8\n",
      "           5     0.5000    0.1250    0.2000         8\n",
      "           6     0.8235    0.8235    0.8235        17\n",
      "\n",
      "    accuracy                         0.5773       194\n",
      "   macro avg     0.5333    0.4664    0.4785       194\n",
      "weighted avg     0.5603    0.5773    0.5607       194\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.6185567010309279, 0.6185567010309279, 0.6030927835051546, 0.6134020618556701, 0.6082474226804123]]\n",
      "['Mean Accuracy:', np.float64(0.6123711340206186)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=25,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    seed=4,\n",
    "    num_classes=7,\n",
    "    use_stratified_kfold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dc70d",
   "metadata": {},
   "source": [
    "# Old Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/25 - Train Loss: 1.3894, Train Acc: 0.1985 - Val Loss: 1.3430, Val Acc: 0.2938\n",
      "Fold 1, Epoch 2/25 - Train Loss: 1.3055, Train Acc: 0.3041 - Val Loss: 1.2449, Val Acc: 0.3918\n",
      "Fold 1, Epoch 3/25 - Train Loss: 1.1855, Train Acc: 0.3814 - Val Loss: 1.1397, Val Acc: 0.4639\n",
      "Fold 1, Epoch 4/25 - Train Loss: 1.0984, Train Acc: 0.4446 - Val Loss: 1.0660, Val Acc: 0.4536\n",
      "Fold 1, Epoch 5/25 - Train Loss: 1.0050, Train Acc: 0.5013 - Val Loss: 1.0056, Val Acc: 0.4691\n",
      "Fold 1, Epoch 6/25 - Train Loss: 0.9427, Train Acc: 0.5155 - Val Loss: 0.9152, Val Acc: 0.4691\n",
      "Fold 1, Epoch 7/25 - Train Loss: 0.8515, Train Acc: 0.5451 - Val Loss: 0.8592, Val Acc: 0.4330\n",
      "Fold 1, Epoch 8/25 - Train Loss: 0.7587, Train Acc: 0.5851 - Val Loss: 0.7459, Val Acc: 0.5309\n",
      "Fold 1, Epoch 9/25 - Train Loss: 0.6569, Train Acc: 0.6469 - Val Loss: 0.7472, Val Acc: 0.5361\n",
      "Fold 1, Epoch 10/25 - Train Loss: 0.5770, Train Acc: 0.6856 - Val Loss: 0.7018, Val Acc: 0.5206\n",
      "Fold 1, Epoch 11/25 - Train Loss: 0.5606, Train Acc: 0.6714 - Val Loss: 0.6128, Val Acc: 0.5258\n",
      "Fold 1, Epoch 12/25 - Train Loss: 0.4787, Train Acc: 0.7062 - Val Loss: 0.6088, Val Acc: 0.5979\n",
      "Fold 1, Epoch 13/25 - Train Loss: 0.4702, Train Acc: 0.7088 - Val Loss: 0.5792, Val Acc: 0.5722\n",
      "Fold 1, Epoch 14/25 - Train Loss: 0.4466, Train Acc: 0.7320 - Val Loss: 0.5777, Val Acc: 0.5567\n",
      "Fold 1, Epoch 15/25 - Train Loss: 0.4110, Train Acc: 0.7204 - Val Loss: 0.5718, Val Acc: 0.5773\n",
      "Fold 1, Epoch 16/25 - Train Loss: 0.3842, Train Acc: 0.7680 - Val Loss: 0.5601, Val Acc: 0.5928\n",
      "Fold 1, Epoch 17/25 - Train Loss: 0.3558, Train Acc: 0.7874 - Val Loss: 0.5341, Val Acc: 0.5773\n",
      "Fold 1, Epoch 18/25 - Train Loss: 0.3500, Train Acc: 0.7680 - Val Loss: 0.5120, Val Acc: 0.5773\n",
      "Fold 1, Epoch 19/25 - Train Loss: 0.3058, Train Acc: 0.8015 - Val Loss: 0.5336, Val Acc: 0.5773\n",
      "Fold 1, Epoch 20/25 - Train Loss: 0.2921, Train Acc: 0.8028 - Val Loss: 0.5476, Val Acc: 0.5825\n",
      "Fold 1, Epoch 21/25 - Train Loss: 0.2494, Train Acc: 0.8196 - Val Loss: 0.5439, Val Acc: 0.6134\n",
      "Fold 1, Epoch 22/25 - Train Loss: 0.2371, Train Acc: 0.8260 - Val Loss: 0.5108, Val Acc: 0.6031\n",
      "Fold 1, Epoch 23/25 - Train Loss: 0.2326, Train Acc: 0.8466 - Val Loss: 0.5016, Val Acc: 0.5722\n",
      "Fold 1, Epoch 24/25 - Train Loss: 0.2318, Train Acc: 0.8363 - Val Loss: 0.5452, Val Acc: 0.5773\n",
      "Fold 1, Epoch 25/25 - Train Loss: 0.2223, Train Acc: 0.8415 - Val Loss: 0.5488, Val Acc: 0.5979\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.35      1.00      0.52         6\n",
      "      type-2       0.33      0.22      0.26        23\n",
      "      type-3       0.59      0.53      0.56        70\n",
      "      type-4       0.65      0.66      0.65        70\n",
      "      type-5       0.33      0.17      0.22         6\n",
      "      type-6       0.40      0.40      0.40         5\n",
      "      type-7       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.57       194\n",
      "   macro avg       0.48      0.57      0.49       194\n",
      "weighted avg       0.57      0.57      0.56       194\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 6  0  0  0  0  0  0]\n",
      " [ 7  5  8  1  1  0  1]\n",
      " [ 3  6 37 22  1  0  1]\n",
      " [ 1  4 18 46  0  0  1]\n",
      " [ 0  0  0  2  1  3  0]\n",
      " [ 0  0  0  0  0  2  3]\n",
      " [ 0  0  0  0  0  0 14]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3529    1.0000    0.5217         6\n",
      "           1     0.3333    0.2174    0.2632        23\n",
      "           2     0.5873    0.5286    0.5564        70\n",
      "           3     0.6479    0.6571    0.6525        70\n",
      "           4     0.3333    0.1667    0.2222         6\n",
      "           5     0.4000    0.4000    0.4000         5\n",
      "           6     0.7000    1.0000    0.8235        14\n",
      "\n",
      "    accuracy                         0.5722       194\n",
      "   macro avg     0.4793    0.5671    0.4914       194\n",
      "weighted avg     0.5673    0.5722    0.5601       194\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/25 - Train Loss: 1.3934, Train Acc: 0.1946 - Val Loss: 1.3612, Val Acc: 0.2113\n",
      "Fold 2, Epoch 2/25 - Train Loss: 1.2941, Train Acc: 0.3222 - Val Loss: 1.3038, Val Acc: 0.3144\n",
      "Fold 2, Epoch 3/25 - Train Loss: 1.1913, Train Acc: 0.3737 - Val Loss: 1.2145, Val Acc: 0.3402\n",
      "Fold 2, Epoch 4/25 - Train Loss: 1.0722, Train Acc: 0.4704 - Val Loss: 1.1349, Val Acc: 0.3763\n",
      "Fold 2, Epoch 5/25 - Train Loss: 0.9851, Train Acc: 0.4897 - Val Loss: 1.0708, Val Acc: 0.4124\n",
      "Fold 2, Epoch 6/25 - Train Loss: 0.8655, Train Acc: 0.5464 - Val Loss: 0.9729, Val Acc: 0.4227\n",
      "Fold 2, Epoch 7/25 - Train Loss: 0.7838, Train Acc: 0.5799 - Val Loss: 0.8844, Val Acc: 0.4433\n",
      "Fold 2, Epoch 8/25 - Train Loss: 0.7271, Train Acc: 0.5941 - Val Loss: 0.8369, Val Acc: 0.5000\n",
      "Fold 2, Epoch 9/25 - Train Loss: 0.5993, Train Acc: 0.6856 - Val Loss: 0.8093, Val Acc: 0.4845\n",
      "Fold 2, Epoch 10/25 - Train Loss: 0.5646, Train Acc: 0.6572 - Val Loss: 0.7392, Val Acc: 0.5155\n",
      "Fold 2, Epoch 11/25 - Train Loss: 0.5343, Train Acc: 0.6894 - Val Loss: 0.7392, Val Acc: 0.5309\n",
      "Fold 2, Epoch 12/25 - Train Loss: 0.4574, Train Acc: 0.7268 - Val Loss: 0.7156, Val Acc: 0.5258\n",
      "Fold 2, Epoch 13/25 - Train Loss: 0.4165, Train Acc: 0.7448 - Val Loss: 0.7144, Val Acc: 0.5515\n",
      "Fold 2, Epoch 14/25 - Train Loss: 0.3891, Train Acc: 0.7771 - Val Loss: 0.7071, Val Acc: 0.5412\n",
      "Fold 2, Epoch 15/25 - Train Loss: 0.3770, Train Acc: 0.7668 - Val Loss: 0.6876, Val Acc: 0.5052\n",
      "Fold 2, Epoch 16/25 - Train Loss: 0.3480, Train Acc: 0.7758 - Val Loss: 0.6560, Val Acc: 0.5619\n",
      "Fold 2, Epoch 17/25 - Train Loss: 0.3258, Train Acc: 0.7874 - Val Loss: 0.6720, Val Acc: 0.5567\n",
      "Fold 2, Epoch 18/25 - Train Loss: 0.3250, Train Acc: 0.7848 - Val Loss: 0.6770, Val Acc: 0.5567\n",
      "Fold 2, Epoch 19/25 - Train Loss: 0.2662, Train Acc: 0.8209 - Val Loss: 0.6478, Val Acc: 0.5825\n",
      "Fold 2, Epoch 20/25 - Train Loss: 0.2850, Train Acc: 0.8054 - Val Loss: 0.6282, Val Acc: 0.5722\n",
      "Fold 2, Epoch 21/25 - Train Loss: 0.2429, Train Acc: 0.8363 - Val Loss: 0.6389, Val Acc: 0.5670\n",
      "Fold 2, Epoch 22/25 - Train Loss: 0.2108, Train Acc: 0.8454 - Val Loss: 0.6437, Val Acc: 0.5619\n",
      "Fold 2, Epoch 23/25 - Train Loss: 0.2437, Train Acc: 0.8312 - Val Loss: 0.6101, Val Acc: 0.5773\n",
      "Fold 2, Epoch 24/25 - Train Loss: 0.2016, Train Acc: 0.8608 - Val Loss: 0.6291, Val Acc: 0.5722\n",
      "Fold 2, Epoch 25/25 - Train Loss: 0.1962, Train Acc: 0.8505 - Val Loss: 0.6478, Val Acc: 0.5464\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.64      0.64      0.64        14\n",
      "      type-2       0.22      0.33      0.26        15\n",
      "      type-3       0.53      0.48      0.50        64\n",
      "      type-4       0.69      0.69      0.69        64\n",
      "      type-5       0.67      0.40      0.50        10\n",
      "      type-6       0.56      0.56      0.56         9\n",
      "      type-7       0.74      0.78      0.76        18\n",
      "\n",
      "    accuracy                           0.58       194\n",
      "   macro avg       0.58      0.55      0.56       194\n",
      "weighted avg       0.59      0.58      0.58       194\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 9  1  3  0  0  0  1]\n",
      " [ 2  5  6  1  0  0  1]\n",
      " [ 2 12 31 16  0  1  2]\n",
      " [ 1  3 16 44  0  0  0]\n",
      " [ 0  1  2  2  4  0  1]\n",
      " [ 0  0  1  1  2  5  0]\n",
      " [ 0  1  0  0  0  3 14]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6429    0.6429    0.6429        14\n",
      "           1     0.2174    0.3333    0.2632        15\n",
      "           2     0.5254    0.4844    0.5041        64\n",
      "           3     0.6875    0.6875    0.6875        64\n",
      "           4     0.6667    0.4000    0.5000        10\n",
      "           5     0.5556    0.5556    0.5556         9\n",
      "           6     0.7368    0.7778    0.7568        18\n",
      "\n",
      "    accuracy                         0.5773       194\n",
      "   macro avg     0.5760    0.5545    0.5586       194\n",
      "weighted avg     0.5918    0.5773    0.5816       194\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/25 - Train Loss: 1.4076, Train Acc: 0.1869 - Val Loss: 1.3993, Val Acc: 0.2113\n",
      "Fold 3, Epoch 2/25 - Train Loss: 1.3135, Train Acc: 0.2887 - Val Loss: 1.3324, Val Acc: 0.2577\n",
      "Fold 3, Epoch 3/25 - Train Loss: 1.2205, Train Acc: 0.3570 - Val Loss: 1.2609, Val Acc: 0.2990\n",
      "Fold 3, Epoch 4/25 - Train Loss: 1.1191, Train Acc: 0.4472 - Val Loss: 1.1531, Val Acc: 0.3711\n",
      "Fold 3, Epoch 5/25 - Train Loss: 1.0145, Train Acc: 0.4678 - Val Loss: 1.0613, Val Acc: 0.4588\n",
      "Fold 3, Epoch 6/25 - Train Loss: 0.9063, Train Acc: 0.5438 - Val Loss: 0.9748, Val Acc: 0.4845\n",
      "Fold 3, Epoch 7/25 - Train Loss: 0.8154, Train Acc: 0.5593 - Val Loss: 0.8847, Val Acc: 0.5155\n",
      "Fold 3, Epoch 8/25 - Train Loss: 0.7218, Train Acc: 0.5992 - Val Loss: 0.8389, Val Acc: 0.5052\n",
      "Fold 3, Epoch 9/25 - Train Loss: 0.6774, Train Acc: 0.6211 - Val Loss: 0.7805, Val Acc: 0.5619\n",
      "Fold 3, Epoch 10/25 - Train Loss: 0.5490, Train Acc: 0.6946 - Val Loss: 0.7393, Val Acc: 0.5206\n",
      "Fold 3, Epoch 11/25 - Train Loss: 0.5316, Train Acc: 0.6946 - Val Loss: 0.7700, Val Acc: 0.5000\n",
      "Fold 3, Epoch 12/25 - Train Loss: 0.4628, Train Acc: 0.7268 - Val Loss: 0.7448, Val Acc: 0.5258\n",
      "Fold 3, Epoch 13/25 - Train Loss: 0.4462, Train Acc: 0.7113 - Val Loss: 0.7418, Val Acc: 0.5103\n",
      "Fold 3, Epoch 14/25 - Train Loss: 0.4396, Train Acc: 0.7294 - Val Loss: 0.6841, Val Acc: 0.5361\n",
      "Fold 3, Epoch 15/25 - Train Loss: 0.3405, Train Acc: 0.7835 - Val Loss: 0.7109, Val Acc: 0.5309\n",
      "Fold 3, Epoch 16/25 - Train Loss: 0.3407, Train Acc: 0.7693 - Val Loss: 0.6778, Val Acc: 0.5155\n",
      "Fold 3, Epoch 17/25 - Train Loss: 0.3224, Train Acc: 0.7990 - Val Loss: 0.6617, Val Acc: 0.5309\n",
      "Fold 3, Epoch 18/25 - Train Loss: 0.2893, Train Acc: 0.8312 - Val Loss: 0.6831, Val Acc: 0.5309\n",
      "Fold 3, Epoch 19/25 - Train Loss: 0.2768, Train Acc: 0.8054 - Val Loss: 0.6560, Val Acc: 0.5412\n",
      "Fold 3, Epoch 20/25 - Train Loss: 0.2568, Train Acc: 0.8402 - Val Loss: 0.6957, Val Acc: 0.5258\n",
      "Fold 3, Epoch 21/25 - Train Loss: 0.2532, Train Acc: 0.8157 - Val Loss: 0.6354, Val Acc: 0.5567\n",
      "Fold 3, Epoch 22/25 - Train Loss: 0.2429, Train Acc: 0.8235 - Val Loss: 0.6517, Val Acc: 0.5000\n",
      "Fold 3, Epoch 23/25 - Train Loss: 0.2157, Train Acc: 0.8531 - Val Loss: 0.6297, Val Acc: 0.5567\n",
      "Fold 3, Epoch 24/25 - Train Loss: 0.2393, Train Acc: 0.8376 - Val Loss: 0.6756, Val Acc: 0.5258\n",
      "Fold 3, Epoch 25/25 - Train Loss: 0.2001, Train Acc: 0.8570 - Val Loss: 0.6583, Val Acc: 0.5361\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.45      0.36      0.40        14\n",
      "      type-2       0.16      0.21      0.18        19\n",
      "      type-3       0.52      0.54      0.53        68\n",
      "      type-4       0.63      0.66      0.64        56\n",
      "      type-5       0.83      0.56      0.67         9\n",
      "      type-6       1.00      0.89      0.94         9\n",
      "      type-7       0.86      0.63      0.73        19\n",
      "\n",
      "    accuracy                           0.56       194\n",
      "   macro avg       0.64      0.55      0.58       194\n",
      "weighted avg       0.58      0.56      0.56       194\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 5  5  3  0  0  0  1]\n",
      " [ 2  4  9  3  0  0  1]\n",
      " [ 1 13 37 16  1  0  0]\n",
      " [ 0  2 17 37  0  0  0]\n",
      " [ 2  0  0  2  5  0  0]\n",
      " [ 0  0  0  1  0  8  0]\n",
      " [ 1  1  5  0  0  0 12]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4545    0.3571    0.4000        14\n",
      "           1     0.1600    0.2105    0.1818        19\n",
      "           2     0.5211    0.5441    0.5324        68\n",
      "           3     0.6271    0.6607    0.6435        56\n",
      "           4     0.8333    0.5556    0.6667         9\n",
      "           5     1.0000    0.8889    0.9412         9\n",
      "           6     0.8571    0.6316    0.7273        19\n",
      "\n",
      "    accuracy                         0.5567       194\n",
      "   macro avg     0.6362    0.5498    0.5847       194\n",
      "weighted avg     0.5812    0.5567    0.5648       194\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/25 - Train Loss: 1.4073, Train Acc: 0.1830 - Val Loss: 1.3746, Val Acc: 0.2371\n",
      "Fold 4, Epoch 2/25 - Train Loss: 1.3196, Train Acc: 0.3080 - Val Loss: 1.2966, Val Acc: 0.3041\n",
      "Fold 4, Epoch 3/25 - Train Loss: 1.2162, Train Acc: 0.3943 - Val Loss: 1.2038, Val Acc: 0.3969\n",
      "Fold 4, Epoch 4/25 - Train Loss: 1.1193, Train Acc: 0.4291 - Val Loss: 1.1063, Val Acc: 0.4639\n",
      "Fold 4, Epoch 5/25 - Train Loss: 1.0135, Train Acc: 0.5103 - Val Loss: 0.9974, Val Acc: 0.5206\n",
      "Fold 4, Epoch 6/25 - Train Loss: 0.9175, Train Acc: 0.5322 - Val Loss: 0.9172, Val Acc: 0.5103\n",
      "Fold 4, Epoch 7/25 - Train Loss: 0.7946, Train Acc: 0.5644 - Val Loss: 0.8448, Val Acc: 0.5103\n",
      "Fold 4, Epoch 8/25 - Train Loss: 0.7251, Train Acc: 0.6044 - Val Loss: 0.7895, Val Acc: 0.5000\n",
      "Fold 4, Epoch 9/25 - Train Loss: 0.6530, Train Acc: 0.6198 - Val Loss: 0.7279, Val Acc: 0.5309\n",
      "Fold 4, Epoch 10/25 - Train Loss: 0.6013, Train Acc: 0.6637 - Val Loss: 0.7492, Val Acc: 0.5155\n",
      "Fold 4, Epoch 11/25 - Train Loss: 0.4801, Train Acc: 0.7113 - Val Loss: 0.6995, Val Acc: 0.5309\n",
      "Fold 4, Epoch 12/25 - Train Loss: 0.4908, Train Acc: 0.7126 - Val Loss: 0.6472, Val Acc: 0.5361\n",
      "Fold 4, Epoch 13/25 - Train Loss: 0.4396, Train Acc: 0.7229 - Val Loss: 0.6852, Val Acc: 0.5464\n",
      "Fold 4, Epoch 14/25 - Train Loss: 0.4034, Train Acc: 0.7448 - Val Loss: 0.6313, Val Acc: 0.5567\n",
      "Fold 4, Epoch 15/25 - Train Loss: 0.3565, Train Acc: 0.7474 - Val Loss: 0.6431, Val Acc: 0.5567\n",
      "Fold 4, Epoch 16/25 - Train Loss: 0.3412, Train Acc: 0.7577 - Val Loss: 0.6292, Val Acc: 0.5670\n",
      "Fold 4, Epoch 17/25 - Train Loss: 0.3358, Train Acc: 0.7784 - Val Loss: 0.6152, Val Acc: 0.5773\n",
      "Fold 4, Epoch 18/25 - Train Loss: 0.3267, Train Acc: 0.7951 - Val Loss: 0.6195, Val Acc: 0.5876\n",
      "Fold 4, Epoch 19/25 - Train Loss: 0.2811, Train Acc: 0.8041 - Val Loss: 0.6259, Val Acc: 0.5876\n",
      "Fold 4, Epoch 20/25 - Train Loss: 0.2481, Train Acc: 0.8312 - Val Loss: 0.6346, Val Acc: 0.5567\n",
      "Fold 4, Epoch 21/25 - Train Loss: 0.2660, Train Acc: 0.8067 - Val Loss: 0.6533, Val Acc: 0.5619\n",
      "Fold 4, Epoch 22/25 - Train Loss: 0.2509, Train Acc: 0.8428 - Val Loss: 0.6453, Val Acc: 0.5670\n",
      "Fold 4, Epoch 23/25 - Train Loss: 0.2319, Train Acc: 0.8428 - Val Loss: 0.6489, Val Acc: 0.5515\n",
      "Fold 4, Epoch 24/25 - Train Loss: 0.2059, Train Acc: 0.8557 - Val Loss: 0.6264, Val Acc: 0.5670\n",
      "Fold 4, Epoch 25/25 - Train Loss: 0.2190, Train Acc: 0.8441 - Val Loss: 0.6429, Val Acc: 0.5825\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.48      0.77      0.59        13\n",
      "      type-2       0.26      0.26      0.26        19\n",
      "      type-3       0.57      0.47      0.51        64\n",
      "      type-4       0.72      0.72      0.72        61\n",
      "      type-5       0.36      0.44      0.40         9\n",
      "      type-6       0.57      0.67      0.62        12\n",
      "      type-7       0.73      0.69      0.71        16\n",
      "\n",
      "    accuracy                           0.58       194\n",
      "   macro avg       0.53      0.57      0.54       194\n",
      "weighted avg       0.58      0.58      0.58       194\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[10  1  1  0  0  0  1]\n",
      " [ 4  5  5  1  2  0  2]\n",
      " [ 4 11 30 15  2  2  0]\n",
      " [ 0  0 13 44  2  1  1]\n",
      " [ 1  1  1  1  4  1  0]\n",
      " [ 0  0  3  0  1  8  0]\n",
      " [ 2  1  0  0  0  2 11]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4762    0.7692    0.5882        13\n",
      "           1     0.2632    0.2632    0.2632        19\n",
      "           2     0.5660    0.4688    0.5128        64\n",
      "           3     0.7213    0.7213    0.7213        61\n",
      "           4     0.3636    0.4444    0.4000         9\n",
      "           5     0.5714    0.6667    0.6154        12\n",
      "           6     0.7333    0.6875    0.7097        16\n",
      "\n",
      "    accuracy                         0.5773       194\n",
      "   macro avg     0.5279    0.5744    0.5444       194\n",
      "weighted avg     0.5839    0.5773    0.5763       194\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/25 - Train Loss: 1.4184, Train Acc: 0.1585 - Val Loss: 1.3740, Val Acc: 0.2887\n",
      "Fold 5, Epoch 2/25 - Train Loss: 1.2942, Train Acc: 0.3273 - Val Loss: 1.2893, Val Acc: 0.3866\n",
      "Fold 5, Epoch 3/25 - Train Loss: 1.2058, Train Acc: 0.4046 - Val Loss: 1.2039, Val Acc: 0.4639\n",
      "Fold 5, Epoch 4/25 - Train Loss: 1.1240, Train Acc: 0.4227 - Val Loss: 1.1243, Val Acc: 0.4536\n",
      "Fold 5, Epoch 5/25 - Train Loss: 1.0163, Train Acc: 0.4884 - Val Loss: 1.0244, Val Acc: 0.5309\n",
      "Fold 5, Epoch 6/25 - Train Loss: 0.9089, Train Acc: 0.5284 - Val Loss: 0.9524, Val Acc: 0.5103\n",
      "Fold 5, Epoch 7/25 - Train Loss: 0.8012, Train Acc: 0.6005 - Val Loss: 0.8396, Val Acc: 0.5515\n",
      "Fold 5, Epoch 8/25 - Train Loss: 0.7174, Train Acc: 0.6095 - Val Loss: 0.7604, Val Acc: 0.5619\n",
      "Fold 5, Epoch 9/25 - Train Loss: 0.6712, Train Acc: 0.6044 - Val Loss: 0.7484, Val Acc: 0.5876\n",
      "Fold 5, Epoch 10/25 - Train Loss: 0.5882, Train Acc: 0.6546 - Val Loss: 0.7024, Val Acc: 0.5876\n",
      "Fold 5, Epoch 11/25 - Train Loss: 0.5402, Train Acc: 0.6791 - Val Loss: 0.6649, Val Acc: 0.6031\n",
      "Fold 5, Epoch 12/25 - Train Loss: 0.5072, Train Acc: 0.6920 - Val Loss: 0.6225, Val Acc: 0.6031\n",
      "Fold 5, Epoch 13/25 - Train Loss: 0.4594, Train Acc: 0.7294 - Val Loss: 0.6016, Val Acc: 0.6186\n",
      "Fold 5, Epoch 14/25 - Train Loss: 0.3782, Train Acc: 0.7680 - Val Loss: 0.5884, Val Acc: 0.6082\n",
      "Fold 5, Epoch 15/25 - Train Loss: 0.3498, Train Acc: 0.7887 - Val Loss: 0.6418, Val Acc: 0.5825\n",
      "Fold 5, Epoch 16/25 - Train Loss: 0.3575, Train Acc: 0.7629 - Val Loss: 0.5857, Val Acc: 0.6082\n",
      "Fold 5, Epoch 17/25 - Train Loss: 0.3345, Train Acc: 0.7732 - Val Loss: 0.5876, Val Acc: 0.6392\n",
      "Fold 5, Epoch 18/25 - Train Loss: 0.2805, Train Acc: 0.8402 - Val Loss: 0.5791, Val Acc: 0.6134\n",
      "Fold 5, Epoch 19/25 - Train Loss: 0.2616, Train Acc: 0.8209 - Val Loss: 0.5584, Val Acc: 0.6134\n",
      "Fold 5, Epoch 20/25 - Train Loss: 0.2555, Train Acc: 0.8119 - Val Loss: 0.5619, Val Acc: 0.6134\n",
      "Fold 5, Epoch 21/25 - Train Loss: 0.2480, Train Acc: 0.8183 - Val Loss: 0.5960, Val Acc: 0.6031\n",
      "Fold 5, Epoch 22/25 - Train Loss: 0.2279, Train Acc: 0.8428 - Val Loss: 0.5822, Val Acc: 0.6082\n",
      "Fold 5, Epoch 23/25 - Train Loss: 0.2232, Train Acc: 0.8428 - Val Loss: 0.5549, Val Acc: 0.6392\n",
      "Fold 5, Epoch 24/25 - Train Loss: 0.2047, Train Acc: 0.8479 - Val Loss: 0.5845, Val Acc: 0.6237\n",
      "Fold 5, Epoch 25/25 - Train Loss: 0.2007, Train Acc: 0.8531 - Val Loss: 0.5811, Val Acc: 0.6340\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.68      0.72      0.70        18\n",
      "      type-2       0.19      0.19      0.19        16\n",
      "      type-3       0.53      0.51      0.52        57\n",
      "      type-4       0.77      0.83      0.79        75\n",
      "      type-5       0.33      0.20      0.25         5\n",
      "      type-6       0.60      0.43      0.50         7\n",
      "      type-7       0.87      0.81      0.84        16\n",
      "\n",
      "    accuracy                           0.64       194\n",
      "   macro avg       0.57      0.53      0.54       194\n",
      "weighted avg       0.63      0.64      0.63       194\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[13  2  2  1  0  0  0]\n",
      " [ 2  3  9  1  1  0  0]\n",
      " [ 1 10 29 14  0  1  2]\n",
      " [ 0  1 11 62  0  1  0]\n",
      " [ 2  0  1  1  1  0  0]\n",
      " [ 0  0  1  2  1  3  0]\n",
      " [ 1  0  2  0  0  0 13]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6842    0.7222    0.7027        18\n",
      "           1     0.1875    0.1875    0.1875        16\n",
      "           2     0.5273    0.5088    0.5179        57\n",
      "           3     0.7654    0.8267    0.7949        75\n",
      "           4     0.3333    0.2000    0.2500         5\n",
      "           5     0.6000    0.4286    0.5000         7\n",
      "           6     0.8667    0.8125    0.8387        16\n",
      "\n",
      "    accuracy                         0.6392       194\n",
      "   macro avg     0.5663    0.5266    0.5417       194\n",
      "weighted avg     0.6315    0.6392    0.6338       194\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.5721649484536082, 0.5773195876288659, 0.5567010309278351, 0.5773195876288659, 0.6391752577319587]]\n",
      "['Mean Accuracy:', np.float64(0.5845360824742267)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b3',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=25,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=16,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    seed=4,\n",
    "    num_classes=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4979a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [ 85 110 270 263  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 1.3483, Train Acc: 0.2779 - Val Loss: 1.2287, Val Acc: 0.3116\n",
      "Fold None, Epoch 2/15 - Train Loss: 1.1277, Train Acc: 0.3791 - Val Loss: 0.9899, Val Acc: 0.4093\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.9610, Train Acc: 0.4767 - Val Loss: 0.8523, Val Acc: 0.4512\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.7984, Train Acc: 0.5744 - Val Loss: 0.7394, Val Acc: 0.5302\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.6748, Train Acc: 0.6081 - Val Loss: 0.6649, Val Acc: 0.5488\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.5889, Train Acc: 0.6500 - Val Loss: 0.6483, Val Acc: 0.5628\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.5455, Train Acc: 0.6721 - Val Loss: 0.6470, Val Acc: 0.5395\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.4737, Train Acc: 0.7012 - Val Loss: 0.6112, Val Acc: 0.5814\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.4449, Train Acc: 0.7174 - Val Loss: 0.5528, Val Acc: 0.6279\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.3791, Train Acc: 0.7337 - Val Loss: 0.5617, Val Acc: 0.6140\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.3302, Train Acc: 0.7895 - Val Loss: 0.5432, Val Acc: 0.6093\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.3167, Train Acc: 0.7640 - Val Loss: 0.5318, Val Acc: 0.6419\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.2800, Train Acc: 0.7977 - Val Loss: 0.5164, Val Acc: 0.6558\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.2485, Train Acc: 0.8233 - Val Loss: 0.5233, Val Acc: 0.6512\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.2725, Train Acc: 0.8128 - Val Loss: 0.5209, Val Acc: 0.6465\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.60      0.86      0.71        21\n",
      "      type-2       0.59      0.57      0.58        28\n",
      "      type-3       0.62      0.60      0.61        68\n",
      "      type-4       0.70      0.65      0.67        65\n",
      "      type-5       0.67      0.50      0.57         8\n",
      "      type-6       0.71      0.62      0.67         8\n",
      "      type-7       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.67      0.67      0.66       215\n",
      "weighted avg       0.66      0.66      0.65       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[18  1  0  0  0  0  2]\n",
      " [ 6 16  4  1  0  0  1]\n",
      " [ 3  6 41 17  0  0  1]\n",
      " [ 2  2 18 42  1  0  0]\n",
      " [ 0  0  2  0  4  2  0]\n",
      " [ 0  1  1  0  1  5  0]\n",
      " [ 1  1  0  0  0  0 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.8571    0.7059        21\n",
      "           1     0.5926    0.5714    0.5818        28\n",
      "           2     0.6212    0.6029    0.6119        68\n",
      "           3     0.7000    0.6462    0.6720        65\n",
      "           4     0.6667    0.5000    0.5714         8\n",
      "           5     0.7143    0.6250    0.6667         8\n",
      "           6     0.7895    0.8824    0.8333        17\n",
      "\n",
      "    accuracy                         0.6558       215\n",
      "   macro avg     0.6692    0.6693    0.6633       215\n",
      "weighted avg     0.6577    0.6558    0.6534       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='mobilenet_v3_large',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f386f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [100 111 270 262  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 1.4252, Train Acc: 0.1497 - Val Loss: 1.3597, Val Acc: 0.2557\n",
      "Fold None, Epoch 2/15 - Train Loss: 1.3566, Train Acc: 0.2480 - Val Loss: 1.3260, Val Acc: 0.3059\n",
      "Fold None, Epoch 3/15 - Train Loss: 1.3074, Train Acc: 0.2926 - Val Loss: 1.2779, Val Acc: 0.3562\n",
      "Fold None, Epoch 4/15 - Train Loss: 1.2326, Train Acc: 0.3554 - Val Loss: 1.2260, Val Acc: 0.4018\n",
      "Fold None, Epoch 5/15 - Train Loss: 1.1748, Train Acc: 0.3851 - Val Loss: 1.1556, Val Acc: 0.4064\n",
      "Fold None, Epoch 6/15 - Train Loss: 1.1128, Train Acc: 0.4320 - Val Loss: 1.0714, Val Acc: 0.4521\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.9950, Train Acc: 0.4983 - Val Loss: 0.9776, Val Acc: 0.4886\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.9359, Train Acc: 0.5280 - Val Loss: 0.9076, Val Acc: 0.4977\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.8530, Train Acc: 0.5543 - Val Loss: 0.8295, Val Acc: 0.5342\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.7801, Train Acc: 0.5749 - Val Loss: 0.7839, Val Acc: 0.5297\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.7227, Train Acc: 0.5989 - Val Loss: 0.7129, Val Acc: 0.5525\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.6504, Train Acc: 0.6274 - Val Loss: 0.6431, Val Acc: 0.5799\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.5668, Train Acc: 0.6663 - Val Loss: 0.6146, Val Acc: 0.5571\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.5009, Train Acc: 0.6857 - Val Loss: 0.6075, Val Acc: 0.5525\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.4435, Train Acc: 0.7257 - Val Loss: 0.5430, Val Acc: 0.6164\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.75      0.96      0.84        25\n",
      "      type-2       0.44      0.41      0.42        27\n",
      "      type-3       0.56      0.44      0.49        68\n",
      "      type-4       0.65      0.68      0.67        66\n",
      "      type-5       0.42      0.62      0.50         8\n",
      "      type-6       0.83      0.62      0.71         8\n",
      "      type-7       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.62       219\n",
      "   macro avg       0.62      0.66      0.63       219\n",
      "weighted avg       0.61      0.62      0.61       219\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[24  0  0  0  0  0  1]\n",
      " [ 5 11  7  2  1  0  1]\n",
      " [ 1 12 30 20  3  0  2]\n",
      " [ 2  1 17 45  0  0  1]\n",
      " [ 0  1  0  1  5  1  0]\n",
      " [ 0  0  0  1  1  5  1]\n",
      " [ 0  0  0  0  2  0 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.9600    0.8421        25\n",
      "           1     0.4400    0.4074    0.4231        27\n",
      "           2     0.5556    0.4412    0.4918        68\n",
      "           3     0.6522    0.6818    0.6667        66\n",
      "           4     0.4167    0.6250    0.5000         8\n",
      "           5     0.8333    0.6250    0.7143         8\n",
      "           6     0.7143    0.8824    0.7895        17\n",
      "\n",
      "    accuracy                         0.6164       219\n",
      "   macro avg     0.6231    0.6604    0.6325       219\n",
      "weighted avg     0.6100    0.6164    0.6076       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [100 111 270 262  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 1.4120, Train Acc: 0.1749 - Val Loss: 1.2051, Val Acc: 0.3425\n",
      "Fold None, Epoch 2/20 - Train Loss: 1.2750, Train Acc: 0.2720 - Val Loss: 1.1779, Val Acc: 0.3470\n",
      "Fold None, Epoch 3/20 - Train Loss: 1.1859, Train Acc: 0.3154 - Val Loss: 1.1232, Val Acc: 0.3790\n",
      "Fold None, Epoch 4/20 - Train Loss: 1.1256, Train Acc: 0.3749 - Val Loss: 1.0569, Val Acc: 0.3836\n",
      "Fold None, Epoch 5/20 - Train Loss: 1.0594, Train Acc: 0.4206 - Val Loss: 1.0140, Val Acc: 0.3927\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.9753, Train Acc: 0.4720 - Val Loss: 0.9710, Val Acc: 0.4018\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.9627, Train Acc: 0.4583 - Val Loss: 0.9287, Val Acc: 0.4521\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.9476, Train Acc: 0.4514 - Val Loss: 0.8917, Val Acc: 0.4840\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.8636, Train Acc: 0.5177 - Val Loss: 0.8702, Val Acc: 0.4703\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.8627, Train Acc: 0.4949 - Val Loss: 0.8426, Val Acc: 0.4932\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.8206, Train Acc: 0.5269 - Val Loss: 0.8383, Val Acc: 0.4977\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.8445, Train Acc: 0.5029 - Val Loss: 0.8152, Val Acc: 0.4840\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.8184, Train Acc: 0.5063 - Val Loss: 0.8145, Val Acc: 0.5023\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.7660, Train Acc: 0.5394 - Val Loss: 0.7903, Val Acc: 0.5251\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.7296, Train Acc: 0.5543 - Val Loss: 0.7722, Val Acc: 0.5251\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.7258, Train Acc: 0.5463 - Val Loss: 0.8139, Val Acc: 0.5068\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.6827, Train Acc: 0.5943 - Val Loss: 0.8204, Val Acc: 0.4658\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.6815, Train Acc: 0.5920 - Val Loss: 0.7865, Val Acc: 0.4840\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.6395, Train Acc: 0.6274 - Val Loss: 0.7706, Val Acc: 0.5160\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.6568, Train Acc: 0.5966 - Val Loss: 0.7946, Val Acc: 0.5023\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.51      0.80      0.62        25\n",
      "      type-2       0.32      0.30      0.31        27\n",
      "      type-3       0.45      0.44      0.45        68\n",
      "      type-4       0.65      0.48      0.56        66\n",
      "      type-5       0.31      0.62      0.42         8\n",
      "      type-6       0.62      0.62      0.62         8\n",
      "      type-7       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.52       219\n",
      "   macro avg       0.53      0.58      0.54       219\n",
      "weighted avg       0.53      0.52      0.52       219\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[20  0  4  0  0  0  1]\n",
      " [ 5  8  7  2  2  2  1]\n",
      " [11  9 30 13  3  1  1]\n",
      " [ 3  4 23 32  4  0  0]\n",
      " [ 0  2  0  1  5  0  0]\n",
      " [ 0  1  0  1  1  5  0]\n",
      " [ 0  1  2  0  1  0 13]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5128    0.8000    0.6250        25\n",
      "           1     0.3200    0.2963    0.3077        27\n",
      "           2     0.4545    0.4412    0.4478        68\n",
      "           3     0.6531    0.4848    0.5565        66\n",
      "           4     0.3125    0.6250    0.4167         8\n",
      "           5     0.6250    0.6250    0.6250         8\n",
      "           6     0.8125    0.7647    0.7879        17\n",
      "\n",
      "    accuracy                         0.5160       219\n",
      "   macro avg     0.5272    0.5767    0.5381       219\n",
      "weighted avg     0.5333    0.5160    0.5152       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prestera inte jätte bra. mobilenet_v2 är bättre \n",
    "\n",
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='mobilenet_v3_large',\n",
    "    freeze_until='features.7',  # or 'features.4', None for no freezing.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4e3a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ALL LOGS ====\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.72      0.72      0.72        25\n",
      "      type-2       0.55      0.72      0.62        25\n",
      "      type-3       0.53      0.49      0.51        65\n",
      "      type-4       0.72      0.64      0.68        61\n",
      "      type-5       0.50      0.83      0.62         6\n",
      "      type-6       0.60      0.60      0.60         5\n",
      "      type-7       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.63       202\n",
      "   macro avg       0.63      0.69      0.65       202\n",
      "weighted avg       0.64      0.63      0.63       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = get_logs()\n",
    "\n",
    "print(\"==== ALL LOGS ====\")\n",
    "for log in logs:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66e56a",
   "metadata": {},
   "source": [
    "# To load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "366e5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = models.efficientnet_b0()\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, NUM_CLASSES)\n",
    "    )\n",
    "    state_dict = torch.load(model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff56321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onnx_model(model_path):\n",
    "\n",
    "    # Load the ONNX model\n",
    "    model = onnx.load(model_path)\n",
    "    onnx.checker.check_model(model)\n",
    "\n",
    "    # Create an ONNX Runtime session\n",
    "    session = ort.InferenceSession(model_path)\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cc6a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_onnx_model(session, loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.numpy()  # Convert to numpy array\n",
    "        outputs = session.run(None, {\"image\": inputs})[0]  # Get the first output\n",
    "        preds = np.argmax(outputs, axis=1)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "    return None, None, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd415c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ONNX Model Evaluation Confusion Matrix ---\n",
      "[[ 64   1   0   0   0   0   0]\n",
      " [  0  88   2   2   0   0   0]\n",
      " [  3  16 271  29   0   3   1]\n",
      " [  2   3  52 269   0   0   0]\n",
      " [  0   0   0   0  39   0   0]\n",
      " [  0   0   0   0   0  42   0]\n",
      " [  0   0   0   0   0   0  83]]\n",
      "\n",
      "--- ONNX Model Evaluation Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9275    0.9846    0.9552        65\n",
      "           1     0.8148    0.9565    0.8800        92\n",
      "           2     0.8338    0.8390    0.8364       323\n",
      "           3     0.8967    0.8252    0.8594       326\n",
      "           4     1.0000    1.0000    1.0000        39\n",
      "           5     0.9333    1.0000    0.9655        42\n",
      "           6     0.9881    1.0000    0.9940        83\n",
      "\n",
      "    accuracy                         0.8825       970\n",
      "   macro avg     0.9135    0.9436    0.9272       970\n",
      "weighted avg     0.8836    0.8825    0.8819       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"kf_stool_classification_61.onnx\"  # Path to your ONNX model\n",
    "\n",
    "model = load_onnx_model(MODEL_PATH)\n",
    "\n",
    "# model evaluation\n",
    "val_dataset = StoolDataset(DATA_DIR, transform=val_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "_, _, preds, labels = evaluate_onnx_model(model, val_loader)\n",
    "cm = confusion_matrix(labels, preds)\n",
    "crpt = classification_report(labels, preds, digits=4)\n",
    "\n",
    "log_and_store(\"\\n--- ONNX Model Evaluation Confusion Matrix ---\")\n",
    "log_and_store(cm, is_confmat=True)  \n",
    "log_and_store(\"\\n--- ONNX Model Evaluation Classification Report ---\")\n",
    "log_and_store(crpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323635fe",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d8adc",
   "metadata": {},
   "source": [
    "### Save as .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to stool_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. Define where to save\n",
    "SAVE_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "# 2. Save the state_dict\n",
    "#torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"Model weights saved to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd490f",
   "metadata": {},
   "source": [
    "### Save as .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfcdfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX export completed: stool_model.onnx\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Create dummy input for ONNX export (batch_size=1, 3 channels, IMG_SIZE x IMG_SIZE)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,                               # your trained model\n",
    "    dummy_input,                         # input tensor\n",
    "    \"stool_model.onnx\",                  # output file name\n",
    "    export_params=True,                  # store weights inside the model file\n",
    "    opset_version=11,                    # ONNX opset version\n",
    "    do_constant_folding=True,            # fold constant values for optimization\n",
    "    input_names=['input'],               # name for the input layer\n",
    "    output_names=['output'],             # name for the output layer\n",
    "    dynamic_axes={                      # allow variable input sizes\n",
    "        'input': {0: 'batch_size'},     \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ ONNX export completed: stool_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
