{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7bc1ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62f7fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a97ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_confusion_matrix(cm):\n",
    "    \"\"\"Returns a string of a nicely formatted confusion matrix with indices and highlighted diagonal.\"\"\"\n",
    "    headers = [\"\"] + [f\"Pred {i}\" for i in range(len(cm[0]))]\n",
    "    table = []\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        formatted_row = []\n",
    "        for j, val in enumerate(row):\n",
    "            if i == j:\n",
    "                formatted_row.append(f\"*{val}*\")  # Highlight diagonal\n",
    "            else:\n",
    "                formatted_row.append(str(val))\n",
    "        table.append([f\"True {i}\"] + formatted_row)\n",
    "\n",
    "    return tabulate(table, headers=headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b14f9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = []\n",
    "\n",
    "def log_and_store(*msgs, table_format=False, is_confmat=False):\n",
    "    \"\"\"\n",
    "    Logs plain messages or pretty-prints confusion matrices or tables.\n",
    "    \"\"\"\n",
    "    if is_confmat and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = format_confusion_matrix(msgs[0])\n",
    "    elif table_format and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = tabulate(msgs[0], tablefmt=\"grid\")\n",
    "    else:\n",
    "        msg = \" \".join(str(m) for m in msgs)\n",
    "\n",
    "    print(msg)\n",
    "    all_logs.append(msg)\n",
    "\n",
    "def get_logs():\n",
    "    \"\"\"\n",
    "    Returnerar en lista med alla loggade meddelanden.\n",
    "    \"\"\"\n",
    "    return all_logs\n",
    "\n",
    "def clear_logs():\n",
    "    \"\"\"\n",
    "    TÃ¶mmer loggen.\n",
    "    \"\"\"\n",
    "    all_logs.clear()\n",
    "\n",
    "def save_logs_to_file(filename):\n",
    "    \"\"\"\n",
    "    Sparar loggade meddelanden till en fil.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for log in all_logs:\n",
    "            f.write(log + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79638fe9",
   "metadata": {},
   "source": [
    "# Advanced Training Pipeline\n",
    "\n",
    "This notebook implements:\n",
    "1. Stronger and more varied augmentation, including class-specific oversampling.\n",
    "2. Model-level adjustments: gradual unfreezing, EfficientNet-B0/B3, label smoothing, focal loss/class-weighted loss.\n",
    "3. Training strategies: early stopping, checkpoint ensembles, and k-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea9da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../data-BSS\"  # Update this path\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd323500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoolDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(class_path, fname), idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "481bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger and more varied augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.Lambda(lambda img: img.filter(ImageFilter.FIND_EDGES))], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "340ab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing Loss (CrossEntropy with label_smoothing)\n",
    "criterion_smooth = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FocalLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f3691ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\\n    # Load pretrained EfficientNet\\n    if backbone == 'efficientnet_b0':\\n        model = models.efficientnet_b0(pretrained=True)\\n    elif backbone == 'efficientnet_b3':\\n        model = models.efficientnet_b3(pretrained=True)\\n    elif backbone == 'mobilenet_v2':\\n        model = models.mobilenet_v2(pretrained=True)\\n    elif backbone == 'mobilenet_v3_small':\\n        model = models.mobilenet_v3_small(pretrained=True)\\n    else:\\n        raise ValueError('Invalid backbone')\\n\\n    # Replace classifier head\\n    in_features = model.classifier[1].in_features\\n    model.classifier = nn.Sequential(\\n        nn.Linear(in_features, 512),\\n        nn.ReLU(inplace=True),\\n        nn.Dropout(0.4),\\n        nn.Linear(512, num_classes)\\n    )\\n\\n    # Freeze layers if specified\\n    if freeze_until_layer:\\n        for name, param in model.named_parameters():\\n            param.requires_grad = False\\n            if name.startswith(freeze_until_layer):\\n                break\\n        # Unfreeze subsequent layers\\n        unfreeze = False\\n        for name, param in model.named_parameters():\\n            if unfreeze:\\n                param.requires_grad = True\\n            if name.startswith(freeze_until_layer):\\n                unfreeze = True\\n\\n    return model.to(DEVICE)\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    # Load pretrained EfficientNet\n",
    "    if backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    # Replace classifier head\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Freeze layers if specified\n",
    "    if freeze_until_layer:\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                break\n",
    "        # Unfreeze subsequent layers\n",
    "        unfreeze = False\n",
    "        for name, param in model.named_parameters():\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                unfreeze = True\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5c33c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    if backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        # freeze layers\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        # Replace final classifier\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb02600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return None, None, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "84c606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx):\n",
    "\n",
    "    #patience = 3\n",
    "    #counter = 0\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) # for accuracy\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) # for loss\n",
    "\n",
    "    best_acc     = 0.0\n",
    "    best_loss    = float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ââ OneâCycle LR schedule ââââââââââââââââââââââââââââââââââââââââââââââââââ\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=optimizer.param_groups[0]['lr'] * 10,  # e.g. 10Ã your base LR\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch = val_corrects / val_total\n",
    "        # step the oneâcycle scheduler each batchâcycle (done at epochâend here)\n",
    "        scheduler.step()\n",
    "\n",
    "        # keep snapshot of bestâever validation loss (for final restore)\n",
    "        if val_loss_epoch < best_loss:\n",
    "            best_loss    = val_loss_epoch\n",
    "            best_acc     = val_acc_epoch\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f\"Fold {fold_idx}, Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        #if val_acc_epoch > best_acc:\n",
    "        #    best_acc = val_acc_epoch\n",
    "        #   best_weights = model.state_dict().copy()\n",
    "        #   counter = 0\n",
    "        #else:\n",
    "        #    counter += 1\n",
    "        #    if counter >= patience:\n",
    "        #        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #       break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Final validation metrics\n",
    "    _, _, preds, labels = evaluate_model(model, val_loader)\n",
    "    log_and_store(\"\\nClassification Report for Fold {}:\".format(fold_idx))\n",
    "    log_and_store(classification_report(labels, preds, target_names=sorted(os.listdir(DATA_DIR))))\n",
    "\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a45e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../data-BSS -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a1e6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cf9c6",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c234e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(\n",
    "    data_dir,\n",
    "    backbone='mobilenet_v2',\n",
    "    freeze_until_layer=None,\n",
    "    criterion_fn=None,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    k_folds=3,\n",
    "    batch_size=32,\n",
    "    train_transforms=None,\n",
    "    val_transforms=None,\n",
    "    seed=42,\n",
    "    num_classes=7,\n",
    "):\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "\n",
    "    # Class weights for full dataset (optional, for balance insights)\n",
    "    all_labels_full = [label for _, label in full_dataset]\n",
    "    class_counts = np.bincount(all_labels_full)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights_full = [class_weights[label] for label in all_labels_full]\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    fold_models = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices), 1):\n",
    "        print(f\"\\n======= Fold {fold_idx} =======\")\n",
    "\n",
    "        # Subset + transforms\n",
    "        train_ds = torch.utils.data.Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "        val_ds   = torch.utils.data.Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "        # Weighted sampler\n",
    "        train_labels_fold = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "        class_sample_count_fold = np.array([train_labels_fold.count(i) for i in range(num_classes)])\n",
    "        class_weights_fold = 1.0 / class_sample_count_fold\n",
    "        sample_weights_fold = np.array([class_weights_fold[label] for label in train_labels_fold])\n",
    "        sample_weights_fold = torch.from_numpy(sample_weights_fold.astype(np.double))\n",
    "        sampler_fold = WeightedRandomSampler(sample_weights_fold, num_samples=len(sample_weights_fold), replacement=True)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler_fold)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(backbone=backbone, freeze_until_layer=freeze_until_layer)\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # Loss\n",
    "        criterion = criterion_fn if criterion_fn is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train\n",
    "        best_model, best_acc = train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx)\n",
    "        fold_models.append(best_model)\n",
    "        fold_accuracies.append(best_acc)\n",
    "\n",
    "        # Evaluate and log\n",
    "        best_model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = best_model(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(yb.numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        crpt = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Confusion Matrix ---\")\n",
    "        log_and_store(cm, is_confmat=True)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Classification Report ---\")\n",
    "        log_and_store(crpt)\n",
    "\n",
    "    log_and_store([\"\\nFold Models:\", [f\"Fold {i+1}\" for i in range(len(fold_models))]])\n",
    "    log_and_store([\"Fold Accuracies:\", fold_accuracies])\n",
    "    log_and_store([\"Mean Accuracy:\", np.mean(fold_accuracies)])\n",
    "\n",
    "    return fold_models, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ae6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_split(\n",
    "    data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "):\n",
    "    print(\"======= Single Split Training =======\")\n",
    "\n",
    "    # Full dataset\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    all_labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=val_split, random_state=seed, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Create datasets with transforms\n",
    "    train_ds = Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "    val_ds = Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "    # Weighted sampler for class imbalance\n",
    "    train_labels = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "    class_sample_counts = np.array([train_labels.count(i) for i in range(NUM_CLASSES)])\n",
    "    print(f\"Class sample counts: {class_sample_counts}\")\n",
    "    class_weights = 1.0 / class_sample_counts\n",
    "    sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights.astype(np.double))\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = create_model(backbone=model_name, freeze_until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    if criterion == 'focal':\n",
    "        loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    elif criterion == 'smooth':\n",
    "        loss_fn = criterion_smooth\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "    # Train\n",
    "    best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx=None)\n",
    "\n",
    "    # Evaluation\n",
    "    best_model.eval()\n",
    "    all_preds, all_labels_eval = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = best_model(xb).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_eval.extend(yb.numpy())\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels_eval, all_preds)\n",
    "    cr = classification_report(all_labels_eval, all_preds, digits=4)\n",
    "\n",
    "    log_and_store(\"--- Confusion Matrix ---\")\n",
    "    log_and_store(cm, is_confmat=True)\n",
    "    log_and_store(\"--- Classification Report ---\")\n",
    "    log_and_store(cr)\n",
    "\n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19280109",
   "metadata": {},
   "source": [
    "# Training ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b24a86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logs()  # Clear logs if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d5b2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "backbone = 'efficientnet_b3'  # or 'mobilenet_v2', 'mobilenet_v3_small', efficientnet_b3, efficientnet_b0.\n",
    "freeze_until = 'features.4'  # e.g., 'features.4'\n",
    "criterion = 'focal' # 'focal' or 'smooth'\n",
    "num_epochs = 20\n",
    "batch_size = 16 # This represents the batch size for training and validation which is the number of samples processed before the model is updated.\n",
    "lr = 1e-4  # Learning rate\n",
    "\n",
    "val_split = 0.2  # Fraction of data to use for validation\n",
    "\n",
    "k_folds = 3\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f938440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/15 - Train Loss: 1.3820, Train Acc: 0.1849 - Val Loss: 1.4448, Val Acc: 0.1767\n",
      "Fold 1, Epoch 2/15 - Train Loss: 1.1167, Train Acc: 0.3977 - Val Loss: 1.2405, Val Acc: 0.2605\n",
      "Fold 1, Epoch 3/15 - Train Loss: 0.9388, Train Acc: 0.4744 - Val Loss: 1.0296, Val Acc: 0.3860\n",
      "Fold 1, Epoch 4/15 - Train Loss: 0.7894, Train Acc: 0.5767 - Val Loss: 0.9028, Val Acc: 0.4140\n",
      "Fold 1, Epoch 5/15 - Train Loss: 0.6866, Train Acc: 0.5907 - Val Loss: 0.8238, Val Acc: 0.4326\n",
      "Fold 1, Epoch 6/15 - Train Loss: 0.5789, Train Acc: 0.6465 - Val Loss: 0.7452, Val Acc: 0.4605\n",
      "Fold 1, Epoch 7/15 - Train Loss: 0.5021, Train Acc: 0.6942 - Val Loss: 0.7053, Val Acc: 0.4977\n",
      "Fold 1, Epoch 8/15 - Train Loss: 0.4631, Train Acc: 0.7105 - Val Loss: 0.7037, Val Acc: 0.4698\n",
      "Fold 1, Epoch 9/15 - Train Loss: 0.4124, Train Acc: 0.7209 - Val Loss: 0.6732, Val Acc: 0.5070\n",
      "Fold 1, Epoch 10/15 - Train Loss: 0.3535, Train Acc: 0.7814 - Val Loss: 0.7026, Val Acc: 0.4930\n",
      "Fold 1, Epoch 11/15 - Train Loss: 0.3219, Train Acc: 0.7640 - Val Loss: 0.6587, Val Acc: 0.5256\n",
      "Fold 1, Epoch 12/15 - Train Loss: 0.3131, Train Acc: 0.7663 - Val Loss: 0.6492, Val Acc: 0.5302\n",
      "Fold 1, Epoch 13/15 - Train Loss: 0.2913, Train Acc: 0.7884 - Val Loss: 0.6246, Val Acc: 0.5209\n",
      "Fold 1, Epoch 14/15 - Train Loss: 0.2880, Train Acc: 0.7849 - Val Loss: 0.6312, Val Acc: 0.5070\n",
      "Fold 1, Epoch 15/15 - Train Loss: 0.2429, Train Acc: 0.8349 - Val Loss: 0.6285, Val Acc: 0.5442\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.67      0.77      0.71        26\n",
      "      type-2       0.48      0.52      0.50        21\n",
      "      type-3       0.46      0.43      0.44        75\n",
      "      type-4       0.50      0.51      0.50        59\n",
      "      type-5       0.46      0.55      0.50        11\n",
      "      type-6       0.67      0.22      0.33         9\n",
      "      type-7       0.69      0.79      0.73        14\n",
      "\n",
      "    accuracy                           0.52       215\n",
      "   macro avg       0.56      0.54      0.53       215\n",
      "weighted avg       0.52      0.52      0.51       215\n",
      "\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[20  0  4  2  0  0  0]\n",
      " [ 3 11  6  0  0  0  1]\n",
      " [ 5  7 32 25  2  0  4]\n",
      " [ 0  4 25 30  0  0  0]\n",
      " [ 2  0  1  2  6  0  0]\n",
      " [ 0  1  1  0  5  2  0]\n",
      " [ 0  0  1  1  0  1 11]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.7692    0.7143        26\n",
      "           1     0.4783    0.5238    0.5000        21\n",
      "           2     0.4571    0.4267    0.4414        75\n",
      "           3     0.5000    0.5085    0.5042        59\n",
      "           4     0.4615    0.5455    0.5000        11\n",
      "           5     0.6667    0.2222    0.3333         9\n",
      "           6     0.6875    0.7857    0.7333        14\n",
      "\n",
      "    accuracy                         0.5209       215\n",
      "   macro avg     0.5597    0.5402    0.5324       215\n",
      "weighted avg     0.5203    0.5209    0.5148       215\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/15 - Train Loss: 1.3111, Train Acc: 0.2884 - Val Loss: 1.2497, Val Acc: 0.2419\n",
      "Fold 2, Epoch 2/15 - Train Loss: 1.0874, Train Acc: 0.3779 - Val Loss: 1.0197, Val Acc: 0.4093\n",
      "Fold 2, Epoch 3/15 - Train Loss: 0.8747, Train Acc: 0.5233 - Val Loss: 0.9052, Val Acc: 0.4279\n",
      "Fold 2, Epoch 4/15 - Train Loss: 0.7663, Train Acc: 0.5698 - Val Loss: 0.8165, Val Acc: 0.4698\n",
      "Fold 2, Epoch 5/15 - Train Loss: 0.6599, Train Acc: 0.6093 - Val Loss: 0.7606, Val Acc: 0.4930\n",
      "Fold 2, Epoch 6/15 - Train Loss: 0.5490, Train Acc: 0.6744 - Val Loss: 0.6985, Val Acc: 0.5209\n",
      "Fold 2, Epoch 7/15 - Train Loss: 0.4830, Train Acc: 0.7023 - Val Loss: 0.6284, Val Acc: 0.5535\n",
      "Fold 2, Epoch 8/15 - Train Loss: 0.4597, Train Acc: 0.7105 - Val Loss: 0.5820, Val Acc: 0.6000\n",
      "Fold 2, Epoch 9/15 - Train Loss: 0.4116, Train Acc: 0.7209 - Val Loss: 0.6282, Val Acc: 0.5721\n",
      "Fold 2, Epoch 10/15 - Train Loss: 0.3455, Train Acc: 0.7767 - Val Loss: 0.5802, Val Acc: 0.6186\n",
      "Fold 2, Epoch 11/15 - Train Loss: 0.3323, Train Acc: 0.7791 - Val Loss: 0.5536, Val Acc: 0.6279\n",
      "Fold 2, Epoch 12/15 - Train Loss: 0.3145, Train Acc: 0.7698 - Val Loss: 0.5600, Val Acc: 0.6279\n",
      "Fold 2, Epoch 13/15 - Train Loss: 0.2759, Train Acc: 0.8163 - Val Loss: 0.5840, Val Acc: 0.6233\n",
      "Fold 2, Epoch 14/15 - Train Loss: 0.2683, Train Acc: 0.8047 - Val Loss: 0.5316, Val Acc: 0.6465\n",
      "Fold 2, Epoch 15/15 - Train Loss: 0.2532, Train Acc: 0.8093 - Val Loss: 0.5503, Val Acc: 0.6465\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.65      0.77      0.71        22\n",
      "      type-2       0.50      0.54      0.52        24\n",
      "      type-3       0.60      0.68      0.64        76\n",
      "      type-4       0.77      0.61      0.68        67\n",
      "      type-5       0.67      0.67      0.67         6\n",
      "      type-6       0.67      0.29      0.40         7\n",
      "      type-7       0.67      0.77      0.71        13\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.65      0.62      0.62       215\n",
      "weighted avg       0.66      0.65      0.65       215\n",
      "\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[17  2  3  0  0  0  0]\n",
      " [ 1 13  8  1  0  0  1]\n",
      " [ 7  5 52  9  0  0  3]\n",
      " [ 1  5 20 41  0  0  0]\n",
      " [ 0  0  0  1  4  1  0]\n",
      " [ 0  0  1  1  2  2  1]\n",
      " [ 0  1  2  0  0  0 10]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6538    0.7727    0.7083        22\n",
      "           1     0.5000    0.5417    0.5200        24\n",
      "           2     0.6047    0.6842    0.6420        76\n",
      "           3     0.7736    0.6119    0.6833        67\n",
      "           4     0.6667    0.6667    0.6667         6\n",
      "           5     0.6667    0.2857    0.4000         7\n",
      "           6     0.6667    0.7692    0.7143        13\n",
      "\n",
      "    accuracy                         0.6465       215\n",
      "   macro avg     0.6474    0.6189    0.6192       215\n",
      "weighted avg     0.6581    0.6465    0.6452       215\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/15 - Train Loss: 1.2903, Train Acc: 0.2744 - Val Loss: 1.2607, Val Acc: 0.2651\n",
      "Fold 3, Epoch 2/15 - Train Loss: 1.0645, Train Acc: 0.4012 - Val Loss: 1.0467, Val Acc: 0.3395\n",
      "Fold 3, Epoch 3/15 - Train Loss: 0.8668, Train Acc: 0.5198 - Val Loss: 0.9758, Val Acc: 0.4140\n",
      "Fold 3, Epoch 4/15 - Train Loss: 0.7564, Train Acc: 0.5837 - Val Loss: 0.8489, Val Acc: 0.4744\n",
      "Fold 3, Epoch 5/15 - Train Loss: 0.6330, Train Acc: 0.6093 - Val Loss: 0.7924, Val Acc: 0.4837\n",
      "Fold 3, Epoch 6/15 - Train Loss: 0.5063, Train Acc: 0.6802 - Val Loss: 0.6975, Val Acc: 0.5674\n",
      "Fold 3, Epoch 7/15 - Train Loss: 0.4795, Train Acc: 0.6919 - Val Loss: 0.7038, Val Acc: 0.5070\n",
      "Fold 3, Epoch 8/15 - Train Loss: 0.4713, Train Acc: 0.7000 - Val Loss: 0.6382, Val Acc: 0.5581\n",
      "Fold 3, Epoch 9/15 - Train Loss: 0.3854, Train Acc: 0.7302 - Val Loss: 0.6340, Val Acc: 0.5628\n",
      "Fold 3, Epoch 10/15 - Train Loss: 0.3781, Train Acc: 0.7326 - Val Loss: 0.6045, Val Acc: 0.5907\n",
      "Fold 3, Epoch 11/15 - Train Loss: 0.2978, Train Acc: 0.7860 - Val Loss: 0.5815, Val Acc: 0.5860\n",
      "Fold 3, Epoch 12/15 - Train Loss: 0.3128, Train Acc: 0.7814 - Val Loss: 0.6263, Val Acc: 0.5535\n",
      "Fold 3, Epoch 13/15 - Train Loss: 0.2626, Train Acc: 0.8221 - Val Loss: 0.5978, Val Acc: 0.5535\n",
      "Fold 3, Epoch 14/15 - Train Loss: 0.2818, Train Acc: 0.7942 - Val Loss: 0.5735, Val Acc: 0.6047\n",
      "Fold 3, Epoch 15/15 - Train Loss: 0.2537, Train Acc: 0.8163 - Val Loss: 0.5941, Val Acc: 0.6326\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.65      0.83      0.73        24\n",
      "      type-2       0.65      0.41      0.50        32\n",
      "      type-3       0.58      0.64      0.61        69\n",
      "      type-4       0.62      0.59      0.61        59\n",
      "      type-5       0.33      0.60      0.43         5\n",
      "      type-6       0.38      0.60      0.46         5\n",
      "      type-7       0.80      0.57      0.67        21\n",
      "\n",
      "    accuracy                           0.60       215\n",
      "   macro avg       0.57      0.61      0.57       215\n",
      "weighted avg       0.62      0.60      0.60       215\n",
      "\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[20  2  2  0  0  0  0]\n",
      " [ 7 13  9  1  1  0  1]\n",
      " [ 0  4 44 17  1  2  1]\n",
      " [ 1  0 19 35  4  0  0]\n",
      " [ 0  0  1  1  3  0  0]\n",
      " [ 0  1  0  0  0  3  1]\n",
      " [ 3  0  1  2  0  3 12]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6452    0.8333    0.7273        24\n",
      "           1     0.6500    0.4062    0.5000        32\n",
      "           2     0.5789    0.6377    0.6069        69\n",
      "           3     0.6250    0.5932    0.6087        59\n",
      "           4     0.3333    0.6000    0.4286         5\n",
      "           5     0.3750    0.6000    0.4615         5\n",
      "           6     0.8000    0.5714    0.6667        21\n",
      "\n",
      "    accuracy                         0.6047       215\n",
      "   macro avg     0.5725    0.6060    0.5714       215\n",
      "weighted avg     0.6207    0.6047    0.6032       215\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/15 - Train Loss: 1.3173, Train Acc: 0.2605 - Val Loss: 1.3287, Val Acc: 0.2186\n",
      "Fold 4, Epoch 2/15 - Train Loss: 1.0632, Train Acc: 0.4244 - Val Loss: 1.1221, Val Acc: 0.3256\n",
      "Fold 4, Epoch 3/15 - Train Loss: 0.9116, Train Acc: 0.4884 - Val Loss: 0.8612, Val Acc: 0.4651\n",
      "Fold 4, Epoch 4/15 - Train Loss: 0.7561, Train Acc: 0.5535 - Val Loss: 0.7963, Val Acc: 0.4512\n",
      "Fold 4, Epoch 5/15 - Train Loss: 0.6758, Train Acc: 0.6047 - Val Loss: 0.7382, Val Acc: 0.5349\n",
      "Fold 4, Epoch 6/15 - Train Loss: 0.5665, Train Acc: 0.6733 - Val Loss: 0.6683, Val Acc: 0.5628\n",
      "Fold 4, Epoch 7/15 - Train Loss: 0.5059, Train Acc: 0.6849 - Val Loss: 0.6173, Val Acc: 0.5349\n",
      "Fold 4, Epoch 8/15 - Train Loss: 0.4280, Train Acc: 0.7186 - Val Loss: 0.5941, Val Acc: 0.5674\n",
      "Fold 4, Epoch 9/15 - Train Loss: 0.3927, Train Acc: 0.7442 - Val Loss: 0.6043, Val Acc: 0.5349\n",
      "Fold 4, Epoch 10/15 - Train Loss: 0.3812, Train Acc: 0.7488 - Val Loss: 0.5568, Val Acc: 0.5860\n",
      "Fold 4, Epoch 11/15 - Train Loss: 0.3177, Train Acc: 0.7872 - Val Loss: 0.5720, Val Acc: 0.5256\n",
      "Fold 4, Epoch 12/15 - Train Loss: 0.3019, Train Acc: 0.7849 - Val Loss: 0.5367, Val Acc: 0.5767\n",
      "Fold 4, Epoch 13/15 - Train Loss: 0.2901, Train Acc: 0.8047 - Val Loss: 0.5236, Val Acc: 0.6047\n",
      "Fold 4, Epoch 14/15 - Train Loss: 0.2448, Train Acc: 0.8163 - Val Loss: 0.5384, Val Acc: 0.5907\n",
      "Fold 4, Epoch 15/15 - Train Loss: 0.2440, Train Acc: 0.8209 - Val Loss: 0.5160, Val Acc: 0.6279\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.57      0.87      0.68        15\n",
      "      type-2       0.51      0.54      0.53        35\n",
      "      type-3       0.50      0.47      0.49        57\n",
      "      type-4       0.74      0.72      0.73        67\n",
      "      type-5       0.67      0.46      0.55        13\n",
      "      type-6       0.67      0.60      0.63        10\n",
      "      type-7       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.63       215\n",
      "   macro avg       0.65      0.65      0.64       215\n",
      "weighted avg       0.63      0.63      0.63       215\n",
      "\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[13  1  1  0  0  0  0]\n",
      " [ 4 19 11  1  0  0  0]\n",
      " [ 2 14 27 13  0  0  1]\n",
      " [ 1  2 15 48  1  0  0]\n",
      " [ 2  1  0  2  6  2  0]\n",
      " [ 0  0  0  1  2  6  1]\n",
      " [ 1  0  0  0  0  1 16]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5652    0.8667    0.6842        15\n",
      "           1     0.5135    0.5429    0.5278        35\n",
      "           2     0.5000    0.4737    0.4865        57\n",
      "           3     0.7385    0.7164    0.7273        67\n",
      "           4     0.6667    0.4615    0.5455        13\n",
      "           5     0.6667    0.6000    0.6316        10\n",
      "           6     0.8889    0.8889    0.8889        18\n",
      "\n",
      "    accuracy                         0.6279       215\n",
      "   macro avg     0.6485    0.6500    0.6417       215\n",
      "weighted avg     0.6314    0.6279    0.6260       215\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/15 - Train Loss: 1.3078, Train Acc: 0.2814 - Val Loss: 1.2993, Val Acc: 0.2837\n",
      "Fold 5, Epoch 2/15 - Train Loss: 1.0560, Train Acc: 0.4395 - Val Loss: 1.1125, Val Acc: 0.3628\n",
      "Fold 5, Epoch 3/15 - Train Loss: 0.8603, Train Acc: 0.5372 - Val Loss: 0.9279, Val Acc: 0.4372\n",
      "Fold 5, Epoch 4/15 - Train Loss: 0.7128, Train Acc: 0.6058 - Val Loss: 0.7916, Val Acc: 0.4698\n",
      "Fold 5, Epoch 5/15 - Train Loss: 0.6316, Train Acc: 0.6349 - Val Loss: 0.6975, Val Acc: 0.5070\n",
      "Fold 5, Epoch 6/15 - Train Loss: 0.5851, Train Acc: 0.6384 - Val Loss: 0.7137, Val Acc: 0.5209\n",
      "Fold 5, Epoch 7/15 - Train Loss: 0.5005, Train Acc: 0.6791 - Val Loss: 0.6938, Val Acc: 0.5349\n",
      "Fold 5, Epoch 8/15 - Train Loss: 0.4100, Train Acc: 0.7442 - Val Loss: 0.6633, Val Acc: 0.5860\n",
      "Fold 5, Epoch 9/15 - Train Loss: 0.4383, Train Acc: 0.7140 - Val Loss: 0.6311, Val Acc: 0.5860\n",
      "Fold 5, Epoch 10/15 - Train Loss: 0.3626, Train Acc: 0.7640 - Val Loss: 0.6359, Val Acc: 0.6093\n",
      "Fold 5, Epoch 11/15 - Train Loss: 0.3224, Train Acc: 0.7814 - Val Loss: 0.6053, Val Acc: 0.6233\n",
      "Fold 5, Epoch 12/15 - Train Loss: 0.3135, Train Acc: 0.7814 - Val Loss: 0.6024, Val Acc: 0.6000\n",
      "Fold 5, Epoch 13/15 - Train Loss: 0.3150, Train Acc: 0.7895 - Val Loss: 0.5936, Val Acc: 0.6372\n",
      "Fold 5, Epoch 14/15 - Train Loss: 0.2855, Train Acc: 0.7930 - Val Loss: 0.6232, Val Acc: 0.6186\n",
      "Fold 5, Epoch 15/15 - Train Loss: 0.2442, Train Acc: 0.8326 - Val Loss: 0.6544, Val Acc: 0.5721\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.71      0.79      0.75        19\n",
      "      type-2       0.50      0.58      0.54        26\n",
      "      type-3       0.57      0.43      0.49        61\n",
      "      type-4       0.67      0.79      0.72        76\n",
      "      type-5       0.20      0.25      0.22         4\n",
      "      type-6       0.75      0.55      0.63        11\n",
      "      type-7       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.64       215\n",
      "   macro avg       0.62      0.59      0.60       215\n",
      "weighted avg       0.64      0.64      0.63       215\n",
      "\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[15  3  0  0  0  0  1]\n",
      " [ 4 15  6  1  0  0  0]\n",
      " [ 1  8 26 24  1  1  0]\n",
      " [ 0  3 12 60  1  0  0]\n",
      " [ 1  0  0  2  1  0  0]\n",
      " [ 0  0  0  3  2  6  0]\n",
      " [ 0  1  2  0  0  1 14]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.7895    0.7500        19\n",
      "           1     0.5000    0.5769    0.5357        26\n",
      "           2     0.5652    0.4262    0.4860        61\n",
      "           3     0.6667    0.7895    0.7229        76\n",
      "           4     0.2000    0.2500    0.2222         4\n",
      "           5     0.7500    0.5455    0.6316        11\n",
      "           6     0.9333    0.7778    0.8485        18\n",
      "\n",
      "    accuracy                         0.6372       215\n",
      "   macro avg     0.6185    0.5936    0.5996       215\n",
      "weighted avg     0.6398    0.6372    0.6320       215\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.5209302325581395, 0.6465116279069767, 0.6046511627906976, 0.627906976744186, 0.6372093023255814]]\n",
      "['Mean Accuracy:', np.float64(0.6074418604651163)]\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='mobilenet_v3_large',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=15,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=16,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    seed=42,\n",
    "    num_classes=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4979a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [ 85 110 270 263  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 1.3483, Train Acc: 0.2779 - Val Loss: 1.2287, Val Acc: 0.3116\n",
      "Fold None, Epoch 2/15 - Train Loss: 1.1277, Train Acc: 0.3791 - Val Loss: 0.9899, Val Acc: 0.4093\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.9610, Train Acc: 0.4767 - Val Loss: 0.8523, Val Acc: 0.4512\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.7984, Train Acc: 0.5744 - Val Loss: 0.7394, Val Acc: 0.5302\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.6748, Train Acc: 0.6081 - Val Loss: 0.6649, Val Acc: 0.5488\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.5889, Train Acc: 0.6500 - Val Loss: 0.6483, Val Acc: 0.5628\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.5455, Train Acc: 0.6721 - Val Loss: 0.6470, Val Acc: 0.5395\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.4737, Train Acc: 0.7012 - Val Loss: 0.6112, Val Acc: 0.5814\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.4449, Train Acc: 0.7174 - Val Loss: 0.5528, Val Acc: 0.6279\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.3791, Train Acc: 0.7337 - Val Loss: 0.5617, Val Acc: 0.6140\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.3302, Train Acc: 0.7895 - Val Loss: 0.5432, Val Acc: 0.6093\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.3167, Train Acc: 0.7640 - Val Loss: 0.5318, Val Acc: 0.6419\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.2800, Train Acc: 0.7977 - Val Loss: 0.5164, Val Acc: 0.6558\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.2485, Train Acc: 0.8233 - Val Loss: 0.5233, Val Acc: 0.6512\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.2725, Train Acc: 0.8128 - Val Loss: 0.5209, Val Acc: 0.6465\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.60      0.86      0.71        21\n",
      "      type-2       0.59      0.57      0.58        28\n",
      "      type-3       0.62      0.60      0.61        68\n",
      "      type-4       0.70      0.65      0.67        65\n",
      "      type-5       0.67      0.50      0.57         8\n",
      "      type-6       0.71      0.62      0.67         8\n",
      "      type-7       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.67      0.67      0.66       215\n",
      "weighted avg       0.66      0.66      0.65       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[18  1  0  0  0  0  2]\n",
      " [ 6 16  4  1  0  0  1]\n",
      " [ 3  6 41 17  0  0  1]\n",
      " [ 2  2 18 42  1  0  0]\n",
      " [ 0  0  2  0  4  2  0]\n",
      " [ 0  1  1  0  1  5  0]\n",
      " [ 1  1  0  0  0  0 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.8571    0.7059        21\n",
      "           1     0.5926    0.5714    0.5818        28\n",
      "           2     0.6212    0.6029    0.6119        68\n",
      "           3     0.7000    0.6462    0.6720        65\n",
      "           4     0.6667    0.5000    0.5714         8\n",
      "           5     0.7143    0.6250    0.6667         8\n",
      "           6     0.7895    0.8824    0.8333        17\n",
      "\n",
      "    accuracy                         0.6558       215\n",
      "   macro avg     0.6692    0.6693    0.6633       215\n",
      "weighted avg     0.6577    0.6558    0.6534       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='mobilenet_v3_large',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f386f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [100 111 270 262  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 1.4252, Train Acc: 0.1497 - Val Loss: 1.3597, Val Acc: 0.2557\n",
      "Fold None, Epoch 2/15 - Train Loss: 1.3566, Train Acc: 0.2480 - Val Loss: 1.3260, Val Acc: 0.3059\n",
      "Fold None, Epoch 3/15 - Train Loss: 1.3074, Train Acc: 0.2926 - Val Loss: 1.2779, Val Acc: 0.3562\n",
      "Fold None, Epoch 4/15 - Train Loss: 1.2326, Train Acc: 0.3554 - Val Loss: 1.2260, Val Acc: 0.4018\n",
      "Fold None, Epoch 5/15 - Train Loss: 1.1748, Train Acc: 0.3851 - Val Loss: 1.1556, Val Acc: 0.4064\n",
      "Fold None, Epoch 6/15 - Train Loss: 1.1128, Train Acc: 0.4320 - Val Loss: 1.0714, Val Acc: 0.4521\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.9950, Train Acc: 0.4983 - Val Loss: 0.9776, Val Acc: 0.4886\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.9359, Train Acc: 0.5280 - Val Loss: 0.9076, Val Acc: 0.4977\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.8530, Train Acc: 0.5543 - Val Loss: 0.8295, Val Acc: 0.5342\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.7801, Train Acc: 0.5749 - Val Loss: 0.7839, Val Acc: 0.5297\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.7227, Train Acc: 0.5989 - Val Loss: 0.7129, Val Acc: 0.5525\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.6504, Train Acc: 0.6274 - Val Loss: 0.6431, Val Acc: 0.5799\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.5668, Train Acc: 0.6663 - Val Loss: 0.6146, Val Acc: 0.5571\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.5009, Train Acc: 0.6857 - Val Loss: 0.6075, Val Acc: 0.5525\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.4435, Train Acc: 0.7257 - Val Loss: 0.5430, Val Acc: 0.6164\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.75      0.96      0.84        25\n",
      "      type-2       0.44      0.41      0.42        27\n",
      "      type-3       0.56      0.44      0.49        68\n",
      "      type-4       0.65      0.68      0.67        66\n",
      "      type-5       0.42      0.62      0.50         8\n",
      "      type-6       0.83      0.62      0.71         8\n",
      "      type-7       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.62       219\n",
      "   macro avg       0.62      0.66      0.63       219\n",
      "weighted avg       0.61      0.62      0.61       219\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[24  0  0  0  0  0  1]\n",
      " [ 5 11  7  2  1  0  1]\n",
      " [ 1 12 30 20  3  0  2]\n",
      " [ 2  1 17 45  0  0  1]\n",
      " [ 0  1  0  1  5  1  0]\n",
      " [ 0  0  0  1  1  5  1]\n",
      " [ 0  0  0  0  2  0 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.9600    0.8421        25\n",
      "           1     0.4400    0.4074    0.4231        27\n",
      "           2     0.5556    0.4412    0.4918        68\n",
      "           3     0.6522    0.6818    0.6667        66\n",
      "           4     0.4167    0.6250    0.5000         8\n",
      "           5     0.8333    0.6250    0.7143         8\n",
      "           6     0.7143    0.8824    0.7895        17\n",
      "\n",
      "    accuracy                         0.6164       219\n",
      "   macro avg     0.6231    0.6604    0.6325       219\n",
      "weighted avg     0.6100    0.6164    0.6076       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [100 111 270 262  31  34  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 1.4120, Train Acc: 0.1749 - Val Loss: 1.2051, Val Acc: 0.3425\n",
      "Fold None, Epoch 2/20 - Train Loss: 1.2750, Train Acc: 0.2720 - Val Loss: 1.1779, Val Acc: 0.3470\n",
      "Fold None, Epoch 3/20 - Train Loss: 1.1859, Train Acc: 0.3154 - Val Loss: 1.1232, Val Acc: 0.3790\n",
      "Fold None, Epoch 4/20 - Train Loss: 1.1256, Train Acc: 0.3749 - Val Loss: 1.0569, Val Acc: 0.3836\n",
      "Fold None, Epoch 5/20 - Train Loss: 1.0594, Train Acc: 0.4206 - Val Loss: 1.0140, Val Acc: 0.3927\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.9753, Train Acc: 0.4720 - Val Loss: 0.9710, Val Acc: 0.4018\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.9627, Train Acc: 0.4583 - Val Loss: 0.9287, Val Acc: 0.4521\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.9476, Train Acc: 0.4514 - Val Loss: 0.8917, Val Acc: 0.4840\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.8636, Train Acc: 0.5177 - Val Loss: 0.8702, Val Acc: 0.4703\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.8627, Train Acc: 0.4949 - Val Loss: 0.8426, Val Acc: 0.4932\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.8206, Train Acc: 0.5269 - Val Loss: 0.8383, Val Acc: 0.4977\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.8445, Train Acc: 0.5029 - Val Loss: 0.8152, Val Acc: 0.4840\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.8184, Train Acc: 0.5063 - Val Loss: 0.8145, Val Acc: 0.5023\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.7660, Train Acc: 0.5394 - Val Loss: 0.7903, Val Acc: 0.5251\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.7296, Train Acc: 0.5543 - Val Loss: 0.7722, Val Acc: 0.5251\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.7258, Train Acc: 0.5463 - Val Loss: 0.8139, Val Acc: 0.5068\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.6827, Train Acc: 0.5943 - Val Loss: 0.8204, Val Acc: 0.4658\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.6815, Train Acc: 0.5920 - Val Loss: 0.7865, Val Acc: 0.4840\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.6395, Train Acc: 0.6274 - Val Loss: 0.7706, Val Acc: 0.5160\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.6568, Train Acc: 0.5966 - Val Loss: 0.7946, Val Acc: 0.5023\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.51      0.80      0.62        25\n",
      "      type-2       0.32      0.30      0.31        27\n",
      "      type-3       0.45      0.44      0.45        68\n",
      "      type-4       0.65      0.48      0.56        66\n",
      "      type-5       0.31      0.62      0.42         8\n",
      "      type-6       0.62      0.62      0.62         8\n",
      "      type-7       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.52       219\n",
      "   macro avg       0.53      0.58      0.54       219\n",
      "weighted avg       0.53      0.52      0.52       219\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[20  0  4  0  0  0  1]\n",
      " [ 5  8  7  2  2  2  1]\n",
      " [11  9 30 13  3  1  1]\n",
      " [ 3  4 23 32  4  0  0]\n",
      " [ 0  2  0  1  5  0  0]\n",
      " [ 0  1  0  1  1  5  0]\n",
      " [ 0  1  2  0  1  0 13]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5128    0.8000    0.6250        25\n",
      "           1     0.3200    0.2963    0.3077        27\n",
      "           2     0.4545    0.4412    0.4478        68\n",
      "           3     0.6531    0.4848    0.5565        66\n",
      "           4     0.3125    0.6250    0.4167         8\n",
      "           5     0.6250    0.6250    0.6250         8\n",
      "           6     0.8125    0.7647    0.7879        17\n",
      "\n",
      "    accuracy                         0.5160       219\n",
      "   macro avg     0.5272    0.5767    0.5381       219\n",
      "weighted avg     0.5333    0.5160    0.5152       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prestera inte jÃ¤tte bra. mobilenet_v2 Ã¤r bÃ¤ttre \n",
    "\n",
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='mobilenet_v3_large',\n",
    "    freeze_until='features.7',  # or 'features.4', None for no freezing.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4e3a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ALL LOGS ====\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.72      0.72      0.72        25\n",
      "      type-2       0.55      0.72      0.62        25\n",
      "      type-3       0.53      0.49      0.51        65\n",
      "      type-4       0.72      0.64      0.68        61\n",
      "      type-5       0.50      0.83      0.62         6\n",
      "      type-6       0.60      0.60      0.60         5\n",
      "      type-7       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.63       202\n",
      "   macro avg       0.63      0.69      0.65       202\n",
      "weighted avg       0.64      0.63      0.63       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = get_logs()\n",
    "\n",
    "print(\"==== ALL LOGS ====\")\n",
    "for log in logs:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66e56a",
   "metadata": {},
   "source": [
    "# To load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "366e5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = models.efficientnet_b0()\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, NUM_CLASSES)\n",
    "    )\n",
    "    state_dict = torch.load(model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd415c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "\n",
    "# model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323635fe",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d8adc",
   "metadata": {},
   "source": [
    "### Save as .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to stool_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. Define where to save\n",
    "SAVE_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "# 2. Save the state_dict\n",
    "#torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"Model weights saved to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd490f",
   "metadata": {},
   "source": [
    "### Save as .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfcdfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â ONNX export completed: stool_model.onnx\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Create dummy input for ONNX export (batch_size=1, 3 channels, IMG_SIZE x IMG_SIZE)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,                               # your trained model\n",
    "    dummy_input,                         # input tensor\n",
    "    \"stool_model.onnx\",                  # output file name\n",
    "    export_params=True,                  # store weights inside the model file\n",
    "    opset_version=11,                    # ONNX opset version\n",
    "    do_constant_folding=True,            # fold constant values for optimization\n",
    "    input_names=['input'],               # name for the input layer\n",
    "    output_names=['output'],             # name for the output layer\n",
    "    dynamic_axes={                      # allow variable input sizes\n",
    "        'input': {0: 'batch_size'},     \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"â ONNX export completed: stool_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
