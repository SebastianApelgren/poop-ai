{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a12e02",
   "metadata": {},
   "source": [
    "# Imports and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1550a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f0bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abb92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_confusion_matrix(cm):\n",
    "    \"\"\"Returns a string of a nicely formatted confusion matrix with indices and highlighted diagonal.\"\"\"\n",
    "    headers = [\"\"] + [f\"Pred {i}\" for i in range(len(cm[0]))]\n",
    "    table = []\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        formatted_row = []\n",
    "        for j, val in enumerate(row):\n",
    "            if i == j:\n",
    "                formatted_row.append(f\"*{val}*\")  # Highlight diagonal\n",
    "            else:\n",
    "                formatted_row.append(str(val))\n",
    "        table.append([f\"True {i}\"] + formatted_row)\n",
    "\n",
    "    return tabulate(table, headers=headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38680489",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = []\n",
    "\n",
    "def log_and_store(*msgs, table_format=False, is_confmat=False):\n",
    "    \"\"\"\n",
    "    Logs plain messages or pretty-prints confusion matrices or tables.\n",
    "    \"\"\"\n",
    "    if is_confmat and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = format_confusion_matrix(msgs[0])\n",
    "    elif table_format and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = tabulate(msgs[0], tablefmt=\"grid\")\n",
    "    else:\n",
    "        msg = \" \".join(str(m) for m in msgs)\n",
    "\n",
    "    print(msg)\n",
    "    all_logs.append(msg)\n",
    "\n",
    "def get_logs():\n",
    "    \"\"\"\n",
    "    Returnerar en lista med alla loggade meddelanden.\n",
    "    \"\"\"\n",
    "    return all_logs\n",
    "\n",
    "def clear_logs():\n",
    "    \"\"\"\n",
    "    Tömmer loggen.\n",
    "    \"\"\"\n",
    "    all_logs.clear()\n",
    "\n",
    "def save_logs_to_file(filename):\n",
    "    \"\"\"\n",
    "    Sparar loggade meddelanden till en fil.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for log in all_logs:\n",
    "            f.write(log + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ba160",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5ca921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../data-pools/data-consistence\"  # Update this path\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0eb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoolDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(class_path, fname), idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3e8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger and more varied augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.Lambda(lambda img: img.filter(ImageFilter.FIND_EDGES))], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a1c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FocalLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ace8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    if backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        # freeze layers\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        # Replace final classifier\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9174d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return None, None, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae38d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx, use_best_loss):\n",
    "\n",
    "    #patience = 3\n",
    "    #counter = 0\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) # for accuracy\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) # for loss\n",
    "\n",
    "    best_acc     = 0.0\n",
    "    best_loss    = float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ── One‐Cycle LR schedule ──────────────────────────────────────────────────\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=optimizer.param_groups[0]['lr'] * 10,  # e.g. 10× your base LR\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch = val_corrects / val_total\n",
    "        \n",
    "        # keep snapshot of best‐ever validation loss (for final restore)\n",
    "        if use_best_loss:\n",
    "            if val_loss_epoch < best_loss:\n",
    "                best_loss    = val_loss_epoch\n",
    "                best_acc     = val_acc_epoch\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if val_acc_epoch > best_acc:\n",
    "                best_loss = val_loss_epoch\n",
    "                print(f\"New best model found with accuracy {val_acc_epoch:.4f} and previous best {best_acc:.4f}\")\n",
    "                best_acc = val_acc_epoch\n",
    "                best_weights = model.state_dict().copy()\n",
    "            elif val_acc_epoch == best_acc:\n",
    "                # If accuracy is the same, prefer lower loss\n",
    "                if val_loss_epoch < best_loss:\n",
    "                    best_loss = val_loss_epoch\n",
    "                    best_weights = model.state_dict().copy()\n",
    "\n",
    "        print(f\"Fold {fold_idx}, Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        #if val_acc_epoch > best_acc:\n",
    "        #    best_acc = val_acc_epoch\n",
    "        #   best_weights = model.state_dict().copy()\n",
    "        #   counter = 0\n",
    "        #else:\n",
    "        #    counter += 1\n",
    "        #    if counter >= patience:\n",
    "        #        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #       break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Final validation metrics\n",
    "    # _, _, preds, labels = evaluate_model(model, val_loader)\n",
    "    # log_and_store(\"\\nClassification Report for Fold {}:\".format(fold_idx))\n",
    "    # log_and_store(classification_report(labels, preds, target_names=sorted(os.listdir(data_dir)), digits=4))\n",
    "\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866de657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a5431",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97447537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(\n",
    "    data_dir,\n",
    "    backbone,\n",
    "    loss_fn,\n",
    "    freeze_until_layer=None,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    k_folds=3,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    use_best_loss=False, # Use best loss for validation, otherwise use best accuracy\n",
    "):\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "\n",
    "    # Class weights for full dataset (optional, for balance insights)\n",
    "    all_labels_full = [label for _, label in full_dataset]\n",
    "    class_counts = np.bincount(all_labels_full)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights_full = [class_weights[label] for label in all_labels_full]\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    fold_models = []\n",
    "    fold_accuracies = []\n",
    "    per_fold_recalls = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices, all_labels_full), 1):\n",
    "        print(f\"\\n======= Fold {fold_idx} =======\")\n",
    "\n",
    "        # Subset + transforms\n",
    "        train_ds = torch.utils.data.Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "        val_ds   = torch.utils.data.Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "        # Weighted sampler\n",
    "        train_labels_fold = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "        class_sample_count_fold = np.array([train_labels_fold.count(i) for i in range(num_classes)])\n",
    "\n",
    "        print(f\"Class sample counts: {class_sample_count_fold}\")\n",
    "        \n",
    "        class_weights_fold = 1.0 / class_sample_count_fold\n",
    "        sample_weights_fold = np.array([class_weights_fold[label] for label in train_labels_fold])\n",
    "        sample_weights_fold = torch.from_numpy(sample_weights_fold.astype(np.double))\n",
    "        sampler_fold = WeightedRandomSampler(sample_weights_fold, num_samples=len(sample_weights_fold), replacement=True)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler_fold)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        print(f\"Training set length: {len(train_loader.dataset)}\")\n",
    "        print(f\"Validation set length: {len(val_loader.dataset)}\")\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(backbone=backbone,num_classes=num_classes , freeze_until_layer=freeze_until_layer)\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # Train\n",
    "        best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx, use_best_loss)\n",
    "        fold_models.append(best_model)\n",
    "        fold_accuracies.append(best_acc)\n",
    "\n",
    "        # Evaluate and log\n",
    "        best_model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = best_model(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(yb.numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        crpt = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "        cr_dict = classification_report(all_labels, all_preds, digits=4, output_dict=True)\n",
    "        recalls = {cls: metrics[\"recall\"] for cls, metrics in cr_dict.items() if cls.isdigit()}\n",
    "        per_fold_recalls.append(recalls)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Confusion Matrix ---\")\n",
    "        log_and_store(cm, is_confmat=True)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Classification Report ---\")\n",
    "        log_and_store(crpt)\n",
    "\n",
    "    log_and_store([\"\\nFold Models:\", [f\"Fold {i+1}\" for i in range(len(fold_models))]])\n",
    "    log_and_store([\"Fold Accuracies:\", fold_accuracies])\n",
    "    log_and_store([\"Mean Accuracy:\", np.mean(fold_accuracies)])\n",
    "\n",
    "    # Aggregate and average recalls\n",
    "    average_recalls = defaultdict(list)\n",
    "    for recall_dict in per_fold_recalls:\n",
    "        for cls, value in recall_dict.items():\n",
    "            average_recalls[cls].append(value)\n",
    "\n",
    "    average_recalls = {cls: np.mean(vals) for cls, vals in average_recalls.items()}\n",
    "    log_and_store([\"Average Recalls:\", average_recalls])\n",
    "\n",
    "\n",
    "    return fold_models, fold_accuracies, average_recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aecbdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_split(\n",
    "    data_dir,\n",
    "    model_name,\n",
    "    loss_fn, \n",
    "    freeze_until=None,\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    print(\"======= Single Split Training =======\")\n",
    "\n",
    "    # Full dataset\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    all_labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=val_split, random_state=seed, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Create datasets with transforms\n",
    "    train_ds = Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "    val_ds = Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "    # Weighted sampler for class imbalance\n",
    "    train_labels = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "    class_sample_counts = np.array([train_labels.count(i) for i in range(num_classes)])\n",
    "\n",
    "    print(f\"Class sample counts: {class_sample_counts}\")\n",
    "    \n",
    "    class_weights = 1.0 / class_sample_counts\n",
    "    sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights.astype(np.double))\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = create_model(backbone=model_name, freeze_until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    # Train\n",
    "    best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx=None, use_best_loss=False)\n",
    "\n",
    "    # Evaluation\n",
    "    best_model.eval()\n",
    "    all_preds, all_labels_eval = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = best_model(xb).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_eval.extend(yb.numpy())\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels_eval, all_preds)\n",
    "    cr = classification_report(all_labels_eval, all_preds, digits=4)\n",
    "\n",
    "    log_and_store(\"--- Confusion Matrix ---\")\n",
    "    log_and_store(cm, is_confmat=True)\n",
    "    log_and_store(\"--- Classification Report ---\")\n",
    "    log_and_store(cr)\n",
    "\n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d222b",
   "metadata": {},
   "source": [
    "# Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24c9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data_dir = \"../datasets/data-consistence\"\n",
    "constipation_data_dir = \"../datasets/data-constipated\"\n",
    "normal_data_dir = \"../datasets/data-normal\"\n",
    "loose_data_dir = \"../datasets/data-loose\"\n",
    "\n",
    "smooth = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "focal = FocalLoss(alpha=1, gamma=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ab6f8",
   "metadata": {},
   "source": [
    "# Model saving fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6229d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingEnsemble(nn.Module):\n",
    "    def __init__(self, models, weights=None):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        if weights is None:\n",
    "            self.register_buffer(\"weights\", torch.ones(len(models)) / len(models))\n",
    "        else:\n",
    "            w = torch.tensor(weights, dtype=torch.float32)\n",
    "            self.register_buffer(\"weights\", w / w.sum())\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [m(x) for m in self.models]                  # list of [B, C]\n",
    "        stacked = torch.stack(outs, dim=0)                  # [K, B, C]\n",
    "        weighted = stacked * self.weights.view(-1, 1, 1)    # broadcast weights\n",
    "        return weighted.sum(dim=0)                          # [B, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d33a758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ensemble_to_onnx(kf_models, accs=None, output_path=\"ensemble.onnx\"):\n",
    "    \"\"\"\n",
    "    Saves the ensemble of models to an ONNX file.\n",
    "    \"\"\"\n",
    "    for m in kf_models:\n",
    "        m.eval()\n",
    "        m.to(\"cpu\")\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    ensemble = AveragingEnsemble(kf_models, weights=accs)  # or None for equal weights\n",
    "    ensemble.eval()\n",
    "    \n",
    "    dummy = torch.randn(1, 3, 224, 224)  # adapt shape/channels\n",
    "\n",
    "    torch.onnx.export(\n",
    "        ensemble,\n",
    "        dummy,\n",
    "        output_path,\n",
    "        opset_version=13,\n",
    "        input_names=[\"image\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes={\"image\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "        do_constant_folding=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22cdce",
   "metadata": {},
   "source": [
    "# Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "398766e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../datasets/data-BSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3160f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "type-1: 65 images\n",
      "type-2: 92 images\n",
      "type-3: 323 images\n",
      "type-4: 326 images\n",
      "type-5: 39 images\n",
      "type-6: 42 images\n",
      "type-7: 84 images\n",
      "{1: 65, 2: 92, 3: 323, 4: 326, 5: 39, 6: 42, 7: 84}\n"
     ]
    }
   ],
   "source": [
    "class_folders = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "for class_name in class_folders:\n",
    "    class_path = os.path.join(DATA_DIR, class_name)\n",
    "    # Count only files (ignore hidden/system files)\n",
    "    files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "    class_counts[class_name] = len(files)\n",
    "\n",
    "# Print class counts\n",
    "print(\"Class counts:\")\n",
    "type_counts = {}\n",
    "type = 1\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "    type_counts[type] = count\n",
    "    type += 1\n",
    "\n",
    "print(type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb2150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hierarchical_accuracy(\n",
    "    consistency_recalls: dict,\n",
    "    subtype_accuracies: dict,\n",
    "    type_counts: dict = type_counts\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the overall hierarchical classification accuracy.\n",
    "\n",
    "    Args:\n",
    "        type_counts: dict mapping BSS type (1-7) to number of samples.\n",
    "                     e.g., {1: 100, 2: 120, 3: 130, ..., 7: 80}\n",
    "        consistency_recalls: dict mapping consistency class to recall.\n",
    "                     Keys: 'constipated', 'normal', 'loose'.\n",
    "                     e.g., {'constipated': 0.80, 'normal': 0.85, 'loose': 0.78}\n",
    "        subtype_accuracies: dict mapping consistency class to the accuracy of the\n",
    "                            subtype CNN within that class.\n",
    "                     e.g., {'constipated': 0.72, 'normal': 0.83, 'loose': 0.69}\n",
    "\n",
    "    Returns:\n",
    "        float: overall hierarchical accuracy\n",
    "    \"\"\"\n",
    "    # Define consistency groups\n",
    "    consistency_groups = {\n",
    "        'constipated': [1, 2],\n",
    "        'normal': [3, 4, 5],\n",
    "        'loose': [6, 7]\n",
    "    }\n",
    "\n",
    "    total_samples = sum(type_counts.values())\n",
    "    hierarchical_accuracy = 0.0\n",
    "\n",
    "    for group, types in consistency_groups.items():\n",
    "        # Count how many samples are in this group\n",
    "        group_count = sum(type_counts[t] for t in types)\n",
    "\n",
    "        # Proportion of the dataset in this consistency group\n",
    "        P_c = group_count / total_samples\n",
    "\n",
    "        # Multiply by consistency recall and subtype accuracy\n",
    "        A_c = consistency_recalls.get(group, 0.0)\n",
    "        A_s_given_c = subtype_accuracies.get(group, 0.0)\n",
    "\n",
    "        hierarchical_accuracy += P_c * A_c * A_s_given_c\n",
    "\n",
    "    return hierarchical_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767938b",
   "metadata": {},
   "source": [
    "# Category Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3399b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163330.46s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "!find ../datasets/data-consistence -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bf3e0",
   "metadata": {},
   "source": [
    "## Single Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffdec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [128 100 550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 0.4715, Train Acc: 0.4306 - Val Loss: 0.4329, Val Acc: 0.5385\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.4060, Train Acc: 0.5643 - Val Loss: 0.3614, Val Acc: 0.6359\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.3573, Train Acc: 0.6221 - Val Loss: 0.3038, Val Acc: 0.7436\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.3081, Train Acc: 0.7018 - Val Loss: 0.2511, Val Acc: 0.7744\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.2899, Train Acc: 0.7147 - Val Loss: 0.2146, Val Acc: 0.8000\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.2411, Train Acc: 0.7468 - Val Loss: 0.1884, Val Acc: 0.8513\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.2205, Train Acc: 0.7648 - Val Loss: 0.1746, Val Acc: 0.8667\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.1894, Train Acc: 0.8162 - Val Loss: 0.1606, Val Acc: 0.8410\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.1920, Train Acc: 0.8111 - Val Loss: 0.1506, Val Acc: 0.8256\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.1648, Train Acc: 0.8213 - Val Loss: 0.1456, Val Acc: 0.8308\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.1554, Train Acc: 0.8252 - Val Loss: 0.1672, Val Acc: 0.8051\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.1519, Train Acc: 0.8303 - Val Loss: 0.1629, Val Acc: 0.8051\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.1392, Train Acc: 0.8368 - Val Loss: 0.1534, Val Acc: 0.8308\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.1291, Train Acc: 0.8650 - Val Loss: 0.1490, Val Acc: 0.8256\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.1085, Train Acc: 0.8895 - Val Loss: 0.1411, Val Acc: 0.8410\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.0984, Train Acc: 0.8985 - Val Loss: 0.1374, Val Acc: 0.8410\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.0881, Train Acc: 0.8830 - Val Loss: 0.1460, Val Acc: 0.8462\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.1015, Train Acc: 0.9036 - Val Loss: 0.1400, Val Acc: 0.8462\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.0871, Train Acc: 0.9023 - Val Loss: 0.1364, Val Acc: 0.8462\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.0914, Train Acc: 0.9087 - Val Loss: 0.1521, Val Acc: 0.8205\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated     0.6471    0.6875    0.6667        32\n",
      "       loose     0.7407    0.8000    0.7692        25\n",
      "      normal     0.9179    0.8913    0.9044       138\n",
      "\n",
      "    accuracy                         0.8462       195\n",
      "   macro avg     0.7686    0.7929    0.7801       195\n",
      "weighted avg     0.8507    0.8462    0.8481       195\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 22   3   7]\n",
      " [  1  20   4]\n",
      " [ 11   4 123]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6471    0.6875    0.6667        32\n",
      "           1     0.7407    0.8000    0.7692        25\n",
      "           2     0.9179    0.8913    0.9044       138\n",
      "\n",
      "    accuracy                         0.8462       195\n",
      "   macro avg     0.7686    0.7929    0.7801       195\n",
      "weighted avg     0.8507    0.8462    0.8481       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=category_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=focal, # focal or smooth\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [128 100 550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 1.0707, Train Acc: 0.4422 - Val Loss: 1.0217, Val Acc: 0.5590\n",
      "Fold None, Epoch 2/20 - Train Loss: 1.0113, Train Acc: 0.5334 - Val Loss: 0.9877, Val Acc: 0.5026\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.9315, Train Acc: 0.6272 - Val Loss: 0.8982, Val Acc: 0.6564\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.8479, Train Acc: 0.6864 - Val Loss: 0.8357, Val Acc: 0.6872\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.8122, Train Acc: 0.6992 - Val Loss: 0.7616, Val Acc: 0.7487\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.7581, Train Acc: 0.7314 - Val Loss: 0.7368, Val Acc: 0.7744\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.7167, Train Acc: 0.7545 - Val Loss: 0.6781, Val Acc: 0.7949\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.6938, Train Acc: 0.7686 - Val Loss: 0.6585, Val Acc: 0.7949\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.6546, Train Acc: 0.8021 - Val Loss: 0.6492, Val Acc: 0.7795\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.6462, Train Acc: 0.7905 - Val Loss: 0.6013, Val Acc: 0.8154\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.6231, Train Acc: 0.8059 - Val Loss: 0.5925, Val Acc: 0.8308\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.5798, Train Acc: 0.8522 - Val Loss: 0.6102, Val Acc: 0.8205\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.5519, Train Acc: 0.8560 - Val Loss: 0.5956, Val Acc: 0.8205\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.5467, Train Acc: 0.8702 - Val Loss: 0.5832, Val Acc: 0.8410\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.4991, Train Acc: 0.8972 - Val Loss: 0.5722, Val Acc: 0.8359\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.5119, Train Acc: 0.9036 - Val Loss: 0.5630, Val Acc: 0.8359\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.4917, Train Acc: 0.8895 - Val Loss: 0.5685, Val Acc: 0.8615\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.4735, Train Acc: 0.9126 - Val Loss: 0.5781, Val Acc: 0.8513\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.4549, Train Acc: 0.9126 - Val Loss: 0.5528, Val Acc: 0.8462\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.4538, Train Acc: 0.9177 - Val Loss: 0.5977, Val Acc: 0.8410\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated     0.6176    0.6562    0.6364        32\n",
      "       loose     0.7308    0.7600    0.7451        25\n",
      "      normal     0.9259    0.9058    0.9158       138\n",
      "\n",
      "    accuracy                         0.8462       195\n",
      "   macro avg     0.7581    0.7740    0.7657       195\n",
      "weighted avg     0.8503    0.8462    0.8480       195\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 21   5   6]\n",
      " [  2  19   4]\n",
      " [ 11   2 125]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6176    0.6562    0.6364        32\n",
      "           1     0.7308    0.7600    0.7451        25\n",
      "           2     0.9259    0.9058    0.9158       138\n",
      "\n",
      "    accuracy                         0.8462       195\n",
      "   macro avg     0.7581    0.7740    0.7657       195\n",
      "weighted avg     0.8503    0.8462    0.8480       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=category_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # focal or smooth\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecca0c",
   "metadata": {},
   "source": [
    "## K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [128 100 550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/20 - Train Loss: 0.4679, Train Acc: 0.4267 - Val Loss: 0.4052, Val Acc: 0.5487\n",
      "Fold 1, Epoch 2/20 - Train Loss: 0.3144, Train Acc: 0.6620 - Val Loss: 0.2260, Val Acc: 0.7744\n",
      "Fold 1, Epoch 3/20 - Train Loss: 0.1779, Train Acc: 0.8123 - Val Loss: 0.2251, Val Acc: 0.7333\n",
      "Fold 1, Epoch 4/20 - Train Loss: 0.1653, Train Acc: 0.8329 - Val Loss: 0.2590, Val Acc: 0.7179\n",
      "Fold 1, Epoch 5/20 - Train Loss: 0.1718, Train Acc: 0.8303 - Val Loss: 0.3171, Val Acc: 0.7128\n",
      "Fold 1, Epoch 6/20 - Train Loss: 0.1709, Train Acc: 0.8136 - Val Loss: 0.4068, Val Acc: 0.6974\n",
      "Fold 1, Epoch 7/20 - Train Loss: 0.1353, Train Acc: 0.8393 - Val Loss: 0.3135, Val Acc: 0.7590\n",
      "Fold 1, Epoch 8/20 - Train Loss: 0.1420, Train Acc: 0.8432 - Val Loss: 0.2431, Val Acc: 0.7744\n",
      "Fold 1, Epoch 9/20 - Train Loss: 0.1637, Train Acc: 0.8226 - Val Loss: 0.3554, Val Acc: 0.6974\n",
      "Fold 1, Epoch 10/20 - Train Loss: 0.1282, Train Acc: 0.8702 - Val Loss: 0.4030, Val Acc: 0.6923\n",
      "Fold 1, Epoch 11/20 - Train Loss: 0.0951, Train Acc: 0.8946 - Val Loss: 0.3996, Val Acc: 0.6974\n",
      "Fold 1, Epoch 12/20 - Train Loss: 0.0851, Train Acc: 0.9075 - Val Loss: 0.3074, Val Acc: 0.7590\n",
      "Fold 1, Epoch 13/20 - Train Loss: 0.0643, Train Acc: 0.9409 - Val Loss: 0.3605, Val Acc: 0.7026\n",
      "Fold 1, Epoch 14/20 - Train Loss: 0.0571, Train Acc: 0.9409 - Val Loss: 0.3058, Val Acc: 0.7744\n",
      "Fold 1, Epoch 15/20 - Train Loss: 0.0524, Train Acc: 0.9512 - Val Loss: 0.3054, Val Acc: 0.7641\n",
      "Fold 1, Epoch 16/20 - Train Loss: 0.0463, Train Acc: 0.9434 - Val Loss: 0.3574, Val Acc: 0.7590\n",
      "Fold 1, Epoch 17/20 - Train Loss: 0.0405, Train Acc: 0.9589 - Val Loss: 0.3576, Val Acc: 0.7692\n",
      "Fold 1, Epoch 18/20 - Train Loss: 0.0374, Train Acc: 0.9614 - Val Loss: 0.3671, Val Acc: 0.7641\n",
      "Fold 1, Epoch 19/20 - Train Loss: 0.0265, Train Acc: 0.9692 - Val Loss: 0.3484, Val Acc: 0.7795\n",
      "Fold 1, Epoch 20/20 - Train Loss: 0.0374, Train Acc: 0.9614 - Val Loss: 0.3558, Val Acc: 0.7641\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 19   4   9]\n",
      " [  1  19   5]\n",
      " [ 25   8 105]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4222    0.5938    0.4935        32\n",
      "           1     0.6129    0.7600    0.6786        25\n",
      "           2     0.8824    0.7609    0.8171       138\n",
      "\n",
      "    accuracy                         0.7333       195\n",
      "   macro avg     0.6392    0.7049    0.6631       195\n",
      "weighted avg     0.7723    0.7333    0.7463       195\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [128 100 550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/20 - Train Loss: 0.4643, Train Acc: 0.4537 - Val Loss: 0.3661, Val Acc: 0.5692\n",
      "Fold 2, Epoch 2/20 - Train Loss: 0.3222, Train Acc: 0.6594 - Val Loss: 0.2388, Val Acc: 0.7590\n",
      "Fold 2, Epoch 3/20 - Train Loss: 0.2079, Train Acc: 0.7648 - Val Loss: 0.2288, Val Acc: 0.7744\n",
      "Fold 2, Epoch 4/20 - Train Loss: 0.1524, Train Acc: 0.8393 - Val Loss: 0.3820, Val Acc: 0.6359\n",
      "Fold 2, Epoch 5/20 - Train Loss: 0.1799, Train Acc: 0.7918 - Val Loss: 0.2771, Val Acc: 0.7282\n",
      "Fold 2, Epoch 6/20 - Train Loss: 0.1860, Train Acc: 0.8175 - Val Loss: 0.2993, Val Acc: 0.8000\n",
      "Fold 2, Epoch 7/20 - Train Loss: 0.1683, Train Acc: 0.8111 - Val Loss: 0.3292, Val Acc: 0.7641\n",
      "Fold 2, Epoch 8/20 - Train Loss: 0.1422, Train Acc: 0.8329 - Val Loss: 0.3661, Val Acc: 0.7744\n",
      "Fold 2, Epoch 9/20 - Train Loss: 0.1112, Train Acc: 0.8663 - Val Loss: 0.2956, Val Acc: 0.7744\n",
      "Fold 2, Epoch 10/20 - Train Loss: 0.1075, Train Acc: 0.8817 - Val Loss: 0.3109, Val Acc: 0.7795\n",
      "Fold 2, Epoch 11/20 - Train Loss: 0.0984, Train Acc: 0.8985 - Val Loss: 0.4171, Val Acc: 0.7128\n",
      "Fold 2, Epoch 12/20 - Train Loss: 0.0718, Train Acc: 0.9203 - Val Loss: 0.3427, Val Acc: 0.8154\n",
      "Fold 2, Epoch 13/20 - Train Loss: 0.0839, Train Acc: 0.9023 - Val Loss: 0.2999, Val Acc: 0.7846\n",
      "Fold 2, Epoch 14/20 - Train Loss: 0.0819, Train Acc: 0.9152 - Val Loss: 0.2878, Val Acc: 0.7744\n",
      "Fold 2, Epoch 15/20 - Train Loss: 0.0632, Train Acc: 0.9344 - Val Loss: 0.3153, Val Acc: 0.8051\n",
      "Fold 2, Epoch 16/20 - Train Loss: 0.0512, Train Acc: 0.9473 - Val Loss: 0.3195, Val Acc: 0.8154\n",
      "Fold 2, Epoch 17/20 - Train Loss: 0.0444, Train Acc: 0.9473 - Val Loss: 0.3297, Val Acc: 0.8205\n",
      "Fold 2, Epoch 18/20 - Train Loss: 0.0456, Train Acc: 0.9627 - Val Loss: 0.3344, Val Acc: 0.7949\n",
      "Fold 2, Epoch 19/20 - Train Loss: 0.0322, Train Acc: 0.9730 - Val Loss: 0.3310, Val Acc: 0.8000\n",
      "Fold 2, Epoch 20/20 - Train Loss: 0.0416, Train Acc: 0.9563 - Val Loss: 0.3440, Val Acc: 0.7795\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 13   3  16]\n",
      " [  1  19   5]\n",
      " [ 17   2 119]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4194    0.4062    0.4127        32\n",
      "           1     0.7917    0.7600    0.7755        25\n",
      "           2     0.8500    0.8623    0.8561       138\n",
      "\n",
      "    accuracy                         0.7744       195\n",
      "   macro avg     0.6870    0.6762    0.6814       195\n",
      "weighted avg     0.7719    0.7744    0.7730       195\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [128 100 550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/20 - Train Loss: 0.4815, Train Acc: 0.4139 - Val Loss: 0.3795, Val Acc: 0.6154\n",
      "Fold 3, Epoch 2/20 - Train Loss: 0.3385, Train Acc: 0.6465 - Val Loss: 0.2247, Val Acc: 0.7641\n",
      "Fold 3, Epoch 3/20 - Train Loss: 0.2108, Train Acc: 0.7918 - Val Loss: 0.2213, Val Acc: 0.7026\n",
      "Fold 3, Epoch 4/20 - Train Loss: 0.1966, Train Acc: 0.7776 - Val Loss: 0.1839, Val Acc: 0.7744\n",
      "Fold 3, Epoch 5/20 - Train Loss: 0.2034, Train Acc: 0.7931 - Val Loss: 0.2138, Val Acc: 0.7846\n",
      "Fold 3, Epoch 6/20 - Train Loss: 0.1866, Train Acc: 0.8085 - Val Loss: 0.2593, Val Acc: 0.7128\n",
      "Fold 3, Epoch 7/20 - Train Loss: 0.1602, Train Acc: 0.8278 - Val Loss: 0.3112, Val Acc: 0.6974\n",
      "Fold 3, Epoch 8/20 - Train Loss: 0.1276, Train Acc: 0.8470 - Val Loss: 0.1995, Val Acc: 0.8359\n",
      "Fold 3, Epoch 9/20 - Train Loss: 0.1189, Train Acc: 0.8792 - Val Loss: 0.2026, Val Acc: 0.7795\n",
      "Fold 3, Epoch 10/20 - Train Loss: 0.1097, Train Acc: 0.8702 - Val Loss: 0.1929, Val Acc: 0.8103\n",
      "Fold 3, Epoch 11/20 - Train Loss: 0.0985, Train Acc: 0.8843 - Val Loss: 0.1825, Val Acc: 0.8256\n",
      "Fold 3, Epoch 12/20 - Train Loss: 0.0962, Train Acc: 0.8907 - Val Loss: 0.1879, Val Acc: 0.8462\n",
      "Fold 3, Epoch 13/20 - Train Loss: 0.0796, Train Acc: 0.9126 - Val Loss: 0.2079, Val Acc: 0.8308\n",
      "Fold 3, Epoch 14/20 - Train Loss: 0.0639, Train Acc: 0.9319 - Val Loss: 0.1786, Val Acc: 0.8410\n",
      "Fold 3, Epoch 15/20 - Train Loss: 0.0721, Train Acc: 0.9306 - Val Loss: 0.1938, Val Acc: 0.8000\n",
      "Fold 3, Epoch 16/20 - Train Loss: 0.0612, Train Acc: 0.9319 - Val Loss: 0.1915, Val Acc: 0.8103\n",
      "Fold 3, Epoch 17/20 - Train Loss: 0.0505, Train Acc: 0.9422 - Val Loss: 0.1825, Val Acc: 0.8513\n",
      "Fold 3, Epoch 18/20 - Train Loss: 0.0410, Train Acc: 0.9537 - Val Loss: 0.1992, Val Acc: 0.8256\n",
      "Fold 3, Epoch 19/20 - Train Loss: 0.0467, Train Acc: 0.9422 - Val Loss: 0.1932, Val Acc: 0.8308\n",
      "Fold 3, Epoch 20/20 - Train Loss: 0.0403, Train Acc: 0.9563 - Val Loss: 0.1892, Val Acc: 0.8359\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 24   0   8]\n",
      " [  1  22   2]\n",
      " [ 19   1 118]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5455    0.7500    0.6316        32\n",
      "           1     0.9565    0.8800    0.9167        25\n",
      "           2     0.9219    0.8551    0.8872       138\n",
      "\n",
      "    accuracy                         0.8410       195\n",
      "   macro avg     0.8080    0.8284    0.8118       195\n",
      "weighted avg     0.8645    0.8410    0.8490       195\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [128 100 551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/20 - Train Loss: 0.4760, Train Acc: 0.4069 - Val Loss: 0.3706, Val Acc: 0.6392\n",
      "Fold 4, Epoch 2/20 - Train Loss: 0.3372, Train Acc: 0.6444 - Val Loss: 0.2707, Val Acc: 0.7113\n",
      "Fold 4, Epoch 3/20 - Train Loss: 0.2162, Train Acc: 0.7677 - Val Loss: 0.2504, Val Acc: 0.7526\n",
      "Fold 4, Epoch 4/20 - Train Loss: 0.1541, Train Acc: 0.8254 - Val Loss: 0.2585, Val Acc: 0.7474\n",
      "Fold 4, Epoch 5/20 - Train Loss: 0.1719, Train Acc: 0.8087 - Val Loss: 0.5628, Val Acc: 0.4588\n",
      "Fold 4, Epoch 6/20 - Train Loss: 0.1841, Train Acc: 0.8113 - Val Loss: 0.2928, Val Acc: 0.7113\n",
      "Fold 4, Epoch 7/20 - Train Loss: 0.2024, Train Acc: 0.7856 - Val Loss: 0.2548, Val Acc: 0.7835\n",
      "Fold 4, Epoch 8/20 - Train Loss: 0.1740, Train Acc: 0.8216 - Val Loss: 0.2612, Val Acc: 0.7423\n",
      "Fold 4, Epoch 9/20 - Train Loss: 0.1315, Train Acc: 0.8498 - Val Loss: 0.2299, Val Acc: 0.7577\n",
      "Fold 4, Epoch 10/20 - Train Loss: 0.1067, Train Acc: 0.8755 - Val Loss: 0.2840, Val Acc: 0.7629\n",
      "Fold 4, Epoch 11/20 - Train Loss: 0.1099, Train Acc: 0.8935 - Val Loss: 0.2492, Val Acc: 0.7887\n",
      "Fold 4, Epoch 12/20 - Train Loss: 0.1119, Train Acc: 0.8678 - Val Loss: 0.2292, Val Acc: 0.8196\n",
      "Fold 4, Epoch 13/20 - Train Loss: 0.0900, Train Acc: 0.9063 - Val Loss: 0.2219, Val Acc: 0.8093\n",
      "Fold 4, Epoch 14/20 - Train Loss: 0.0727, Train Acc: 0.9294 - Val Loss: 0.2182, Val Acc: 0.8196\n",
      "Fold 4, Epoch 15/20 - Train Loss: 0.0541, Train Acc: 0.9474 - Val Loss: 0.2476, Val Acc: 0.7938\n",
      "Fold 4, Epoch 16/20 - Train Loss: 0.0600, Train Acc: 0.9332 - Val Loss: 0.2320, Val Acc: 0.8144\n",
      "Fold 4, Epoch 17/20 - Train Loss: 0.0443, Train Acc: 0.9499 - Val Loss: 0.2210, Val Acc: 0.7990\n",
      "Fold 4, Epoch 18/20 - Train Loss: 0.0443, Train Acc: 0.9409 - Val Loss: 0.2191, Val Acc: 0.8093\n",
      "Fold 4, Epoch 19/20 - Train Loss: 0.0439, Train Acc: 0.9461 - Val Loss: 0.2238, Val Acc: 0.8041\n",
      "Fold 4, Epoch 20/20 - Train Loss: 0.0496, Train Acc: 0.9551 - Val Loss: 0.2327, Val Acc: 0.8093\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 19   1  12]\n",
      " [  1  20   4]\n",
      " [ 13   4 120]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5758    0.5938    0.5846        32\n",
      "           1     0.8000    0.8000    0.8000        25\n",
      "           2     0.8824    0.8759    0.8791       137\n",
      "\n",
      "    accuracy                         0.8196       194\n",
      "   macro avg     0.7527    0.7566    0.7546       194\n",
      "weighted avg     0.8212    0.8196    0.8203       194\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [128 100 551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/20 - Train Loss: 0.4830, Train Acc: 0.4069 - Val Loss: 0.3873, Val Acc: 0.6546\n",
      "Fold 5, Epoch 2/20 - Train Loss: 0.3267, Train Acc: 0.6816 - Val Loss: 0.2515, Val Acc: 0.6959\n",
      "Fold 5, Epoch 3/20 - Train Loss: 0.1943, Train Acc: 0.7831 - Val Loss: 0.2873, Val Acc: 0.6443\n",
      "Fold 5, Epoch 4/20 - Train Loss: 0.1611, Train Acc: 0.8203 - Val Loss: 0.2558, Val Acc: 0.7371\n",
      "Fold 5, Epoch 5/20 - Train Loss: 0.1719, Train Acc: 0.7985 - Val Loss: 0.5865, Val Acc: 0.6031\n",
      "Fold 5, Epoch 6/20 - Train Loss: 0.2009, Train Acc: 0.7869 - Val Loss: 0.2816, Val Acc: 0.8041\n",
      "Fold 5, Epoch 7/20 - Train Loss: 0.1850, Train Acc: 0.8074 - Val Loss: 0.5131, Val Acc: 0.5619\n",
      "Fold 5, Epoch 8/20 - Train Loss: 0.1521, Train Acc: 0.8383 - Val Loss: 0.5063, Val Acc: 0.5567\n",
      "Fold 5, Epoch 9/20 - Train Loss: 0.1406, Train Acc: 0.8549 - Val Loss: 0.2016, Val Acc: 0.7680\n",
      "Fold 5, Epoch 10/20 - Train Loss: 0.0966, Train Acc: 0.8742 - Val Loss: 0.3757, Val Acc: 0.6649\n",
      "Fold 5, Epoch 11/20 - Train Loss: 0.0906, Train Acc: 0.9012 - Val Loss: 0.2694, Val Acc: 0.7526\n",
      "Fold 5, Epoch 12/20 - Train Loss: 0.0842, Train Acc: 0.9114 - Val Loss: 0.2319, Val Acc: 0.7474\n",
      "Fold 5, Epoch 13/20 - Train Loss: 0.0726, Train Acc: 0.9050 - Val Loss: 0.1990, Val Acc: 0.8041\n",
      "Fold 5, Epoch 14/20 - Train Loss: 0.0654, Train Acc: 0.9191 - Val Loss: 0.2091, Val Acc: 0.8196\n",
      "Fold 5, Epoch 15/20 - Train Loss: 0.0647, Train Acc: 0.9371 - Val Loss: 0.2461, Val Acc: 0.8402\n",
      "Fold 5, Epoch 16/20 - Train Loss: 0.0473, Train Acc: 0.9525 - Val Loss: 0.2085, Val Acc: 0.8196\n",
      "Fold 5, Epoch 17/20 - Train Loss: 0.0541, Train Acc: 0.9397 - Val Loss: 0.1933, Val Acc: 0.8505\n",
      "Fold 5, Epoch 18/20 - Train Loss: 0.0433, Train Acc: 0.9512 - Val Loss: 0.1941, Val Acc: 0.8299\n",
      "Fold 5, Epoch 19/20 - Train Loss: 0.0414, Train Acc: 0.9474 - Val Loss: 0.2059, Val Acc: 0.8196\n",
      "Fold 5, Epoch 20/20 - Train Loss: 0.0426, Train Acc: 0.9602 - Val Loss: 0.1823, Val Acc: 0.8093\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 19   2  11]\n",
      " [  2  17   6]\n",
      " [ 15   1 121]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5278    0.5938    0.5588        32\n",
      "           1     0.8500    0.6800    0.7556        25\n",
      "           2     0.8768    0.8832    0.8800       137\n",
      "\n",
      "    accuracy                         0.8093       194\n",
      "   macro avg     0.7515    0.7190    0.7315       194\n",
      "weighted avg     0.8158    0.8093    0.8110       194\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.7333333333333333, 0.7743589743589744, 0.841025641025641, 0.8195876288659794, 0.8092783505154639]]\n",
      "['Mean Accuracy:', np.float64(0.7955167856198784)]\n",
      "['Average Recalls:', {'0': np.float64(0.5875), '1': np.float64(0.776), '2': np.float64(0.8474769914312917)}]\n"
     ]
    }
   ],
   "source": [
    "kf_models_category, accs_category, recalls = run_kfold_training(\n",
    "    data_dir=category_data_dir,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    loss_fn=focal,\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    num_epochs=20,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=3,\n",
    "    use_best_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752361c2",
   "metadata": {},
   "source": [
    "A = [[ 19   4   9]\n",
    " [  1  19   5]\n",
    " [ 25   8 105]]\n",
    "\n",
    "B = [[ 13   3  16]\n",
    " [  1  19   5]\n",
    " [ 17   2 119]]\n",
    "\n",
    "C = [[ 24   0   8]\n",
    " [  1  22   2]\n",
    " [ 19   1 118]]\n",
    "\n",
    "D = [[ 19   1  12]\n",
    " [  1  20   4]\n",
    " [ 13   4 120]]\n",
    "\n",
    "E = [[ 19   2  11]\n",
    " [  2  17   6]\n",
    " [ 15   1 121]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6de60db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [128 100 550]\n",
      "Training set length: 778\n",
      "Validation set length: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m kf_models_category, accs_category, recalls = \u001b[43mrun_kfold_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategory_data_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mefficientnet_b0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreeze_until_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'features.4' for EfficientNet\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_best_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mrun_kfold_training\u001b[39m\u001b[34m(data_dir, backbone, loss_fn, freeze_until_layer, num_epochs, lr, k_folds, batch_size, seed, num_classes, use_best_loss)\u001b[39m\n\u001b[32m     55\u001b[39m optimizer = torch.optim.Adam(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p: p.requires_grad, model.parameters()), lr=lr)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m best_model, best_acc = \u001b[43mtrain_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m fold_models.append(best_model)\n\u001b[32m     60\u001b[39m fold_accuracies.append(best_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain_validate\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx, use_best_loss)\u001b[39m\n\u001b[32m     24\u001b[39m running_corrects = \u001b[32m0\u001b[39m\n\u001b[32m     25\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mStoolDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     20\u001b[39m image = Image.open(img_path).convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:973\u001b[39m, in \u001b[36mRandomResizedCrop.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    966\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    967\u001b[39m \u001b[33;03m    img (PIL Image or Tensor): Image to be cropped and resized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m \u001b[33;03m    PIL Image or Tensor: Randomly cropped and resized image.\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    972\u001b[39m i, j, h, w = \u001b[38;5;28mself\u001b[39m.get_params(img, \u001b[38;5;28mself\u001b[39m.scale, \u001b[38;5;28mself\u001b[39m.ratio)\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresized_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:650\u001b[39m, in \u001b[36mresized_crop\u001b[39m\u001b[34m(img, top, left, height, width, size, interpolation, antialias)\u001b[39m\n\u001b[32m    648\u001b[39m     _log_api_usage_once(resized_crop)\n\u001b[32m    649\u001b[39m img = crop(img, top, left, height, width)\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m img = \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:477\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    475\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m     pil_interpolation = pil_modes_mapping[interpolation]\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F_t.resize(img, size=output_size, interpolation=interpolation.value, antialias=antialias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) == \u001b[32m2\u001b[39m):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/poop-ai/.venv/lib/python3.11/site-packages/PIL/Image.py:2316\u001b[39m, in \u001b[36mImage.resize\u001b[39m\u001b[34m(self, size, resample, box, reducing_gap)\u001b[39m\n\u001b[32m   2304\u001b[39m         \u001b[38;5;28mself\u001b[39m = (\n\u001b[32m   2305\u001b[39m             \u001b[38;5;28mself\u001b[39m.reduce(factor, box=reduce_box)\n\u001b[32m   2306\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.reduce)\n\u001b[32m   2307\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Image.reduce(\u001b[38;5;28mself\u001b[39m, factor, box=reduce_box)\n\u001b[32m   2308\u001b[39m         )\n\u001b[32m   2309\u001b[39m         box = (\n\u001b[32m   2310\u001b[39m             (box[\u001b[32m0\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2311\u001b[39m             (box[\u001b[32m1\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2312\u001b[39m             (box[\u001b[32m2\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2313\u001b[39m             (box[\u001b[32m3\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2314\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kf_models_category, accs_category, recalls = run_kfold_training(\n",
    "    data_dir=category_data_dir,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    loss_fn=focal,\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    num_epochs=20,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=3,\n",
    "    use_best_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37d727dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used best acc\n",
    "consistency_recalls = {\n",
    "    'constipated': 0.5875,\n",
    "    'normal': 0.8474769914312917,\n",
    "    'loose': 0.776\n",
    "}\n",
    "\n",
    "\n",
    "subtype_accuracies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb8e39",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4825f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ensemble_to_onnx(kf_models_category, accs_category, output_path=\"category_classification.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212f72e",
   "metadata": {},
   "source": [
    "# Constipated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "353155fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167570.04s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "!find ../datasets/data-constipated -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c338b",
   "metadata": {},
   "source": [
    "## Single Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4311f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [52 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.3125 and previous best 0.0000\n",
      "Fold None, Epoch 1/30 - Train Loss: 1.0573, Train Acc: 0.4720 - Val Loss: 1.1171, Val Acc: 0.3125\n",
      "New best model found with accuracy 0.5312 and previous best 0.3125\n",
      "Fold None, Epoch 2/30 - Train Loss: 1.0175, Train Acc: 0.5440 - Val Loss: 1.0229, Val Acc: 0.5312\n",
      "New best model found with accuracy 0.7188 and previous best 0.5312\n",
      "Fold None, Epoch 3/30 - Train Loss: 0.9448, Train Acc: 0.6960 - Val Loss: 0.8822, Val Acc: 0.7188\n",
      "New best model found with accuracy 0.7500 and previous best 0.7188\n",
      "Fold None, Epoch 4/30 - Train Loss: 0.7786, Train Acc: 0.8640 - Val Loss: 0.7204, Val Acc: 0.7500\n",
      "Fold None, Epoch 5/30 - Train Loss: 0.6743, Train Acc: 0.8160 - Val Loss: 0.6972, Val Acc: 0.7500\n",
      "Fold None, Epoch 6/30 - Train Loss: 0.6472, Train Acc: 0.7760 - Val Loss: 0.8057, Val Acc: 0.7500\n",
      "Fold None, Epoch 7/30 - Train Loss: 0.4955, Train Acc: 0.9120 - Val Loss: 0.8904, Val Acc: 0.7500\n",
      "Fold None, Epoch 8/30 - Train Loss: 0.4402, Train Acc: 0.9280 - Val Loss: 0.8534, Val Acc: 0.7188\n",
      "Fold None, Epoch 9/30 - Train Loss: 0.4589, Train Acc: 0.9120 - Val Loss: 1.1590, Val Acc: 0.7188\n",
      "Fold None, Epoch 10/30 - Train Loss: 0.4939, Train Acc: 0.9040 - Val Loss: 0.8912, Val Acc: 0.6250\n",
      "Fold None, Epoch 11/30 - Train Loss: 0.4093, Train Acc: 0.9440 - Val Loss: 0.7921, Val Acc: 0.6562\n",
      "New best model found with accuracy 0.7812 and previous best 0.7500\n",
      "Fold None, Epoch 12/30 - Train Loss: 0.4754, Train Acc: 0.9200 - Val Loss: 0.8688, Val Acc: 0.7812\n",
      "Fold None, Epoch 13/30 - Train Loss: 0.3927, Train Acc: 0.9680 - Val Loss: 1.0660, Val Acc: 0.7188\n",
      "Fold None, Epoch 14/30 - Train Loss: 0.4193, Train Acc: 0.9360 - Val Loss: 0.7818, Val Acc: 0.7500\n",
      "Fold None, Epoch 15/30 - Train Loss: 0.4477, Train Acc: 0.9360 - Val Loss: 0.8986, Val Acc: 0.7500\n",
      "Fold None, Epoch 16/30 - Train Loss: 0.4422, Train Acc: 0.9200 - Val Loss: 1.1534, Val Acc: 0.5625\n",
      "Fold None, Epoch 17/30 - Train Loss: 0.3876, Train Acc: 0.9680 - Val Loss: 1.1414, Val Acc: 0.5938\n",
      "Fold None, Epoch 18/30 - Train Loss: 0.3843, Train Acc: 0.9360 - Val Loss: 1.0038, Val Acc: 0.6875\n",
      "Fold None, Epoch 19/30 - Train Loss: 0.4145, Train Acc: 0.9200 - Val Loss: 0.8895, Val Acc: 0.6875\n",
      "Fold None, Epoch 20/30 - Train Loss: 0.3834, Train Acc: 0.9440 - Val Loss: 0.8452, Val Acc: 0.7812\n",
      "New best model found with accuracy 0.8125 and previous best 0.7812\n",
      "Fold None, Epoch 21/30 - Train Loss: 0.3501, Train Acc: 0.9760 - Val Loss: 0.8029, Val Acc: 0.8125\n",
      "New best model found with accuracy 0.8438 and previous best 0.8125\n",
      "Fold None, Epoch 22/30 - Train Loss: 0.3541, Train Acc: 0.9680 - Val Loss: 0.7676, Val Acc: 0.8438\n",
      "Fold None, Epoch 23/30 - Train Loss: 0.3669, Train Acc: 0.9680 - Val Loss: 0.7549, Val Acc: 0.8438\n",
      "Fold None, Epoch 24/30 - Train Loss: 0.3296, Train Acc: 0.9920 - Val Loss: 0.7419, Val Acc: 0.8125\n",
      "Fold None, Epoch 25/30 - Train Loss: 0.3620, Train Acc: 0.9760 - Val Loss: 0.7410, Val Acc: 0.8438\n",
      "Fold None, Epoch 26/30 - Train Loss: 0.4007, Train Acc: 0.9440 - Val Loss: 0.7398, Val Acc: 0.8438\n",
      "Fold None, Epoch 27/30 - Train Loss: 0.3627, Train Acc: 0.9600 - Val Loss: 0.7617, Val Acc: 0.8125\n",
      "Fold None, Epoch 28/30 - Train Loss: 0.3761, Train Acc: 0.9520 - Val Loss: 0.7507, Val Acc: 0.8438\n",
      "Fold None, Epoch 29/30 - Train Loss: 0.3540, Train Acc: 0.9680 - Val Loss: 0.7318, Val Acc: 0.8438\n",
      "Fold None, Epoch 30/30 - Train Loss: 0.3541, Train Acc: 0.9680 - Val Loss: 0.7284, Val Acc: 0.8438\n",
      "--- Confusion Matrix ---\n",
      "[[10  3]\n",
      " [ 2 17]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8500    0.8947    0.8718        19\n",
      "\n",
      "    accuracy                         0.8438        32\n",
      "   macro avg     0.8417    0.8320    0.8359        32\n",
      "weighted avg     0.8432    0.8438    0.8426        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=constipation_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=30,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9ee79397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [52 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.1875 and previous best 0.0000\n",
      "Fold None, Epoch 1/30 - Train Loss: 0.5153, Train Acc: 0.2960 - Val Loss: 0.6106, Val Acc: 0.1875\n",
      "New best model found with accuracy 0.3438 and previous best 0.1875\n",
      "Fold None, Epoch 2/30 - Train Loss: 0.4910, Train Acc: 0.3600 - Val Loss: 0.5154, Val Acc: 0.3438\n",
      "New best model found with accuracy 0.6250 and previous best 0.3438\n",
      "Fold None, Epoch 3/30 - Train Loss: 0.3732, Train Acc: 0.6720 - Val Loss: 0.3597, Val Acc: 0.6250\n",
      "New best model found with accuracy 0.6875 and previous best 0.6250\n",
      "Fold None, Epoch 4/30 - Train Loss: 0.2991, Train Acc: 0.6880 - Val Loss: 0.2326, Val Acc: 0.6875\n",
      "New best model found with accuracy 0.7500 and previous best 0.6875\n",
      "Fold None, Epoch 5/30 - Train Loss: 0.1842, Train Acc: 0.8160 - Val Loss: 0.1801, Val Acc: 0.7500\n",
      "New best model found with accuracy 0.7812 and previous best 0.7500\n",
      "Fold None, Epoch 6/30 - Train Loss: 0.1199, Train Acc: 0.8960 - Val Loss: 0.1872, Val Acc: 0.7812\n",
      "Fold None, Epoch 7/30 - Train Loss: 0.0749, Train Acc: 0.9200 - Val Loss: 0.2534, Val Acc: 0.7812\n",
      "Fold None, Epoch 8/30 - Train Loss: 0.0599, Train Acc: 0.9280 - Val Loss: 0.2538, Val Acc: 0.6562\n",
      "Fold None, Epoch 9/30 - Train Loss: 0.0796, Train Acc: 0.8880 - Val Loss: 0.2966, Val Acc: 0.6875\n",
      "Fold None, Epoch 10/30 - Train Loss: 0.0719, Train Acc: 0.9040 - Val Loss: 0.4614, Val Acc: 0.6875\n",
      "Fold None, Epoch 11/30 - Train Loss: 0.0984, Train Acc: 0.8800 - Val Loss: 0.5811, Val Acc: 0.6562\n",
      "Fold None, Epoch 12/30 - Train Loss: 0.0819, Train Acc: 0.9120 - Val Loss: 0.3698, Val Acc: 0.6250\n",
      "Fold None, Epoch 13/30 - Train Loss: 0.0750, Train Acc: 0.8800 - Val Loss: 0.3944, Val Acc: 0.5938\n",
      "Fold None, Epoch 14/30 - Train Loss: 0.0895, Train Acc: 0.8080 - Val Loss: 0.3021, Val Acc: 0.6562\n",
      "Fold None, Epoch 15/30 - Train Loss: 0.0630, Train Acc: 0.8960 - Val Loss: 0.2767, Val Acc: 0.7500\n",
      "Fold None, Epoch 16/30 - Train Loss: 0.0426, Train Acc: 0.9360 - Val Loss: 0.3622, Val Acc: 0.6875\n",
      "Fold None, Epoch 17/30 - Train Loss: 0.0563, Train Acc: 0.9200 - Val Loss: 0.4503, Val Acc: 0.6562\n",
      "Fold None, Epoch 18/30 - Train Loss: 0.0500, Train Acc: 0.9360 - Val Loss: 0.5556, Val Acc: 0.6875\n",
      "Fold None, Epoch 19/30 - Train Loss: 0.0438, Train Acc: 0.9360 - Val Loss: 0.5323, Val Acc: 0.6562\n",
      "Fold None, Epoch 20/30 - Train Loss: 0.0394, Train Acc: 0.9600 - Val Loss: 0.5203, Val Acc: 0.5938\n",
      "Fold None, Epoch 21/30 - Train Loss: 0.0273, Train Acc: 0.9600 - Val Loss: 0.5877, Val Acc: 0.6250\n",
      "Fold None, Epoch 22/30 - Train Loss: 0.0401, Train Acc: 0.9440 - Val Loss: 0.6281, Val Acc: 0.6250\n",
      "Fold None, Epoch 23/30 - Train Loss: 0.0467, Train Acc: 0.9200 - Val Loss: 0.6284, Val Acc: 0.6562\n",
      "Fold None, Epoch 24/30 - Train Loss: 0.0359, Train Acc: 0.9440 - Val Loss: 0.6383, Val Acc: 0.6250\n",
      "Fold None, Epoch 25/30 - Train Loss: 0.0253, Train Acc: 0.9440 - Val Loss: 0.5990, Val Acc: 0.6562\n",
      "Fold None, Epoch 26/30 - Train Loss: 0.0212, Train Acc: 0.9600 - Val Loss: 0.5743, Val Acc: 0.6562\n",
      "Fold None, Epoch 27/30 - Train Loss: 0.0151, Train Acc: 0.9840 - Val Loss: 0.5379, Val Acc: 0.6875\n",
      "Fold None, Epoch 28/30 - Train Loss: 0.0243, Train Acc: 0.9520 - Val Loss: 0.5384, Val Acc: 0.6875\n",
      "Fold None, Epoch 29/30 - Train Loss: 0.0272, Train Acc: 0.9680 - Val Loss: 0.5291, Val Acc: 0.6875\n",
      "Fold None, Epoch 30/30 - Train Loss: 0.0218, Train Acc: 0.9680 - Val Loss: 0.5326, Val Acc: 0.7188\n",
      "--- Confusion Matrix ---\n",
      "[[ 8  5]\n",
      " [ 4 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6154    0.6400        13\n",
      "           1     0.7500    0.7895    0.7692        19\n",
      "\n",
      "    accuracy                         0.7188        32\n",
      "   macro avg     0.7083    0.7024    0.7046        32\n",
      "weighted avg     0.7161    0.7188    0.7167        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=constipation_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=focal, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=30,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ee6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [52 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/30 - Train Loss: 1.1294, Train Acc: 0.3280 - Val Loss: 1.1471, Val Acc: 0.2812\n",
      "Fold None, Epoch 2/30 - Train Loss: 1.1228, Train Acc: 0.3440 - Val Loss: 1.1464, Val Acc: 0.2812\n",
      "Fold None, Epoch 3/30 - Train Loss: 1.0767, Train Acc: 0.4000 - Val Loss: 1.1242, Val Acc: 0.3125\n",
      "Fold None, Epoch 4/30 - Train Loss: 1.0695, Train Acc: 0.4880 - Val Loss: 1.0984, Val Acc: 0.4062\n",
      "Fold None, Epoch 5/30 - Train Loss: 1.0998, Train Acc: 0.3840 - Val Loss: 1.0709, Val Acc: 0.4375\n",
      "Fold None, Epoch 6/30 - Train Loss: 1.0561, Train Acc: 0.4080 - Val Loss: 1.0399, Val Acc: 0.3750\n",
      "Fold None, Epoch 7/30 - Train Loss: 1.0257, Train Acc: 0.4640 - Val Loss: 1.0153, Val Acc: 0.4688\n",
      "Fold None, Epoch 8/30 - Train Loss: 1.0014, Train Acc: 0.4880 - Val Loss: 0.9879, Val Acc: 0.4688\n",
      "Fold None, Epoch 9/30 - Train Loss: 0.9691, Train Acc: 0.4640 - Val Loss: 0.9614, Val Acc: 0.5625\n",
      "Fold None, Epoch 10/30 - Train Loss: 0.9413, Train Acc: 0.5040 - Val Loss: 0.9337, Val Acc: 0.5938\n",
      "Fold None, Epoch 11/30 - Train Loss: 0.8820, Train Acc: 0.6560 - Val Loss: 0.9074, Val Acc: 0.5312\n",
      "Fold None, Epoch 12/30 - Train Loss: 0.8669, Train Acc: 0.6720 - Val Loss: 0.8846, Val Acc: 0.5312\n",
      "Fold None, Epoch 13/30 - Train Loss: 0.8675, Train Acc: 0.6080 - Val Loss: 0.8673, Val Acc: 0.5312\n",
      "Fold None, Epoch 14/30 - Train Loss: 0.8518, Train Acc: 0.5920 - Val Loss: 0.8520, Val Acc: 0.5938\n",
      "Fold None, Epoch 15/30 - Train Loss: 0.8337, Train Acc: 0.6000 - Val Loss: 0.8287, Val Acc: 0.6250\n",
      "Fold None, Epoch 16/30 - Train Loss: 0.8343, Train Acc: 0.5760 - Val Loss: 0.8145, Val Acc: 0.6250\n",
      "Fold None, Epoch 17/30 - Train Loss: 0.8398, Train Acc: 0.5600 - Val Loss: 0.8098, Val Acc: 0.6250\n",
      "Fold None, Epoch 18/30 - Train Loss: 0.7837, Train Acc: 0.6800 - Val Loss: 0.8019, Val Acc: 0.6250\n",
      "Fold None, Epoch 19/30 - Train Loss: 0.7946, Train Acc: 0.6480 - Val Loss: 0.7999, Val Acc: 0.6562\n",
      "Fold None, Epoch 20/30 - Train Loss: 0.7535, Train Acc: 0.7120 - Val Loss: 0.8020, Val Acc: 0.5938\n",
      "Fold None, Epoch 21/30 - Train Loss: 0.7759, Train Acc: 0.6560 - Val Loss: 0.7989, Val Acc: 0.5938\n",
      "Fold None, Epoch 22/30 - Train Loss: 0.7233, Train Acc: 0.7600 - Val Loss: 0.7929, Val Acc: 0.5938\n",
      "Fold None, Epoch 23/30 - Train Loss: 0.7625, Train Acc: 0.6720 - Val Loss: 0.7808, Val Acc: 0.6875\n",
      "Fold None, Epoch 24/30 - Train Loss: 0.7112, Train Acc: 0.7760 - Val Loss: 0.7824, Val Acc: 0.6562\n",
      "Fold None, Epoch 25/30 - Train Loss: 0.7167, Train Acc: 0.7360 - Val Loss: 0.7872, Val Acc: 0.5938\n",
      "Fold None, Epoch 26/30 - Train Loss: 0.7280, Train Acc: 0.7120 - Val Loss: 0.7931, Val Acc: 0.6250\n",
      "Fold None, Epoch 27/30 - Train Loss: 0.6927, Train Acc: 0.7920 - Val Loss: 0.7870, Val Acc: 0.6562\n",
      "Fold None, Epoch 28/30 - Train Loss: 0.7271, Train Acc: 0.6800 - Val Loss: 0.7857, Val Acc: 0.6875\n",
      "Fold None, Epoch 29/30 - Train Loss: 0.6777, Train Acc: 0.7840 - Val Loss: 0.7958, Val Acc: 0.6875\n",
      "Fold None, Epoch 30/30 - Train Loss: 0.6892, Train Acc: 0.7680 - Val Loss: 0.7900, Val Acc: 0.6562\n",
      "--- Confusion Matrix ---\n",
      "[[ 7  6]\n",
      " [ 4 15]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.5385    0.5833        13\n",
      "           1     0.7143    0.7895    0.7500        19\n",
      "\n",
      "    accuracy                         0.6875        32\n",
      "   macro avg     0.6753    0.6640    0.6667        32\n",
      "weighted avg     0.6826    0.6875    0.6823        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=constipation_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until='features.1',  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=30,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b86ba",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eacd7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [52 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4062 and previous best 0.0000\n",
      "Fold 1, Epoch 1/30 - Train Loss: 1.0637, Train Acc: 0.4640 - Val Loss: 1.0852, Val Acc: 0.4062\n",
      "New best model found with accuracy 0.5625 and previous best 0.4062\n",
      "Fold 1, Epoch 2/30 - Train Loss: 1.0212, Train Acc: 0.4480 - Val Loss: 1.0054, Val Acc: 0.5625\n",
      "New best model found with accuracy 0.6562 and previous best 0.5625\n",
      "Fold 1, Epoch 3/30 - Train Loss: 0.9506, Train Acc: 0.6400 - Val Loss: 0.8940, Val Acc: 0.6562\n",
      "New best model found with accuracy 0.6875 and previous best 0.6562\n",
      "Fold 1, Epoch 4/30 - Train Loss: 0.8666, Train Acc: 0.6720 - Val Loss: 0.7944, Val Acc: 0.6875\n",
      "New best model found with accuracy 0.7188 and previous best 0.6875\n",
      "Fold 1, Epoch 5/30 - Train Loss: 0.7391, Train Acc: 0.7280 - Val Loss: 0.7454, Val Acc: 0.7188\n",
      "New best model found with accuracy 0.7500 and previous best 0.7188\n",
      "Fold 1, Epoch 6/30 - Train Loss: 0.6153, Train Acc: 0.8720 - Val Loss: 0.7544, Val Acc: 0.7500\n",
      "Fold 1, Epoch 7/30 - Train Loss: 0.5619, Train Acc: 0.8480 - Val Loss: 0.8358, Val Acc: 0.6250\n",
      "Fold 1, Epoch 8/30 - Train Loss: 0.5077, Train Acc: 0.8720 - Val Loss: 0.9691, Val Acc: 0.6250\n",
      "Fold 1, Epoch 9/30 - Train Loss: 0.4933, Train Acc: 0.8640 - Val Loss: 1.2436, Val Acc: 0.5000\n",
      "Fold 1, Epoch 10/30 - Train Loss: 0.4801, Train Acc: 0.8800 - Val Loss: 1.1749, Val Acc: 0.5938\n",
      "Fold 1, Epoch 11/30 - Train Loss: 0.4670, Train Acc: 0.8880 - Val Loss: 1.3810, Val Acc: 0.5312\n",
      "Fold 1, Epoch 12/30 - Train Loss: 0.4425, Train Acc: 0.9520 - Val Loss: 1.4302, Val Acc: 0.5312\n",
      "Fold 1, Epoch 13/30 - Train Loss: 0.4327, Train Acc: 0.9120 - Val Loss: 1.1427, Val Acc: 0.5938\n",
      "Fold 1, Epoch 14/30 - Train Loss: 0.3905, Train Acc: 0.9520 - Val Loss: 1.2405, Val Acc: 0.6250\n",
      "Fold 1, Epoch 15/30 - Train Loss: 0.4054, Train Acc: 0.9520 - Val Loss: 1.2842, Val Acc: 0.5938\n",
      "Fold 1, Epoch 16/30 - Train Loss: 0.4881, Train Acc: 0.8640 - Val Loss: 1.0541, Val Acc: 0.5938\n",
      "Fold 1, Epoch 17/30 - Train Loss: 0.4500, Train Acc: 0.9200 - Val Loss: 0.9300, Val Acc: 0.6250\n",
      "Fold 1, Epoch 18/30 - Train Loss: 0.4279, Train Acc: 0.9280 - Val Loss: 0.9441, Val Acc: 0.6250\n",
      "Fold 1, Epoch 19/30 - Train Loss: 0.3569, Train Acc: 0.9840 - Val Loss: 0.9696, Val Acc: 0.6250\n",
      "Fold 1, Epoch 20/30 - Train Loss: 0.3717, Train Acc: 0.9520 - Val Loss: 1.0032, Val Acc: 0.6250\n",
      "Fold 1, Epoch 21/30 - Train Loss: 0.3676, Train Acc: 1.0000 - Val Loss: 1.0474, Val Acc: 0.6250\n",
      "Fold 1, Epoch 22/30 - Train Loss: 0.4022, Train Acc: 0.9440 - Val Loss: 1.0856, Val Acc: 0.6562\n",
      "Fold 1, Epoch 23/30 - Train Loss: 0.3628, Train Acc: 0.9760 - Val Loss: 1.0907, Val Acc: 0.5938\n",
      "Fold 1, Epoch 24/30 - Train Loss: 0.3602, Train Acc: 0.9680 - Val Loss: 1.0949, Val Acc: 0.6562\n",
      "Fold 1, Epoch 25/30 - Train Loss: 0.3386, Train Acc: 0.9840 - Val Loss: 1.0990, Val Acc: 0.6250\n",
      "Fold 1, Epoch 26/30 - Train Loss: 0.3692, Train Acc: 0.9440 - Val Loss: 1.1173, Val Acc: 0.6562\n",
      "Fold 1, Epoch 27/30 - Train Loss: 0.3241, Train Acc: 0.9920 - Val Loss: 1.1135, Val Acc: 0.6250\n",
      "Fold 1, Epoch 28/30 - Train Loss: 0.3475, Train Acc: 0.9760 - Val Loss: 1.1039, Val Acc: 0.5938\n",
      "Fold 1, Epoch 29/30 - Train Loss: 0.3450, Train Acc: 0.9840 - Val Loss: 1.1078, Val Acc: 0.5938\n",
      "Fold 1, Epoch 30/30 - Train Loss: 0.3456, Train Acc: 0.9760 - Val Loss: 1.1138, Val Acc: 0.5938\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 5  8]\n",
      " [ 5 14]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.3846    0.4348        13\n",
      "           1     0.6364    0.7368    0.6829        19\n",
      "\n",
      "    accuracy                         0.5938        32\n",
      "   macro avg     0.5682    0.5607    0.5589        32\n",
      "weighted avg     0.5810    0.5938    0.5821        32\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [52 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.5938 and previous best 0.0000\n",
      "Fold 2, Epoch 1/30 - Train Loss: 1.1484, Train Acc: 0.2160 - Val Loss: 1.0275, Val Acc: 0.5938\n",
      "New best model found with accuracy 0.7500 and previous best 0.5938\n",
      "Fold 2, Epoch 2/30 - Train Loss: 1.0911, Train Acc: 0.4560 - Val Loss: 0.9640, Val Acc: 0.7500\n",
      "Fold 2, Epoch 3/30 - Train Loss: 0.9903, Train Acc: 0.6240 - Val Loss: 0.8674, Val Acc: 0.7500\n",
      "Fold 2, Epoch 4/30 - Train Loss: 0.8918, Train Acc: 0.7040 - Val Loss: 0.7389, Val Acc: 0.7500\n",
      "New best model found with accuracy 0.7812 and previous best 0.7500\n",
      "Fold 2, Epoch 5/30 - Train Loss: 0.7392, Train Acc: 0.8320 - Val Loss: 0.6894, Val Acc: 0.7812\n",
      "Fold 2, Epoch 6/30 - Train Loss: 0.5984, Train Acc: 0.8480 - Val Loss: 0.8133, Val Acc: 0.7188\n",
      "Fold 2, Epoch 7/30 - Train Loss: 0.4714, Train Acc: 0.9120 - Val Loss: 0.8854, Val Acc: 0.6562\n",
      "Fold 2, Epoch 8/30 - Train Loss: 0.4726, Train Acc: 0.8880 - Val Loss: 0.8381, Val Acc: 0.7500\n",
      "Fold 2, Epoch 9/30 - Train Loss: 0.5044, Train Acc: 0.8720 - Val Loss: 0.7818, Val Acc: 0.6562\n",
      "Fold 2, Epoch 10/30 - Train Loss: 0.5096, Train Acc: 0.8640 - Val Loss: 0.6801, Val Acc: 0.7500\n",
      "Fold 2, Epoch 11/30 - Train Loss: 0.4691, Train Acc: 0.9120 - Val Loss: 0.7814, Val Acc: 0.7812\n",
      "Fold 2, Epoch 12/30 - Train Loss: 0.4511, Train Acc: 0.9200 - Val Loss: 0.8382, Val Acc: 0.7812\n",
      "Fold 2, Epoch 13/30 - Train Loss: 0.4021, Train Acc: 0.9600 - Val Loss: 0.8998, Val Acc: 0.7188\n",
      "Fold 2, Epoch 14/30 - Train Loss: 0.4215, Train Acc: 0.9200 - Val Loss: 0.7613, Val Acc: 0.7188\n",
      "New best model found with accuracy 0.8750 and previous best 0.7812\n",
      "Fold 2, Epoch 15/30 - Train Loss: 0.4643, Train Acc: 0.9040 - Val Loss: 0.7082, Val Acc: 0.8750\n",
      "Fold 2, Epoch 16/30 - Train Loss: 0.4429, Train Acc: 0.9040 - Val Loss: 0.6759, Val Acc: 0.8438\n",
      "Fold 2, Epoch 17/30 - Train Loss: 0.4202, Train Acc: 0.9040 - Val Loss: 0.6843, Val Acc: 0.7812\n",
      "Fold 2, Epoch 18/30 - Train Loss: 0.3816, Train Acc: 0.9440 - Val Loss: 0.7307, Val Acc: 0.7812\n",
      "Fold 2, Epoch 19/30 - Train Loss: 0.4033, Train Acc: 0.9200 - Val Loss: 0.7761, Val Acc: 0.7812\n",
      "Fold 2, Epoch 20/30 - Train Loss: 0.3804, Train Acc: 0.9440 - Val Loss: 0.8012, Val Acc: 0.8125\n",
      "Fold 2, Epoch 21/30 - Train Loss: 0.3698, Train Acc: 0.9520 - Val Loss: 0.7966, Val Acc: 0.8125\n",
      "Fold 2, Epoch 22/30 - Train Loss: 0.4182, Train Acc: 0.9200 - Val Loss: 0.8079, Val Acc: 0.8125\n",
      "Fold 2, Epoch 23/30 - Train Loss: 0.3446, Train Acc: 0.9680 - Val Loss: 0.7813, Val Acc: 0.8125\n",
      "Fold 2, Epoch 24/30 - Train Loss: 0.3457, Train Acc: 0.9840 - Val Loss: 0.7924, Val Acc: 0.7812\n",
      "Fold 2, Epoch 25/30 - Train Loss: 0.4159, Train Acc: 0.8960 - Val Loss: 0.8009, Val Acc: 0.7812\n",
      "Fold 2, Epoch 26/30 - Train Loss: 0.3662, Train Acc: 0.9600 - Val Loss: 0.7835, Val Acc: 0.7812\n",
      "Fold 2, Epoch 27/30 - Train Loss: 0.3821, Train Acc: 0.9520 - Val Loss: 0.7704, Val Acc: 0.8438\n",
      "Fold 2, Epoch 28/30 - Train Loss: 0.3843, Train Acc: 0.9360 - Val Loss: 0.7710, Val Acc: 0.7812\n",
      "Fold 2, Epoch 29/30 - Train Loss: 0.3550, Train Acc: 0.9760 - Val Loss: 0.7630, Val Acc: 0.8438\n",
      "Fold 2, Epoch 30/30 - Train Loss: 0.3593, Train Acc: 0.9680 - Val Loss: 0.7669, Val Acc: 0.8438\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[10  3]\n",
      " [ 2 17]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8500    0.8947    0.8718        19\n",
      "\n",
      "    accuracy                         0.8438        32\n",
      "   macro avg     0.8417    0.8320    0.8359        32\n",
      "weighted avg     0.8432    0.8438    0.8426        32\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [52 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.3226 and previous best 0.0000\n",
      "Fold 3, Epoch 1/30 - Train Loss: 1.1307, Train Acc: 0.2778 - Val Loss: 1.1228, Val Acc: 0.3226\n",
      "New best model found with accuracy 0.4516 and previous best 0.3226\n",
      "Fold 3, Epoch 2/30 - Train Loss: 1.0725, Train Acc: 0.4286 - Val Loss: 1.0530, Val Acc: 0.4516\n",
      "New best model found with accuracy 0.4839 and previous best 0.4516\n",
      "Fold 3, Epoch 3/30 - Train Loss: 0.9914, Train Acc: 0.5873 - Val Loss: 0.9679, Val Acc: 0.4839\n",
      "New best model found with accuracy 0.5806 and previous best 0.4839\n",
      "Fold 3, Epoch 4/30 - Train Loss: 0.8410, Train Acc: 0.7778 - Val Loss: 0.8847, Val Acc: 0.5806\n",
      "Fold 3, Epoch 5/30 - Train Loss: 0.7218, Train Acc: 0.8095 - Val Loss: 0.8575, Val Acc: 0.5484\n",
      "New best model found with accuracy 0.6452 and previous best 0.5806\n",
      "Fold 3, Epoch 6/30 - Train Loss: 0.5658, Train Acc: 0.8571 - Val Loss: 0.8334, Val Acc: 0.6452\n",
      "Fold 3, Epoch 7/30 - Train Loss: 0.4978, Train Acc: 0.8889 - Val Loss: 1.1642, Val Acc: 0.6129\n",
      "Fold 3, Epoch 8/30 - Train Loss: 0.4833, Train Acc: 0.8810 - Val Loss: 1.2520, Val Acc: 0.6452\n",
      "New best model found with accuracy 0.6774 and previous best 0.6452\n",
      "Fold 3, Epoch 9/30 - Train Loss: 0.5157, Train Acc: 0.9127 - Val Loss: 1.0292, Val Acc: 0.6774\n",
      "Fold 3, Epoch 10/30 - Train Loss: 0.4351, Train Acc: 0.9206 - Val Loss: 0.9489, Val Acc: 0.6452\n",
      "Fold 3, Epoch 11/30 - Train Loss: 0.5099, Train Acc: 0.8492 - Val Loss: 1.0762, Val Acc: 0.6774\n",
      "Fold 3, Epoch 12/30 - Train Loss: 0.4419, Train Acc: 0.9127 - Val Loss: 1.1211, Val Acc: 0.6129\n",
      "Fold 3, Epoch 13/30 - Train Loss: 0.4293, Train Acc: 0.9286 - Val Loss: 0.9329, Val Acc: 0.6452\n",
      "New best model found with accuracy 0.7097 and previous best 0.6774\n",
      "Fold 3, Epoch 14/30 - Train Loss: 0.4123, Train Acc: 0.9444 - Val Loss: 1.0426, Val Acc: 0.7097\n",
      "Fold 3, Epoch 15/30 - Train Loss: 0.3782, Train Acc: 0.9524 - Val Loss: 1.1351, Val Acc: 0.6452\n",
      "Fold 3, Epoch 16/30 - Train Loss: 0.4225, Train Acc: 0.9286 - Val Loss: 1.1051, Val Acc: 0.6452\n",
      "Fold 3, Epoch 17/30 - Train Loss: 0.4416, Train Acc: 0.9048 - Val Loss: 1.0646, Val Acc: 0.5484\n",
      "Fold 3, Epoch 18/30 - Train Loss: 0.4052, Train Acc: 0.9286 - Val Loss: 0.9235, Val Acc: 0.6452\n",
      "Fold 3, Epoch 19/30 - Train Loss: 0.4065, Train Acc: 0.9444 - Val Loss: 0.8394, Val Acc: 0.6774\n",
      "Fold 3, Epoch 20/30 - Train Loss: 0.3758, Train Acc: 0.9603 - Val Loss: 0.8080, Val Acc: 0.6774\n",
      "Fold 3, Epoch 21/30 - Train Loss: 0.4258, Train Acc: 0.9206 - Val Loss: 0.9023, Val Acc: 0.6452\n",
      "Fold 3, Epoch 22/30 - Train Loss: 0.3607, Train Acc: 0.9762 - Val Loss: 0.9855, Val Acc: 0.6774\n",
      "Fold 3, Epoch 23/30 - Train Loss: 0.3617, Train Acc: 0.9762 - Val Loss: 0.9807, Val Acc: 0.6774\n",
      "Fold 3, Epoch 24/30 - Train Loss: 0.3642, Train Acc: 0.9683 - Val Loss: 0.9638, Val Acc: 0.6774\n",
      "Fold 3, Epoch 25/30 - Train Loss: 0.3780, Train Acc: 0.9683 - Val Loss: 0.9365, Val Acc: 0.7097\n",
      "Fold 3, Epoch 26/30 - Train Loss: 0.3657, Train Acc: 0.9603 - Val Loss: 0.9174, Val Acc: 0.7097\n",
      "Fold 3, Epoch 27/30 - Train Loss: 0.3620, Train Acc: 0.9841 - Val Loss: 0.8852, Val Acc: 0.6774\n",
      "Fold 3, Epoch 28/30 - Train Loss: 0.3751, Train Acc: 0.9603 - Val Loss: 0.9137, Val Acc: 0.7097\n",
      "Fold 3, Epoch 29/30 - Train Loss: 0.3696, Train Acc: 0.9603 - Val Loss: 0.8913, Val Acc: 0.6774\n",
      "Fold 3, Epoch 30/30 - Train Loss: 0.3531, Train Acc: 0.9762 - Val Loss: 0.8760, Val Acc: 0.6774\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 7  6]\n",
      " [ 4 14]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.5385    0.5833        13\n",
      "           1     0.7000    0.7778    0.7368        18\n",
      "\n",
      "    accuracy                         0.6774        31\n",
      "   macro avg     0.6682    0.6581    0.6601        31\n",
      "weighted avg     0.6733    0.6774    0.6725        31\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [52 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.2258 and previous best 0.0000\n",
      "Fold 4, Epoch 1/30 - Train Loss: 1.1536, Train Acc: 0.2619 - Val Loss: 1.1726, Val Acc: 0.2258\n",
      "New best model found with accuracy 0.4194 and previous best 0.2258\n",
      "Fold 4, Epoch 2/30 - Train Loss: 1.1094, Train Acc: 0.3095 - Val Loss: 1.0959, Val Acc: 0.4194\n",
      "New best model found with accuracy 0.5806 and previous best 0.4194\n",
      "Fold 4, Epoch 3/30 - Train Loss: 1.0251, Train Acc: 0.5317 - Val Loss: 0.9807, Val Acc: 0.5806\n",
      "New best model found with accuracy 0.6129 and previous best 0.5806\n",
      "Fold 4, Epoch 4/30 - Train Loss: 0.8788, Train Acc: 0.7381 - Val Loss: 0.8657, Val Acc: 0.6129\n",
      "Fold 4, Epoch 5/30 - Train Loss: 0.7206, Train Acc: 0.8254 - Val Loss: 0.8081, Val Acc: 0.6129\n",
      "New best model found with accuracy 0.6452 and previous best 0.6129\n",
      "Fold 4, Epoch 6/30 - Train Loss: 0.5865, Train Acc: 0.8730 - Val Loss: 1.0193, Val Acc: 0.6452\n",
      "Fold 4, Epoch 7/30 - Train Loss: 0.5217, Train Acc: 0.8730 - Val Loss: 1.3451, Val Acc: 0.6129\n",
      "Fold 4, Epoch 8/30 - Train Loss: 0.4567, Train Acc: 0.9365 - Val Loss: 1.4302, Val Acc: 0.6129\n",
      "Fold 4, Epoch 9/30 - Train Loss: 0.4209, Train Acc: 0.9444 - Val Loss: 1.0779, Val Acc: 0.6129\n",
      "Fold 4, Epoch 10/30 - Train Loss: 0.4792, Train Acc: 0.8810 - Val Loss: 0.9255, Val Acc: 0.6452\n",
      "New best model found with accuracy 0.7419 and previous best 0.6452\n",
      "Fold 4, Epoch 11/30 - Train Loss: 0.4543, Train Acc: 0.8968 - Val Loss: 0.8873, Val Acc: 0.7419\n",
      "Fold 4, Epoch 12/30 - Train Loss: 0.4948, Train Acc: 0.8810 - Val Loss: 0.9345, Val Acc: 0.7097\n",
      "New best model found with accuracy 0.7742 and previous best 0.7419\n",
      "Fold 4, Epoch 13/30 - Train Loss: 0.4847, Train Acc: 0.8889 - Val Loss: 0.7622, Val Acc: 0.7742\n",
      "Fold 4, Epoch 14/30 - Train Loss: 0.4688, Train Acc: 0.8968 - Val Loss: 0.9090, Val Acc: 0.7097\n",
      "Fold 4, Epoch 15/30 - Train Loss: 0.4486, Train Acc: 0.9206 - Val Loss: 0.9475, Val Acc: 0.7419\n",
      "Fold 4, Epoch 16/30 - Train Loss: 0.3906, Train Acc: 0.9524 - Val Loss: 0.8693, Val Acc: 0.7419\n",
      "Fold 4, Epoch 17/30 - Train Loss: 0.3887, Train Acc: 0.9683 - Val Loss: 0.9077, Val Acc: 0.7742\n",
      "Fold 4, Epoch 18/30 - Train Loss: 0.4080, Train Acc: 0.9365 - Val Loss: 0.8767, Val Acc: 0.7742\n",
      "Fold 4, Epoch 19/30 - Train Loss: 0.4088, Train Acc: 0.9286 - Val Loss: 0.8735, Val Acc: 0.7419\n",
      "Fold 4, Epoch 20/30 - Train Loss: 0.3709, Train Acc: 0.9603 - Val Loss: 0.8961, Val Acc: 0.7419\n",
      "Fold 4, Epoch 21/30 - Train Loss: 0.3826, Train Acc: 0.9524 - Val Loss: 0.9377, Val Acc: 0.7419\n",
      "Fold 4, Epoch 22/30 - Train Loss: 0.3995, Train Acc: 0.9206 - Val Loss: 0.9750, Val Acc: 0.6774\n",
      "Fold 4, Epoch 23/30 - Train Loss: 0.4087, Train Acc: 0.9127 - Val Loss: 1.0165, Val Acc: 0.6774\n",
      "Fold 4, Epoch 24/30 - Train Loss: 0.3781, Train Acc: 0.9524 - Val Loss: 1.0190, Val Acc: 0.7097\n",
      "Fold 4, Epoch 25/30 - Train Loss: 0.3731, Train Acc: 0.9603 - Val Loss: 0.9960, Val Acc: 0.7097\n",
      "Fold 4, Epoch 26/30 - Train Loss: 0.3702, Train Acc: 0.9603 - Val Loss: 1.0010, Val Acc: 0.7097\n",
      "Fold 4, Epoch 27/30 - Train Loss: 0.3697, Train Acc: 0.9444 - Val Loss: 0.9990, Val Acc: 0.7097\n",
      "Fold 4, Epoch 28/30 - Train Loss: 0.3789, Train Acc: 0.9524 - Val Loss: 0.9992, Val Acc: 0.7097\n",
      "Fold 4, Epoch 29/30 - Train Loss: 0.3921, Train Acc: 0.9206 - Val Loss: 0.9961, Val Acc: 0.7097\n",
      "Fold 4, Epoch 30/30 - Train Loss: 0.3660, Train Acc: 0.9762 - Val Loss: 0.9908, Val Acc: 0.7097\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 9  4]\n",
      " [ 5 13]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6429    0.6923    0.6667        13\n",
      "           1     0.7647    0.7222    0.7429        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7038    0.7073    0.7048        31\n",
      "weighted avg     0.7136    0.7097    0.7109        31\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [52 74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.2903 and previous best 0.0000\n",
      "Fold 5, Epoch 1/30 - Train Loss: 1.0699, Train Acc: 0.4762 - Val Loss: 1.1188, Val Acc: 0.2903\n",
      "New best model found with accuracy 0.5161 and previous best 0.2903\n",
      "Fold 5, Epoch 2/30 - Train Loss: 1.0763, Train Acc: 0.4444 - Val Loss: 0.9999, Val Acc: 0.5161\n",
      "New best model found with accuracy 0.7419 and previous best 0.5161\n",
      "Fold 5, Epoch 3/30 - Train Loss: 0.9710, Train Acc: 0.6032 - Val Loss: 0.8553, Val Acc: 0.7419\n",
      "Fold 5, Epoch 4/30 - Train Loss: 0.8524, Train Acc: 0.7619 - Val Loss: 0.7145, Val Acc: 0.7419\n",
      "Fold 5, Epoch 5/30 - Train Loss: 0.7256, Train Acc: 0.8175 - Val Loss: 0.6651, Val Acc: 0.7097\n",
      "New best model found with accuracy 0.8065 and previous best 0.7419\n",
      "Fold 5, Epoch 6/30 - Train Loss: 0.5852, Train Acc: 0.8571 - Val Loss: 0.6786, Val Acc: 0.8065\n",
      "Fold 5, Epoch 7/30 - Train Loss: 0.4982, Train Acc: 0.8810 - Val Loss: 0.6624, Val Acc: 0.7419\n",
      "Fold 5, Epoch 8/30 - Train Loss: 0.4614, Train Acc: 0.9048 - Val Loss: 0.7290, Val Acc: 0.7419\n",
      "Fold 5, Epoch 9/30 - Train Loss: 0.5996, Train Acc: 0.8413 - Val Loss: 0.8560, Val Acc: 0.7097\n",
      "Fold 5, Epoch 10/30 - Train Loss: 0.5814, Train Acc: 0.8571 - Val Loss: 0.8393, Val Acc: 0.6774\n",
      "Fold 5, Epoch 11/30 - Train Loss: 0.5071, Train Acc: 0.8492 - Val Loss: 0.7671, Val Acc: 0.7419\n",
      "Fold 5, Epoch 12/30 - Train Loss: 0.4188, Train Acc: 0.9444 - Val Loss: 0.7912, Val Acc: 0.7742\n",
      "Fold 5, Epoch 13/30 - Train Loss: 0.4375, Train Acc: 0.9603 - Val Loss: 0.8186, Val Acc: 0.7419\n",
      "Fold 5, Epoch 14/30 - Train Loss: 0.4302, Train Acc: 0.9444 - Val Loss: 0.7496, Val Acc: 0.7419\n",
      "Fold 5, Epoch 15/30 - Train Loss: 0.4238, Train Acc: 0.9444 - Val Loss: 0.7005, Val Acc: 0.7419\n",
      "Fold 5, Epoch 16/30 - Train Loss: 0.3710, Train Acc: 0.9683 - Val Loss: 0.6629, Val Acc: 0.7097\n",
      "Fold 5, Epoch 17/30 - Train Loss: 0.4000, Train Acc: 0.9603 - Val Loss: 0.6799, Val Acc: 0.7419\n",
      "Fold 5, Epoch 18/30 - Train Loss: 0.4606, Train Acc: 0.9365 - Val Loss: 0.7187, Val Acc: 0.7419\n",
      "Fold 5, Epoch 19/30 - Train Loss: 0.4125, Train Acc: 0.9524 - Val Loss: 0.7705, Val Acc: 0.7097\n",
      "Fold 5, Epoch 20/30 - Train Loss: 0.4546, Train Acc: 0.9206 - Val Loss: 0.7605, Val Acc: 0.7097\n",
      "Fold 5, Epoch 21/30 - Train Loss: 0.4025, Train Acc: 0.9524 - Val Loss: 0.7676, Val Acc: 0.7419\n",
      "Fold 5, Epoch 22/30 - Train Loss: 0.3715, Train Acc: 0.9603 - Val Loss: 0.7496, Val Acc: 0.7419\n",
      "Fold 5, Epoch 23/30 - Train Loss: 0.3669, Train Acc: 0.9683 - Val Loss: 0.7212, Val Acc: 0.7419\n",
      "Fold 5, Epoch 24/30 - Train Loss: 0.3690, Train Acc: 0.9444 - Val Loss: 0.7052, Val Acc: 0.7419\n",
      "Fold 5, Epoch 25/30 - Train Loss: 0.3644, Train Acc: 0.9524 - Val Loss: 0.6999, Val Acc: 0.7419\n",
      "Fold 5, Epoch 26/30 - Train Loss: 0.3740, Train Acc: 0.9603 - Val Loss: 0.7083, Val Acc: 0.7742\n",
      "Fold 5, Epoch 27/30 - Train Loss: 0.3767, Train Acc: 0.9683 - Val Loss: 0.7182, Val Acc: 0.7419\n",
      "Fold 5, Epoch 28/30 - Train Loss: 0.3783, Train Acc: 0.9524 - Val Loss: 0.7246, Val Acc: 0.7419\n",
      "Fold 5, Epoch 29/30 - Train Loss: 0.3774, Train Acc: 0.9603 - Val Loss: 0.7049, Val Acc: 0.7419\n",
      "Fold 5, Epoch 30/30 - Train Loss: 0.3709, Train Acc: 0.9524 - Val Loss: 0.7046, Val Acc: 0.7419\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 8  5]\n",
      " [ 3 15]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7273    0.6154    0.6667        13\n",
      "           1     0.7500    0.8333    0.7895        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7386    0.7244    0.7281        31\n",
      "weighted avg     0.7405    0.7419    0.7380        31\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.75, 0.875, 0.7096774193548387, 0.7741935483870968, 0.8064516129032258]]\n",
      "['Mean Accuracy:', np.float64(0.7830645161290324)]\n",
      "['Average Recalls:', {'0': np.float64(0.6000000000000001), '1': np.float64(0.7929824561403509)}]\n"
     ]
    }
   ],
   "source": [
    "kf_models_constipated, accs_constipated, recalls = run_kfold_training(\n",
    "    data_dir=constipation_data_dir,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    loss_fn=smooth,\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    num_epochs=30,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=2,\n",
    "    use_best_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f232c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_accuracies['constipated'] = 0.7830645161290324 #np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2b4e1",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1eb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ensemble_to_onnx(kf_models_constipated, accs_constipated, output_path=\"constipated_subtype_classification.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb337a",
   "metadata": {},
   "source": [
    "# Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e56c14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "445028.33s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "!find ../datasets/data-normal -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a145fa4",
   "metadata": {},
   "source": [
    "## Single Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [258 261]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.5385 and previous best 0.0000\n",
      "Fold None, Epoch 1/20 - Train Loss: 1.0728, Train Acc: 0.4123 - Val Loss: 0.9521, Val Acc: 0.5385\n",
      "New best model found with accuracy 0.6615 and previous best 0.5385\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.9086, Train Acc: 0.6089 - Val Loss: 0.7867, Val Acc: 0.6615\n",
      "New best model found with accuracy 0.6923 and previous best 0.6615\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.7268, Train Acc: 0.7264 - Val Loss: 0.7669, Val Acc: 0.6923\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.7016, Train Acc: 0.7380 - Val Loss: 0.8809, Val Acc: 0.6462\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.6598, Train Acc: 0.7630 - Val Loss: 0.9528, Val Acc: 0.6692\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.6567, Train Acc: 0.7900 - Val Loss: 0.9076, Val Acc: 0.6077\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.5742, Train Acc: 0.8324 - Val Loss: 0.8591, Val Acc: 0.6846\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.5532, Train Acc: 0.8651 - Val Loss: 0.8900, Val Acc: 0.6308\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.5266, Train Acc: 0.8709 - Val Loss: 0.9459, Val Acc: 0.6308\n",
      "New best model found with accuracy 0.7154 and previous best 0.6923\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.5298, Train Acc: 0.8516 - Val Loss: 0.7751, Val Acc: 0.7154\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.5030, Train Acc: 0.8767 - Val Loss: 0.7893, Val Acc: 0.7154\n",
      "New best model found with accuracy 0.7462 and previous best 0.7154\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.4728, Train Acc: 0.8960 - Val Loss: 0.8636, Val Acc: 0.7462\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.4362, Train Acc: 0.9191 - Val Loss: 0.9078, Val Acc: 0.6769\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.4504, Train Acc: 0.9037 - Val Loss: 0.8835, Val Acc: 0.7000\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.4215, Train Acc: 0.9306 - Val Loss: 0.8608, Val Acc: 0.7231\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.3912, Train Acc: 0.9403 - Val Loss: 0.8782, Val Acc: 0.7154\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.4047, Train Acc: 0.9383 - Val Loss: 0.8999, Val Acc: 0.7077\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.3877, Train Acc: 0.9557 - Val Loss: 0.8936, Val Acc: 0.6692\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.3876, Train Acc: 0.9499 - Val Loss: 0.9025, Val Acc: 0.7000\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.3861, Train Acc: 0.9403 - Val Loss: 0.8851, Val Acc: 0.7000\n",
      "--- Confusion Matrix ---\n",
      "[[44 21]\n",
      " [18 47]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7097    0.6769    0.6929        65\n",
      "           1     0.6912    0.7231    0.7068        65\n",
      "\n",
      "    accuracy                         0.7000       130\n",
      "   macro avg     0.7004    0.7000    0.6998       130\n",
      "weighted avg     0.7004    0.7000    0.6998       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I ran without type-5 to see\n",
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=normal_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4e4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4493 and previous best 0.0000\n",
      "Fold None, Epoch 1/20 - Train Loss: 1.0844, Train Acc: 0.4018 - Val Loss: 1.0585, Val Acc: 0.4493\n",
      "New best model found with accuracy 0.5580 and previous best 0.4493\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.9288, Train Acc: 0.5636 - Val Loss: 0.9658, Val Acc: 0.5580\n",
      "New best model found with accuracy 0.6159 and previous best 0.5580\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.7877, Train Acc: 0.6891 - Val Loss: 0.8606, Val Acc: 0.6159\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.6641, Train Acc: 0.7600 - Val Loss: 1.0355, Val Acc: 0.5797\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.6499, Train Acc: 0.7982 - Val Loss: 0.9877, Val Acc: 0.5507\n",
      "New best model found with accuracy 0.6304 and previous best 0.6159\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.6598, Train Acc: 0.7727 - Val Loss: 0.9375, Val Acc: 0.6304\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.6244, Train Acc: 0.8164 - Val Loss: 0.9806, Val Acc: 0.5725\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.6067, Train Acc: 0.8127 - Val Loss: 1.2480, Val Acc: 0.5870\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.5268, Train Acc: 0.8691 - Val Loss: 1.0732, Val Acc: 0.5870\n",
      "New best model found with accuracy 0.7464 and previous best 0.6304\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.5506, Train Acc: 0.8473 - Val Loss: 0.9529, Val Acc: 0.7464\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.5149, Train Acc: 0.8691 - Val Loss: 0.9532, Val Acc: 0.6667\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.5345, Train Acc: 0.8600 - Val Loss: 0.9083, Val Acc: 0.6812\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.4758, Train Acc: 0.8964 - Val Loss: 0.9792, Val Acc: 0.6522\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.4811, Train Acc: 0.9018 - Val Loss: 0.9793, Val Acc: 0.6884\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.4184, Train Acc: 0.9455 - Val Loss: 0.9168, Val Acc: 0.6522\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.4028, Train Acc: 0.9509 - Val Loss: 0.9344, Val Acc: 0.6594\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.4081, Train Acc: 0.9418 - Val Loss: 0.8996, Val Acc: 0.6812\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.3989, Train Acc: 0.9400 - Val Loss: 0.9423, Val Acc: 0.6739\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.4003, Train Acc: 0.9436 - Val Loss: 0.9345, Val Acc: 0.6812\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.3861, Train Acc: 0.9564 - Val Loss: 0.9417, Val Acc: 0.6667\n",
      "--- Confusion Matrix ---\n",
      "[[51 14  0]\n",
      " [25 40  0]\n",
      " [ 4  3  1]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6375    0.7846    0.7034        65\n",
      "           1     0.7018    0.6154    0.6557        65\n",
      "           2     1.0000    0.1250    0.2222         8\n",
      "\n",
      "    accuracy                         0.6667       138\n",
      "   macro avg     0.7798    0.5083    0.5271       138\n",
      "weighted avg     0.6888    0.6667    0.6531       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=normal_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "26407750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4783 and previous best 0.0000\n",
      "Fold None, Epoch 1/20 - Train Loss: 0.4579, Train Acc: 0.4364 - Val Loss: 0.4725, Val Acc: 0.4783\n",
      "New best model found with accuracy 0.4928 and previous best 0.4783\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.3513, Train Acc: 0.6273 - Val Loss: 0.3918, Val Acc: 0.4928\n",
      "New best model found with accuracy 0.6594 and previous best 0.4928\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.2417, Train Acc: 0.7145 - Val Loss: 0.3200, Val Acc: 0.6594\n",
      "New best model found with accuracy 0.6812 and previous best 0.6594\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.1713, Train Acc: 0.8164 - Val Loss: 0.3995, Val Acc: 0.6812\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.1588, Train Acc: 0.8200 - Val Loss: 0.4523, Val Acc: 0.5797\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.2062, Train Acc: 0.7400 - Val Loss: 0.3952, Val Acc: 0.6087\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.1751, Train Acc: 0.7982 - Val Loss: 0.3287, Val Acc: 0.5725\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.1726, Train Acc: 0.7818 - Val Loss: 0.3484, Val Acc: 0.6739\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.1390, Train Acc: 0.8327 - Val Loss: 0.3969, Val Acc: 0.5725\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.1720, Train Acc: 0.8055 - Val Loss: 0.3610, Val Acc: 0.6377\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.1900, Train Acc: 0.7927 - Val Loss: 0.3535, Val Acc: 0.6812\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.1151, Train Acc: 0.8545 - Val Loss: 0.3547, Val Acc: 0.6377\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.0864, Train Acc: 0.8891 - Val Loss: 0.3501, Val Acc: 0.6739\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.0790, Train Acc: 0.8873 - Val Loss: 0.3910, Val Acc: 0.6377\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.1046, Train Acc: 0.8818 - Val Loss: 0.5106, Val Acc: 0.6232\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.0827, Train Acc: 0.8945 - Val Loss: 0.4347, Val Acc: 0.6304\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.0880, Train Acc: 0.8982 - Val Loss: 0.4451, Val Acc: 0.6522\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.0749, Train Acc: 0.9236 - Val Loss: 0.4413, Val Acc: 0.6594\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.0766, Train Acc: 0.9109 - Val Loss: 0.4339, Val Acc: 0.6449\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.0566, Train Acc: 0.9327 - Val Loss: 0.4431, Val Acc: 0.6522\n",
      "--- Confusion Matrix ---\n",
      "[[46 18  1]\n",
      " [24 41  0]\n",
      " [ 4  1  3]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6216    0.7077    0.6619        65\n",
      "           1     0.6833    0.6308    0.6560        65\n",
      "           2     0.7500    0.3750    0.5000         8\n",
      "\n",
      "    accuracy                         0.6522       138\n",
      "   macro avg     0.6850    0.5712    0.6060       138\n",
      "weighted avg     0.6581    0.6522    0.6497       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=normal_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=focal, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d0de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 0.4732, Train Acc: 0.4182 - Val Loss: 0.4787, Val Acc: 0.3696\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.4216, Train Acc: 0.5273 - Val Loss: 0.4427, Val Acc: 0.4783\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.3939, Train Acc: 0.5655 - Val Loss: 0.4147, Val Acc: 0.5145\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.3642, Train Acc: 0.5800 - Val Loss: 0.3953, Val Acc: 0.5362\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.3246, Train Acc: 0.6291 - Val Loss: 0.3703, Val Acc: 0.5725\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.3215, Train Acc: 0.6327 - Val Loss: 0.3557, Val Acc: 0.5942\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.2876, Train Acc: 0.6836 - Val Loss: 0.3328, Val Acc: 0.6304\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.2635, Train Acc: 0.7327 - Val Loss: 0.3242, Val Acc: 0.6377\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.2492, Train Acc: 0.7236 - Val Loss: 0.3024, Val Acc: 0.6232\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.2204, Train Acc: 0.7527 - Val Loss: 0.2899, Val Acc: 0.6522\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.2160, Train Acc: 0.7582 - Val Loss: 0.2819, Val Acc: 0.6522\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.1981, Train Acc: 0.7945 - Val Loss: 0.2724, Val Acc: 0.6667\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.1697, Train Acc: 0.7964 - Val Loss: 0.2750, Val Acc: 0.6594\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.1621, Train Acc: 0.8018 - Val Loss: 0.2752, Val Acc: 0.6884\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.1283, Train Acc: 0.8436 - Val Loss: 0.2767, Val Acc: 0.7029\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.1302, Train Acc: 0.8455 - Val Loss: 0.2723, Val Acc: 0.7319\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.1228, Train Acc: 0.8436 - Val Loss: 0.2647, Val Acc: 0.7319\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.1173, Train Acc: 0.8473 - Val Loss: 0.2555, Val Acc: 0.6812\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.1166, Train Acc: 0.8509 - Val Loss: 0.2748, Val Acc: 0.7174\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.0944, Train Acc: 0.8800 - Val Loss: 0.2741, Val Acc: 0.6884\n",
      "--- Confusion Matrix ---\n",
      "[[46 18  1]\n",
      " [18 47  0]\n",
      " [ 5  2  1]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.7077    0.6866        65\n",
      "           1     0.7015    0.7231    0.7121        65\n",
      "           2     0.5000    0.1250    0.2000         8\n",
      "\n",
      "    accuracy                         0.6812       138\n",
      "   macro avg     0.6227    0.5186    0.5329       138\n",
      "weighted avg     0.6734    0.6812    0.6704       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=normal_data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    loss_fn=focal, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce71b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 1.1094, Train Acc: 0.3091 - Val Loss: 1.0993, Val Acc: 0.3261\n",
      "Fold None, Epoch 2/20 - Train Loss: 1.0634, Train Acc: 0.4345 - Val Loss: 1.0806, Val Acc: 0.3841\n",
      "Fold None, Epoch 3/20 - Train Loss: 1.0075, Train Acc: 0.5327 - Val Loss: 1.0566, Val Acc: 0.4493\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.9688, Train Acc: 0.5745 - Val Loss: 1.0312, Val Acc: 0.4928\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.9227, Train Acc: 0.6036 - Val Loss: 0.9995, Val Acc: 0.5580\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.8902, Train Acc: 0.6109 - Val Loss: 0.9762, Val Acc: 0.5435\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.8688, Train Acc: 0.6345 - Val Loss: 0.9711, Val Acc: 0.5652\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.8179, Train Acc: 0.6836 - Val Loss: 0.9315, Val Acc: 0.6087\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.8141, Train Acc: 0.6836 - Val Loss: 0.9078, Val Acc: 0.6087\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.7747, Train Acc: 0.7182 - Val Loss: 0.8816, Val Acc: 0.6087\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.7283, Train Acc: 0.7836 - Val Loss: 0.8586, Val Acc: 0.6667\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.6806, Train Acc: 0.7891 - Val Loss: 0.8407, Val Acc: 0.6667\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.6736, Train Acc: 0.7909 - Val Loss: 0.8265, Val Acc: 0.6667\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.6618, Train Acc: 0.7891 - Val Loss: 0.8070, Val Acc: 0.6957\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.5912, Train Acc: 0.8455 - Val Loss: 0.7953, Val Acc: 0.6377\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.5496, Train Acc: 0.8691 - Val Loss: 0.8059, Val Acc: 0.6812\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.5538, Train Acc: 0.8473 - Val Loss: 0.8059, Val Acc: 0.6812\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.5241, Train Acc: 0.8709 - Val Loss: 0.8006, Val Acc: 0.6812\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.5296, Train Acc: 0.8618 - Val Loss: 0.8231, Val Acc: 0.6957\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.5033, Train Acc: 0.8709 - Val Loss: 0.8301, Val Acc: 0.6739\n",
      "--- Confusion Matrix ---\n",
      "[[43 21  1]\n",
      " [21 43  1]\n",
      " [ 4  2  2]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6324    0.6615    0.6466        65\n",
      "           1     0.6515    0.6615    0.6565        65\n",
      "           2     0.5000    0.2500    0.3333         8\n",
      "\n",
      "    accuracy                         0.6377       138\n",
      "   macro avg     0.5946    0.5244    0.5455       138\n",
      "weighted avg     0.6337    0.6377    0.6331       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=normal_data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718933d9",
   "metadata": {},
   "source": [
    "## K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a9e2c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4348 and previous best 0.0000\n",
      "Fold 1, Epoch 1/24 - Train Loss: 0.4741, Train Acc: 0.4109 - Val Loss: 0.4765, Val Acc: 0.4348\n",
      "New best model found with accuracy 0.5435 and previous best 0.4348\n",
      "Fold 1, Epoch 2/24 - Train Loss: 0.3944, Train Acc: 0.5073 - Val Loss: 0.3983, Val Acc: 0.5435\n",
      "New best model found with accuracy 0.6304 and previous best 0.5435\n",
      "Fold 1, Epoch 3/24 - Train Loss: 0.2815, Train Acc: 0.6891 - Val Loss: 0.3157, Val Acc: 0.6304\n",
      "Fold 1, Epoch 4/24 - Train Loss: 0.2129, Train Acc: 0.7491 - Val Loss: 0.3109, Val Acc: 0.5725\n",
      "Fold 1, Epoch 5/24 - Train Loss: 0.1653, Train Acc: 0.7709 - Val Loss: 0.3327, Val Acc: 0.6304\n",
      "Fold 1, Epoch 6/24 - Train Loss: 0.2038, Train Acc: 0.7364 - Val Loss: 0.4554, Val Acc: 0.6304\n",
      "Fold 1, Epoch 7/24 - Train Loss: 0.1863, Train Acc: 0.7673 - Val Loss: 0.3962, Val Acc: 0.5942\n",
      "Fold 1, Epoch 8/24 - Train Loss: 0.2081, Train Acc: 0.7564 - Val Loss: 0.3386, Val Acc: 0.6159\n",
      "Fold 1, Epoch 9/24 - Train Loss: 0.1460, Train Acc: 0.8018 - Val Loss: 0.4224, Val Acc: 0.5797\n",
      "Fold 1, Epoch 10/24 - Train Loss: 0.2015, Train Acc: 0.7945 - Val Loss: 0.5321, Val Acc: 0.5580\n",
      "Fold 1, Epoch 11/24 - Train Loss: 0.1994, Train Acc: 0.7600 - Val Loss: 0.4738, Val Acc: 0.6014\n",
      "Fold 1, Epoch 12/24 - Train Loss: 0.1333, Train Acc: 0.8436 - Val Loss: 0.3106, Val Acc: 0.6232\n",
      "New best model found with accuracy 0.6884 and previous best 0.6304\n",
      "Fold 1, Epoch 13/24 - Train Loss: 0.1322, Train Acc: 0.8327 - Val Loss: 0.2974, Val Acc: 0.6884\n",
      "Fold 1, Epoch 14/24 - Train Loss: 0.1137, Train Acc: 0.8673 - Val Loss: 0.3300, Val Acc: 0.6522\n",
      "Fold 1, Epoch 15/24 - Train Loss: 0.0879, Train Acc: 0.8873 - Val Loss: 0.4117, Val Acc: 0.6812\n",
      "New best model found with accuracy 0.7101 and previous best 0.6884\n",
      "Fold 1, Epoch 16/24 - Train Loss: 0.0949, Train Acc: 0.8964 - Val Loss: 0.3227, Val Acc: 0.7101\n",
      "Fold 1, Epoch 17/24 - Train Loss: 0.1048, Train Acc: 0.8782 - Val Loss: 0.3904, Val Acc: 0.6377\n",
      "New best model found with accuracy 0.7319 and previous best 0.7101\n",
      "Fold 1, Epoch 18/24 - Train Loss: 0.0732, Train Acc: 0.9127 - Val Loss: 0.3077, Val Acc: 0.7319\n",
      "New best model found with accuracy 0.7536 and previous best 0.7319\n",
      "Fold 1, Epoch 19/24 - Train Loss: 0.0605, Train Acc: 0.9436 - Val Loss: 0.3118, Val Acc: 0.7536\n",
      "Fold 1, Epoch 20/24 - Train Loss: 0.0591, Train Acc: 0.9382 - Val Loss: 0.3150, Val Acc: 0.7464\n",
      "Fold 1, Epoch 21/24 - Train Loss: 0.0452, Train Acc: 0.9545 - Val Loss: 0.2923, Val Acc: 0.7464\n",
      "Fold 1, Epoch 22/24 - Train Loss: 0.0626, Train Acc: 0.9273 - Val Loss: 0.3365, Val Acc: 0.7101\n",
      "Fold 1, Epoch 23/24 - Train Loss: 0.0620, Train Acc: 0.9200 - Val Loss: 0.3108, Val Acc: 0.7391\n",
      "Fold 1, Epoch 24/24 - Train Loss: 0.0483, Train Acc: 0.9473 - Val Loss: 0.3289, Val Acc: 0.7174\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[46 18  1]\n",
      " [13 48  4]\n",
      " [ 1  2  5]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7667    0.7077    0.7360        65\n",
      "           1     0.7059    0.7385    0.7218        65\n",
      "           2     0.5000    0.6250    0.5556         8\n",
      "\n",
      "    accuracy                         0.7174       138\n",
      "   macro avg     0.6575    0.6904    0.6711       138\n",
      "weighted avg     0.7226    0.7174    0.7189       138\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.3768 and previous best 0.0000\n",
      "Fold 2, Epoch 1/24 - Train Loss: 0.4800, Train Acc: 0.4055 - Val Loss: 0.4739, Val Acc: 0.3768\n",
      "New best model found with accuracy 0.5217 and previous best 0.3768\n",
      "Fold 2, Epoch 2/24 - Train Loss: 0.3784, Train Acc: 0.5782 - Val Loss: 0.3806, Val Acc: 0.5217\n",
      "New best model found with accuracy 0.6232 and previous best 0.5217\n",
      "Fold 2, Epoch 3/24 - Train Loss: 0.2587, Train Acc: 0.6945 - Val Loss: 0.3052, Val Acc: 0.6232\n",
      "New best model found with accuracy 0.6594 and previous best 0.6232\n",
      "Fold 2, Epoch 4/24 - Train Loss: 0.1927, Train Acc: 0.7545 - Val Loss: 0.4000, Val Acc: 0.6594\n",
      "New best model found with accuracy 0.6884 and previous best 0.6594\n",
      "Fold 2, Epoch 5/24 - Train Loss: 0.1638, Train Acc: 0.8073 - Val Loss: 0.3592, Val Acc: 0.6884\n",
      "Fold 2, Epoch 6/24 - Train Loss: 0.1764, Train Acc: 0.7909 - Val Loss: 0.4460, Val Acc: 0.6014\n",
      "Fold 2, Epoch 7/24 - Train Loss: 0.1727, Train Acc: 0.7891 - Val Loss: 0.4717, Val Acc: 0.6304\n",
      "Fold 2, Epoch 8/24 - Train Loss: 0.2060, Train Acc: 0.7691 - Val Loss: 0.4688, Val Acc: 0.6087\n",
      "Fold 2, Epoch 9/24 - Train Loss: 0.1914, Train Acc: 0.7618 - Val Loss: 0.5024, Val Acc: 0.6377\n",
      "Fold 2, Epoch 10/24 - Train Loss: 0.1901, Train Acc: 0.7709 - Val Loss: 0.4918, Val Acc: 0.5870\n",
      "Fold 2, Epoch 11/24 - Train Loss: 0.1814, Train Acc: 0.7964 - Val Loss: 0.3396, Val Acc: 0.6449\n",
      "Fold 2, Epoch 12/24 - Train Loss: 0.1474, Train Acc: 0.8091 - Val Loss: 0.3410, Val Acc: 0.6377\n",
      "New best model found with accuracy 0.7101 and previous best 0.6884\n",
      "Fold 2, Epoch 13/24 - Train Loss: 0.1158, Train Acc: 0.8418 - Val Loss: 0.3037, Val Acc: 0.7101\n",
      "Fold 2, Epoch 14/24 - Train Loss: 0.1285, Train Acc: 0.8564 - Val Loss: 0.3139, Val Acc: 0.6957\n",
      "Fold 2, Epoch 15/24 - Train Loss: 0.0887, Train Acc: 0.8945 - Val Loss: 0.3690, Val Acc: 0.6957\n",
      "New best model found with accuracy 0.7464 and previous best 0.7101\n",
      "Fold 2, Epoch 16/24 - Train Loss: 0.0915, Train Acc: 0.8855 - Val Loss: 0.3181, Val Acc: 0.7464\n",
      "Fold 2, Epoch 17/24 - Train Loss: 0.0790, Train Acc: 0.8891 - Val Loss: 0.3468, Val Acc: 0.7029\n",
      "Fold 2, Epoch 18/24 - Train Loss: 0.0681, Train Acc: 0.9164 - Val Loss: 0.3564, Val Acc: 0.7174\n",
      "Fold 2, Epoch 19/24 - Train Loss: 0.0570, Train Acc: 0.9327 - Val Loss: 0.3281, Val Acc: 0.7174\n",
      "Fold 2, Epoch 20/24 - Train Loss: 0.0487, Train Acc: 0.9455 - Val Loss: 0.3504, Val Acc: 0.7391\n",
      "New best model found with accuracy 0.7536 and previous best 0.7464\n",
      "Fold 2, Epoch 21/24 - Train Loss: 0.0466, Train Acc: 0.9400 - Val Loss: 0.3415, Val Acc: 0.7536\n",
      "Fold 2, Epoch 22/24 - Train Loss: 0.0524, Train Acc: 0.9255 - Val Loss: 0.3367, Val Acc: 0.7246\n",
      "Fold 2, Epoch 23/24 - Train Loss: 0.0427, Train Acc: 0.9455 - Val Loss: 0.3475, Val Acc: 0.7391\n",
      "Fold 2, Epoch 24/24 - Train Loss: 0.0619, Train Acc: 0.9018 - Val Loss: 0.3330, Val Acc: 0.7391\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[48 17  0]\n",
      " [14 51  0]\n",
      " [ 4  1  3]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7273    0.7385    0.7328        65\n",
      "           1     0.7391    0.7846    0.7612        65\n",
      "           2     1.0000    0.3750    0.5455         8\n",
      "\n",
      "    accuracy                         0.7391       138\n",
      "   macro avg     0.8221    0.6327    0.6798       138\n",
      "weighted avg     0.7487    0.7391    0.7353       138\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [258 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.2754 and previous best 0.0000\n",
      "Fold 3, Epoch 1/24 - Train Loss: 0.4743, Train Acc: 0.4182 - Val Loss: 0.5540, Val Acc: 0.2754\n",
      "New best model found with accuracy 0.4783 and previous best 0.2754\n",
      "Fold 3, Epoch 2/24 - Train Loss: 0.3810, Train Acc: 0.5818 - Val Loss: 0.4245, Val Acc: 0.4783\n",
      "New best model found with accuracy 0.5652 and previous best 0.4783\n",
      "Fold 3, Epoch 3/24 - Train Loss: 0.2916, Train Acc: 0.6709 - Val Loss: 0.3576, Val Acc: 0.5652\n",
      "New best model found with accuracy 0.6449 and previous best 0.5652\n",
      "Fold 3, Epoch 4/24 - Train Loss: 0.1816, Train Acc: 0.7727 - Val Loss: 0.3315, Val Acc: 0.6449\n",
      "Fold 3, Epoch 5/24 - Train Loss: 0.1565, Train Acc: 0.7782 - Val Loss: 0.5785, Val Acc: 0.4855\n",
      "Fold 3, Epoch 6/24 - Train Loss: 0.1976, Train Acc: 0.7345 - Val Loss: 0.3279, Val Acc: 0.5507\n",
      "Fold 3, Epoch 7/24 - Train Loss: 0.1791, Train Acc: 0.7818 - Val Loss: 0.2830, Val Acc: 0.6304\n",
      "Fold 3, Epoch 8/24 - Train Loss: 0.1670, Train Acc: 0.8091 - Val Loss: 0.4997, Val Acc: 0.5797\n",
      "New best model found with accuracy 0.6812 and previous best 0.6449\n",
      "Fold 3, Epoch 9/24 - Train Loss: 0.1659, Train Acc: 0.8127 - Val Loss: 0.2761, Val Acc: 0.6812\n",
      "Fold 3, Epoch 10/24 - Train Loss: 0.1792, Train Acc: 0.8018 - Val Loss: 0.3433, Val Acc: 0.6667\n",
      "Fold 3, Epoch 11/24 - Train Loss: 0.1383, Train Acc: 0.8364 - Val Loss: 0.4137, Val Acc: 0.6594\n",
      "New best model found with accuracy 0.7174 and previous best 0.6812\n",
      "Fold 3, Epoch 12/24 - Train Loss: 0.1204, Train Acc: 0.8400 - Val Loss: 0.3041, Val Acc: 0.7174\n",
      "Fold 3, Epoch 13/24 - Train Loss: 0.0966, Train Acc: 0.8600 - Val Loss: 0.3601, Val Acc: 0.6812\n",
      "Fold 3, Epoch 14/24 - Train Loss: 0.1043, Train Acc: 0.8527 - Val Loss: 0.4191, Val Acc: 0.6739\n",
      "Fold 3, Epoch 15/24 - Train Loss: 0.1412, Train Acc: 0.8491 - Val Loss: 0.2840, Val Acc: 0.6739\n",
      "Fold 3, Epoch 16/24 - Train Loss: 0.1201, Train Acc: 0.8618 - Val Loss: 0.3576, Val Acc: 0.6594\n",
      "Fold 3, Epoch 17/24 - Train Loss: 0.0832, Train Acc: 0.8855 - Val Loss: 0.3902, Val Acc: 0.6739\n",
      "Fold 3, Epoch 18/24 - Train Loss: 0.0972, Train Acc: 0.8927 - Val Loss: 0.3775, Val Acc: 0.6884\n",
      "Fold 3, Epoch 19/24 - Train Loss: 0.0658, Train Acc: 0.9236 - Val Loss: 0.3795, Val Acc: 0.6522\n",
      "Fold 3, Epoch 20/24 - Train Loss: 0.0617, Train Acc: 0.9218 - Val Loss: 0.3820, Val Acc: 0.6449\n",
      "Fold 3, Epoch 21/24 - Train Loss: 0.0587, Train Acc: 0.9455 - Val Loss: 0.4052, Val Acc: 0.6812\n",
      "Fold 3, Epoch 22/24 - Train Loss: 0.0630, Train Acc: 0.9345 - Val Loss: 0.4105, Val Acc: 0.6884\n",
      "Fold 3, Epoch 23/24 - Train Loss: 0.0532, Train Acc: 0.9327 - Val Loss: 0.4088, Val Acc: 0.6739\n",
      "Fold 3, Epoch 24/24 - Train Loss: 0.0708, Train Acc: 0.9164 - Val Loss: 0.4194, Val Acc: 0.6812\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[40 25  0]\n",
      " [14 50  1]\n",
      " [ 1  3  4]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7273    0.6154    0.6667        65\n",
      "           1     0.6410    0.7692    0.6993        65\n",
      "           2     0.8000    0.5000    0.6154         8\n",
      "\n",
      "    accuracy                         0.6812       138\n",
      "   macro avg     0.7228    0.6282    0.6605       138\n",
      "weighted avg     0.6909    0.6812    0.6791       138\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [259 260  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.5401 and previous best 0.0000\n",
      "Fold 4, Epoch 1/24 - Train Loss: 0.4834, Train Acc: 0.4047 - Val Loss: 0.4482, Val Acc: 0.5401\n",
      "New best model found with accuracy 0.5474 and previous best 0.5401\n",
      "Fold 4, Epoch 2/24 - Train Loss: 0.3922, Train Acc: 0.5463 - Val Loss: 0.3660, Val Acc: 0.5474\n",
      "New best model found with accuracy 0.6204 and previous best 0.5474\n",
      "Fold 4, Epoch 3/24 - Train Loss: 0.2816, Train Acc: 0.6933 - Val Loss: 0.2709, Val Acc: 0.6204\n",
      "Fold 4, Epoch 4/24 - Train Loss: 0.1800, Train Acc: 0.8058 - Val Loss: 0.2946, Val Acc: 0.5985\n",
      "Fold 4, Epoch 5/24 - Train Loss: 0.1729, Train Acc: 0.7949 - Val Loss: 0.3091, Val Acc: 0.6058\n",
      "Fold 4, Epoch 6/24 - Train Loss: 0.1684, Train Acc: 0.7913 - Val Loss: 0.3305, Val Acc: 0.5839\n",
      "Fold 4, Epoch 7/24 - Train Loss: 0.1971, Train Acc: 0.7695 - Val Loss: 0.4721, Val Acc: 0.5985\n",
      "Fold 4, Epoch 8/24 - Train Loss: 0.1565, Train Acc: 0.8040 - Val Loss: 0.5611, Val Acc: 0.5547\n",
      "Fold 4, Epoch 9/24 - Train Loss: 0.2152, Train Acc: 0.7387 - Val Loss: 0.3583, Val Acc: 0.5766\n",
      "New best model found with accuracy 0.6788 and previous best 0.6204\n",
      "Fold 4, Epoch 10/24 - Train Loss: 0.1539, Train Acc: 0.8131 - Val Loss: 0.2977, Val Acc: 0.6788\n",
      "Fold 4, Epoch 11/24 - Train Loss: 0.1467, Train Acc: 0.8221 - Val Loss: 0.2663, Val Acc: 0.6569\n",
      "Fold 4, Epoch 12/24 - Train Loss: 0.1169, Train Acc: 0.8421 - Val Loss: 0.3647, Val Acc: 0.6642\n",
      "Fold 4, Epoch 13/24 - Train Loss: 0.1066, Train Acc: 0.8693 - Val Loss: 0.5690, Val Acc: 0.6131\n",
      "Fold 4, Epoch 14/24 - Train Loss: 0.1611, Train Acc: 0.8403 - Val Loss: 0.2800, Val Acc: 0.6496\n",
      "Fold 4, Epoch 15/24 - Train Loss: 0.1342, Train Acc: 0.8530 - Val Loss: 0.2582, Val Acc: 0.6569\n",
      "Fold 4, Epoch 16/24 - Train Loss: 0.0828, Train Acc: 0.9038 - Val Loss: 0.2993, Val Acc: 0.6788\n",
      "Fold 4, Epoch 17/24 - Train Loss: 0.0737, Train Acc: 0.8966 - Val Loss: 0.3632, Val Acc: 0.6715\n",
      "Fold 4, Epoch 18/24 - Train Loss: 0.0614, Train Acc: 0.9002 - Val Loss: 0.3137, Val Acc: 0.6715\n",
      "Fold 4, Epoch 19/24 - Train Loss: 0.0631, Train Acc: 0.9147 - Val Loss: 0.3293, Val Acc: 0.6788\n",
      "New best model found with accuracy 0.7080 and previous best 0.6788\n",
      "Fold 4, Epoch 20/24 - Train Loss: 0.0502, Train Acc: 0.9292 - Val Loss: 0.3503, Val Acc: 0.7080\n",
      "Fold 4, Epoch 21/24 - Train Loss: 0.0541, Train Acc: 0.9365 - Val Loss: 0.3227, Val Acc: 0.6642\n",
      "Fold 4, Epoch 22/24 - Train Loss: 0.0541, Train Acc: 0.9328 - Val Loss: 0.3077, Val Acc: 0.6715\n",
      "Fold 4, Epoch 23/24 - Train Loss: 0.0402, Train Acc: 0.9546 - Val Loss: 0.3050, Val Acc: 0.6642\n",
      "Fold 4, Epoch 24/24 - Train Loss: 0.0504, Train Acc: 0.9474 - Val Loss: 0.3256, Val Acc: 0.6861\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[45 18  1]\n",
      " [20 46  0]\n",
      " [ 2  2  3]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6716    0.7031    0.6870        64\n",
      "           1     0.6970    0.6970    0.6970        66\n",
      "           2     0.7500    0.4286    0.5455         7\n",
      "\n",
      "    accuracy                         0.6861       137\n",
      "   macro avg     0.7062    0.6096    0.6431       137\n",
      "weighted avg     0.6878    0.6861    0.6846       137\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [259 261  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4891 and previous best 0.0000\n",
      "Fold 5, Epoch 1/24 - Train Loss: 0.4767, Train Acc: 0.4229 - Val Loss: 0.4423, Val Acc: 0.4891\n",
      "New best model found with accuracy 0.5474 and previous best 0.4891\n",
      "Fold 5, Epoch 2/24 - Train Loss: 0.3955, Train Acc: 0.5662 - Val Loss: 0.3612, Val Acc: 0.5474\n",
      "New best model found with accuracy 0.6058 and previous best 0.5474\n",
      "Fold 5, Epoch 3/24 - Train Loss: 0.2882, Train Acc: 0.7042 - Val Loss: 0.2933, Val Acc: 0.6058\n",
      "New best model found with accuracy 0.6423 and previous best 0.6058\n",
      "Fold 5, Epoch 4/24 - Train Loss: 0.2011, Train Acc: 0.7477 - Val Loss: 0.2524, Val Acc: 0.6423\n",
      "Fold 5, Epoch 5/24 - Train Loss: 0.1547, Train Acc: 0.8240 - Val Loss: 0.3429, Val Acc: 0.6277\n",
      "Fold 5, Epoch 6/24 - Train Loss: 0.1943, Train Acc: 0.7931 - Val Loss: 0.3388, Val Acc: 0.5766\n",
      "Fold 5, Epoch 7/24 - Train Loss: 0.1952, Train Acc: 0.7858 - Val Loss: 0.4560, Val Acc: 0.6204\n",
      "Fold 5, Epoch 8/24 - Train Loss: 0.2237, Train Acc: 0.7495 - Val Loss: 0.3157, Val Acc: 0.6058\n",
      "Fold 5, Epoch 9/24 - Train Loss: 0.1678, Train Acc: 0.7877 - Val Loss: 0.2785, Val Acc: 0.6058\n",
      "New best model found with accuracy 0.6642 and previous best 0.6423\n",
      "Fold 5, Epoch 10/24 - Train Loss: 0.1372, Train Acc: 0.8385 - Val Loss: 0.3396, Val Acc: 0.6642\n",
      "Fold 5, Epoch 11/24 - Train Loss: 0.1291, Train Acc: 0.8494 - Val Loss: 0.4336, Val Acc: 0.6058\n",
      "Fold 5, Epoch 12/24 - Train Loss: 0.1410, Train Acc: 0.8367 - Val Loss: 0.3711, Val Acc: 0.6131\n",
      "Fold 5, Epoch 13/24 - Train Loss: 0.1160, Train Acc: 0.8548 - Val Loss: 0.2773, Val Acc: 0.6058\n",
      "Fold 5, Epoch 14/24 - Train Loss: 0.1122, Train Acc: 0.8475 - Val Loss: 0.2967, Val Acc: 0.6131\n",
      "New best model found with accuracy 0.6788 and previous best 0.6642\n",
      "Fold 5, Epoch 15/24 - Train Loss: 0.0888, Train Acc: 0.8875 - Val Loss: 0.2990, Val Acc: 0.6788\n",
      "Fold 5, Epoch 16/24 - Train Loss: 0.0752, Train Acc: 0.9002 - Val Loss: 0.3528, Val Acc: 0.5912\n",
      "Fold 5, Epoch 17/24 - Train Loss: 0.0749, Train Acc: 0.9056 - Val Loss: 0.4047, Val Acc: 0.6788\n",
      "Fold 5, Epoch 18/24 - Train Loss: 0.0637, Train Acc: 0.9201 - Val Loss: 0.4406, Val Acc: 0.6569\n",
      "Fold 5, Epoch 19/24 - Train Loss: 0.0688, Train Acc: 0.9310 - Val Loss: 0.5013, Val Acc: 0.6423\n",
      "Fold 5, Epoch 20/24 - Train Loss: 0.0593, Train Acc: 0.9256 - Val Loss: 0.4300, Val Acc: 0.6496\n",
      "Fold 5, Epoch 21/24 - Train Loss: 0.0640, Train Acc: 0.9201 - Val Loss: 0.3914, Val Acc: 0.6569\n",
      "Fold 5, Epoch 22/24 - Train Loss: 0.0619, Train Acc: 0.9383 - Val Loss: 0.3924, Val Acc: 0.6423\n",
      "Fold 5, Epoch 23/24 - Train Loss: 0.0523, Train Acc: 0.9401 - Val Loss: 0.4020, Val Acc: 0.6569\n",
      "Fold 5, Epoch 24/24 - Train Loss: 0.0375, Train Acc: 0.9637 - Val Loss: 0.3831, Val Acc: 0.6569\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[42 22  0]\n",
      " [21 44  0]\n",
      " [ 1  3  4]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6562    0.6562    0.6562        64\n",
      "           1     0.6377    0.6769    0.6567        65\n",
      "           2     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.6569       137\n",
      "   macro avg     0.7646    0.6111    0.6599       137\n",
      "weighted avg     0.6675    0.6569    0.6571       137\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.7536231884057971, 0.7536231884057971, 0.717391304347826, 0.708029197080292, 0.6788321167883211]]\n",
      "['Mean Accuracy:', np.float64(0.7222997990056067)]\n",
      "['Average Recalls:', {'0': np.float64(0.6841826923076924), '1': np.float64(0.7332400932400933), '2': np.float64(0.48571428571428577)}]\n"
     ]
    }
   ],
   "source": [
    "kf_models_normal, accs_normal, recalls = run_kfold_training(\n",
    "    data_dir=normal_data_dir,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    loss_fn=focal,\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    num_epochs=24,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=3,\n",
    "    use_best_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86174494",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_accuracies['normal'] = 0.7222997990056067 #np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7f35e",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ensemble_to_onnx(kf_models_normal, accs_normal, output_path=\"normal_subtype_classification.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994bb6b",
   "metadata": {},
   "source": [
    "# Loose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c5b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../datasets/data-loose -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84190b04",
   "metadata": {},
   "source": [
    "## Single Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5c0b452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [34 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4000 and previous best 0.0000\n",
      "Fold None, Epoch 1/30 - Train Loss: 1.1539, Train Acc: 0.2500 - Val Loss: 1.0984, Val Acc: 0.4000\n",
      "New best model found with accuracy 0.5600 and previous best 0.4000\n",
      "Fold None, Epoch 2/30 - Train Loss: 1.0635, Train Acc: 0.4700 - Val Loss: 1.0168, Val Acc: 0.5600\n",
      "New best model found with accuracy 0.7600 and previous best 0.5600\n",
      "Fold None, Epoch 3/30 - Train Loss: 0.9596, Train Acc: 0.7600 - Val Loss: 0.8771, Val Acc: 0.7600\n",
      "Fold None, Epoch 4/30 - Train Loss: 0.7760, Train Acc: 0.8300 - Val Loss: 0.7119, Val Acc: 0.7200\n",
      "Fold None, Epoch 5/30 - Train Loss: 0.6976, Train Acc: 0.7700 - Val Loss: 0.6206, Val Acc: 0.7600\n",
      "New best model found with accuracy 0.8800 and previous best 0.7600\n",
      "Fold None, Epoch 6/30 - Train Loss: 0.5042, Train Acc: 0.9000 - Val Loss: 0.5840, Val Acc: 0.8800\n",
      "Fold None, Epoch 7/30 - Train Loss: 0.4460, Train Acc: 0.9200 - Val Loss: 0.4992, Val Acc: 0.8800\n",
      "Fold None, Epoch 8/30 - Train Loss: 0.4116, Train Acc: 0.9600 - Val Loss: 0.7347, Val Acc: 0.7600\n",
      "New best model found with accuracy 0.9200 and previous best 0.8800\n",
      "Fold None, Epoch 9/30 - Train Loss: 0.4883, Train Acc: 0.9100 - Val Loss: 0.4730, Val Acc: 0.9200\n",
      "Fold None, Epoch 10/30 - Train Loss: 0.4290, Train Acc: 0.9400 - Val Loss: 0.4487, Val Acc: 0.9200\n",
      "Fold None, Epoch 11/30 - Train Loss: 0.4728, Train Acc: 0.9000 - Val Loss: 0.4821, Val Acc: 0.9200\n",
      "New best model found with accuracy 1.0000 and previous best 0.9200\n",
      "Fold None, Epoch 12/30 - Train Loss: 0.5260, Train Acc: 0.8500 - Val Loss: 0.4366, Val Acc: 1.0000\n",
      "Fold None, Epoch 13/30 - Train Loss: 0.5290, Train Acc: 0.8800 - Val Loss: 0.4971, Val Acc: 0.8400\n",
      "Fold None, Epoch 14/30 - Train Loss: 0.4664, Train Acc: 0.8900 - Val Loss: 0.4706, Val Acc: 0.9200\n",
      "Fold None, Epoch 15/30 - Train Loss: 0.4530, Train Acc: 0.9100 - Val Loss: 0.3908, Val Acc: 0.9600\n",
      "Fold None, Epoch 16/30 - Train Loss: 0.4759, Train Acc: 0.8700 - Val Loss: 0.4586, Val Acc: 0.8800\n",
      "Fold None, Epoch 17/30 - Train Loss: 0.4430, Train Acc: 0.9300 - Val Loss: 0.5829, Val Acc: 0.8800\n",
      "Fold None, Epoch 18/30 - Train Loss: 0.5280, Train Acc: 0.8400 - Val Loss: 0.6038, Val Acc: 0.8800\n",
      "Fold None, Epoch 19/30 - Train Loss: 0.4094, Train Acc: 0.9600 - Val Loss: 0.5440, Val Acc: 0.8800\n",
      "Fold None, Epoch 20/30 - Train Loss: 0.4088, Train Acc: 0.9600 - Val Loss: 0.4691, Val Acc: 0.8800\n",
      "Fold None, Epoch 21/30 - Train Loss: 0.3800, Train Acc: 0.9700 - Val Loss: 0.4459, Val Acc: 0.8800\n",
      "Fold None, Epoch 22/30 - Train Loss: 0.3923, Train Acc: 0.9600 - Val Loss: 0.4665, Val Acc: 0.8800\n",
      "Fold None, Epoch 23/30 - Train Loss: 0.4042, Train Acc: 0.9500 - Val Loss: 0.4599, Val Acc: 0.8400\n",
      "Fold None, Epoch 24/30 - Train Loss: 0.4263, Train Acc: 0.9100 - Val Loss: 0.4465, Val Acc: 0.8400\n",
      "Fold None, Epoch 25/30 - Train Loss: 0.3577, Train Acc: 0.9700 - Val Loss: 0.4380, Val Acc: 0.8400\n",
      "Fold None, Epoch 26/30 - Train Loss: 0.3843, Train Acc: 0.9500 - Val Loss: 0.4315, Val Acc: 0.8400\n",
      "Fold None, Epoch 27/30 - Train Loss: 0.3954, Train Acc: 0.9500 - Val Loss: 0.4331, Val Acc: 0.8400\n",
      "Fold None, Epoch 28/30 - Train Loss: 0.3582, Train Acc: 0.9600 - Val Loss: 0.4320, Val Acc: 0.8400\n",
      "Fold None, Epoch 29/30 - Train Loss: 0.3862, Train Acc: 0.9400 - Val Loss: 0.4231, Val Acc: 0.8400\n",
      "Fold None, Epoch 30/30 - Train Loss: 0.3866, Train Acc: 0.9500 - Val Loss: 0.4356, Val Acc: 0.8800\n",
      "--- Confusion Matrix ---\n",
      "[[ 6  2]\n",
      " [ 1 16]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.7500    0.8000         8\n",
      "           1     0.8889    0.9412    0.9143        17\n",
      "\n",
      "    accuracy                         0.8800        25\n",
      "   macro avg     0.8730    0.8456    0.8571        25\n",
      "weighted avg     0.8787    0.8800    0.8777        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc, lrs = train_single_split(\n",
    "    data_dir=loose_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=smooth, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=30,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3ee5c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"OneCycleLR Schedule\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lr-schedule.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "356b44ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [34 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 0.4955, Train Acc: 0.3400 - Val Loss: 0.4061, Val Acc: 0.6000\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.4341, Train Acc: 0.5300 - Val Loss: 0.3819, Val Acc: 0.6000\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.3872, Train Acc: 0.6000 - Val Loss: 0.3477, Val Acc: 0.6400\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.3657, Train Acc: 0.6900 - Val Loss: 0.3014, Val Acc: 0.8000\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.3392, Train Acc: 0.6600 - Val Loss: 0.2633, Val Acc: 0.8800\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.2646, Train Acc: 0.7900 - Val Loss: 0.2159, Val Acc: 0.8400\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.2177, Train Acc: 0.8100 - Val Loss: 0.1763, Val Acc: 0.8000\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.1847, Train Acc: 0.8400 - Val Loss: 0.1495, Val Acc: 0.8400\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.1469, Train Acc: 0.8800 - Val Loss: 0.1251, Val Acc: 0.8800\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.0952, Train Acc: 0.9200 - Val Loss: 0.1109, Val Acc: 0.8800\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.0733, Train Acc: 0.9400 - Val Loss: 0.1170, Val Acc: 0.9200\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.0557, Train Acc: 0.9300 - Val Loss: 0.1048, Val Acc: 0.8800\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.0312, Train Acc: 0.9600 - Val Loss: 0.1239, Val Acc: 0.8800\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.0369, Train Acc: 0.9700 - Val Loss: 0.1351, Val Acc: 0.8800\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.0372, Train Acc: 0.9700 - Val Loss: 0.1670, Val Acc: 0.8400\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.0556, Train Acc: 0.9500 - Val Loss: 0.2193, Val Acc: 0.8400\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.0510, Train Acc: 0.9300 - Val Loss: 0.2019, Val Acc: 0.8400\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.0540, Train Acc: 0.9500 - Val Loss: 0.3070, Val Acc: 0.8800\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.0467, Train Acc: 0.9400 - Val Loss: 0.2333, Val Acc: 0.8800\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.0539, Train Acc: 0.9300 - Val Loss: 0.1622, Val Acc: 0.9200\n",
      "--- Confusion Matrix ---\n",
      "[[ 6  2]\n",
      " [ 1 16]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.7500    0.8000         8\n",
      "           1     0.8889    0.9412    0.9143        17\n",
      "\n",
      "    accuracy                         0.8800        25\n",
      "   macro avg     0.8730    0.8456    0.8571        25\n",
      "weighted avg     0.8787    0.8800    0.8777        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=loose_data_dir,\n",
    "    model_name='efficientnet_b0',\n",
    "    loss_fn=focal, # 'focal' or 'smooth'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348b09a",
   "metadata": {},
   "source": [
    "## K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf415235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n",
      "Class sample counts: [33 67]\n",
      "Training set length: 100\n",
      "Validation set length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.5600 and previous best 0.0000\n",
      "Fold 1, Epoch 1/20 - Train Loss: 0.6805, Train Acc: 0.5700 - Val Loss: 0.6969, Val Acc: 0.5600\n",
      "New best model found with accuracy 0.7600 and previous best 0.5600\n",
      "Fold 1, Epoch 2/20 - Train Loss: 0.6497, Train Acc: 0.6100 - Val Loss: 0.6129, Val Acc: 0.7600\n",
      "New best model found with accuracy 0.8800 and previous best 0.7600\n",
      "Fold 1, Epoch 3/20 - Train Loss: 0.5690, Train Acc: 0.8300 - Val Loss: 0.4837, Val Acc: 0.8800\n",
      "Fold 1, Epoch 4/20 - Train Loss: 0.4551, Train Acc: 0.8700 - Val Loss: 0.4643, Val Acc: 0.7600\n",
      "Fold 1, Epoch 5/20 - Train Loss: 0.3467, Train Acc: 0.9100 - Val Loss: 0.6070, Val Acc: 0.7200\n",
      "Fold 1, Epoch 6/20 - Train Loss: 0.3332, Train Acc: 0.9200 - Val Loss: 0.5659, Val Acc: 0.8400\n",
      "Fold 1, Epoch 7/20 - Train Loss: 0.3457, Train Acc: 0.9100 - Val Loss: 0.5252, Val Acc: 0.8400\n",
      "Fold 1, Epoch 8/20 - Train Loss: 0.4173, Train Acc: 0.9200 - Val Loss: 0.5553, Val Acc: 0.7600\n",
      "Fold 1, Epoch 9/20 - Train Loss: 0.3155, Train Acc: 0.9600 - Val Loss: 0.5593, Val Acc: 0.7600\n",
      "Fold 1, Epoch 10/20 - Train Loss: 0.3890, Train Acc: 0.8900 - Val Loss: 0.7299, Val Acc: 0.8000\n",
      "Fold 1, Epoch 11/20 - Train Loss: 0.3336, Train Acc: 0.9400 - Val Loss: 0.7446, Val Acc: 0.8000\n",
      "Fold 1, Epoch 12/20 - Train Loss: 0.3550, Train Acc: 0.8900 - Val Loss: 0.5068, Val Acc: 0.7600\n",
      "Fold 1, Epoch 13/20 - Train Loss: 0.3266, Train Acc: 0.9300 - Val Loss: 0.4902, Val Acc: 0.8000\n",
      "Fold 1, Epoch 14/20 - Train Loss: 0.2885, Train Acc: 0.9700 - Val Loss: 0.6191, Val Acc: 0.7200\n",
      "Fold 1, Epoch 15/20 - Train Loss: 0.2922, Train Acc: 0.9700 - Val Loss: 0.5519, Val Acc: 0.8000\n",
      "Fold 1, Epoch 16/20 - Train Loss: 0.3029, Train Acc: 0.9600 - Val Loss: 0.5584, Val Acc: 0.8000\n",
      "Fold 1, Epoch 17/20 - Train Loss: 0.3360, Train Acc: 0.9200 - Val Loss: 0.5453, Val Acc: 0.8000\n",
      "Fold 1, Epoch 18/20 - Train Loss: 0.2482, Train Acc: 0.9800 - Val Loss: 0.4913, Val Acc: 0.8000\n",
      "Fold 1, Epoch 19/20 - Train Loss: 0.3060, Train Acc: 0.9400 - Val Loss: 0.5095, Val Acc: 0.8000\n",
      "Fold 1, Epoch 20/20 - Train Loss: 0.2785, Train Acc: 0.9600 - Val Loss: 0.4799, Val Acc: 0.8400\n",
      "\n",
      "--- Fold 1 Confusion Matrix ---\n",
      "[[ 9  0]\n",
      " [ 4 12]]\n",
      "\n",
      "--- Fold 1 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    1.0000    0.8182         9\n",
      "           1     1.0000    0.7500    0.8571        16\n",
      "\n",
      "    accuracy                         0.8400        25\n",
      "   macro avg     0.8462    0.8750    0.8377        25\n",
      "weighted avg     0.8892    0.8400    0.8431        25\n",
      "\n",
      "\n",
      "======= Fold 2 =======\n",
      "Class sample counts: [33 67]\n",
      "Training set length: 100\n",
      "Validation set length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.6400 and previous best 0.0000\n",
      "Fold 2, Epoch 1/20 - Train Loss: 0.6972, Train Acc: 0.5800 - Val Loss: 0.6752, Val Acc: 0.6400\n",
      "New best model found with accuracy 0.6800 and previous best 0.6400\n",
      "Fold 2, Epoch 2/20 - Train Loss: 0.6384, Train Acc: 0.7100 - Val Loss: 0.6097, Val Acc: 0.6800\n",
      "Fold 2, Epoch 3/20 - Train Loss: 0.5515, Train Acc: 0.8200 - Val Loss: 0.5782, Val Acc: 0.6400\n",
      "New best model found with accuracy 0.7200 and previous best 0.6800\n",
      "Fold 2, Epoch 4/20 - Train Loss: 0.3931, Train Acc: 0.9200 - Val Loss: 0.6606, Val Acc: 0.7200\n",
      "Fold 2, Epoch 5/20 - Train Loss: 0.3305, Train Acc: 0.9300 - Val Loss: 0.7714, Val Acc: 0.7200\n",
      "New best model found with accuracy 0.8000 and previous best 0.7200\n",
      "Fold 2, Epoch 6/20 - Train Loss: 0.3407, Train Acc: 0.9100 - Val Loss: 0.6318, Val Acc: 0.8000\n",
      "Fold 2, Epoch 7/20 - Train Loss: 0.2781, Train Acc: 0.9700 - Val Loss: 0.5189, Val Acc: 0.7600\n",
      "New best model found with accuracy 0.8400 and previous best 0.8000\n",
      "Fold 2, Epoch 8/20 - Train Loss: 0.2733, Train Acc: 0.9700 - Val Loss: 0.5541, Val Acc: 0.8400\n",
      "Fold 2, Epoch 9/20 - Train Loss: 0.2730, Train Acc: 0.9800 - Val Loss: 0.8537, Val Acc: 0.6800\n",
      "Fold 2, Epoch 10/20 - Train Loss: 0.3771, Train Acc: 0.9400 - Val Loss: 0.6107, Val Acc: 0.7600\n",
      "Fold 2, Epoch 11/20 - Train Loss: 0.4768, Train Acc: 0.8800 - Val Loss: 0.8110, Val Acc: 0.6000\n",
      "Fold 2, Epoch 12/20 - Train Loss: 0.3865, Train Acc: 0.8500 - Val Loss: 0.7340, Val Acc: 0.7200\n",
      "Fold 2, Epoch 13/20 - Train Loss: 0.3575, Train Acc: 0.9100 - Val Loss: 0.7289, Val Acc: 0.7600\n",
      "Fold 2, Epoch 14/20 - Train Loss: 0.3284, Train Acc: 0.9300 - Val Loss: 0.6687, Val Acc: 0.7600\n",
      "Fold 2, Epoch 15/20 - Train Loss: 0.3361, Train Acc: 0.9400 - Val Loss: 0.5719, Val Acc: 0.6800\n",
      "Fold 2, Epoch 16/20 - Train Loss: 0.2928, Train Acc: 0.9700 - Val Loss: 0.5588, Val Acc: 0.7200\n",
      "Fold 2, Epoch 17/20 - Train Loss: 0.3509, Train Acc: 0.9200 - Val Loss: 0.5521, Val Acc: 0.7600\n",
      "Fold 2, Epoch 18/20 - Train Loss: 0.3543, Train Acc: 0.8700 - Val Loss: 0.5533, Val Acc: 0.8000\n",
      "Fold 2, Epoch 19/20 - Train Loss: 0.2813, Train Acc: 0.9600 - Val Loss: 0.5595, Val Acc: 0.7200\n",
      "Fold 2, Epoch 20/20 - Train Loss: 0.2727, Train Acc: 0.9900 - Val Loss: 0.5544, Val Acc: 0.7600\n",
      "\n",
      "--- Fold 2 Confusion Matrix ---\n",
      "[[ 5  4]\n",
      " [ 2 14]]\n",
      "\n",
      "--- Fold 2 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.5556    0.6250         9\n",
      "           1     0.7778    0.8750    0.8235        16\n",
      "\n",
      "    accuracy                         0.7600        25\n",
      "   macro avg     0.7460    0.7153    0.7243        25\n",
      "weighted avg     0.7549    0.7600    0.7521        25\n",
      "\n",
      "\n",
      "======= Fold 3 =======\n",
      "Class sample counts: [34 66]\n",
      "Training set length: 100\n",
      "Validation set length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4000 and previous best 0.0000\n",
      "Fold 3, Epoch 1/20 - Train Loss: 0.6880, Train Acc: 0.5100 - Val Loss: 0.7234, Val Acc: 0.4000\n",
      "New best model found with accuracy 0.6800 and previous best 0.4000\n",
      "Fold 3, Epoch 2/20 - Train Loss: 0.6371, Train Acc: 0.6600 - Val Loss: 0.6125, Val Acc: 0.6800\n",
      "New best model found with accuracy 0.8400 and previous best 0.6800\n",
      "Fold 3, Epoch 3/20 - Train Loss: 0.5703, Train Acc: 0.7800 - Val Loss: 0.4562, Val Acc: 0.8400\n",
      "New best model found with accuracy 0.9200 and previous best 0.8400\n",
      "Fold 3, Epoch 4/20 - Train Loss: 0.5201, Train Acc: 0.7300 - Val Loss: 0.3667, Val Acc: 0.9200\n",
      "Fold 3, Epoch 5/20 - Train Loss: 0.3742, Train Acc: 0.9200 - Val Loss: 0.3208, Val Acc: 0.9200\n",
      "New best model found with accuracy 0.9600 and previous best 0.9200\n",
      "Fold 3, Epoch 6/20 - Train Loss: 0.3258, Train Acc: 0.9200 - Val Loss: 0.3089, Val Acc: 0.9600\n",
      "Fold 3, Epoch 7/20 - Train Loss: 0.4186, Train Acc: 0.8800 - Val Loss: 0.4121, Val Acc: 0.8800\n",
      "Fold 3, Epoch 8/20 - Train Loss: 0.4097, Train Acc: 0.8800 - Val Loss: 0.4860, Val Acc: 0.8400\n",
      "Fold 3, Epoch 9/20 - Train Loss: 0.4426, Train Acc: 0.8900 - Val Loss: 0.4170, Val Acc: 0.8400\n",
      "Fold 3, Epoch 10/20 - Train Loss: 0.4405, Train Acc: 0.8200 - Val Loss: 0.3404, Val Acc: 0.9200\n",
      "Fold 3, Epoch 11/20 - Train Loss: 0.3884, Train Acc: 0.8900 - Val Loss: 0.3426, Val Acc: 0.9200\n",
      "Fold 3, Epoch 12/20 - Train Loss: 0.3707, Train Acc: 0.9400 - Val Loss: 0.3056, Val Acc: 0.9200\n",
      "Fold 3, Epoch 13/20 - Train Loss: 0.3684, Train Acc: 0.9300 - Val Loss: 0.2829, Val Acc: 0.9600\n",
      "Fold 3, Epoch 14/20 - Train Loss: 0.3181, Train Acc: 0.9300 - Val Loss: 0.2879, Val Acc: 0.9600\n",
      "Fold 3, Epoch 15/20 - Train Loss: 0.2743, Train Acc: 0.9800 - Val Loss: 0.2959, Val Acc: 0.9600\n",
      "Fold 3, Epoch 16/20 - Train Loss: 0.3917, Train Acc: 0.8800 - Val Loss: 0.3124, Val Acc: 0.9200\n",
      "Fold 3, Epoch 17/20 - Train Loss: 0.3178, Train Acc: 0.9300 - Val Loss: 0.2548, Val Acc: 0.9600\n",
      "Fold 3, Epoch 18/20 - Train Loss: 0.2788, Train Acc: 0.9700 - Val Loss: 0.2590, Val Acc: 0.9600\n",
      "Fold 3, Epoch 19/20 - Train Loss: 0.2718, Train Acc: 0.9600 - Val Loss: 0.2712, Val Acc: 0.9600\n",
      "Fold 3, Epoch 20/20 - Train Loss: 0.2830, Train Acc: 0.9700 - Val Loss: 0.2441, Val Acc: 0.9600\n",
      "\n",
      "--- Fold 3 Confusion Matrix ---\n",
      "[[ 7  1]\n",
      " [ 0 17]]\n",
      "\n",
      "--- Fold 3 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8750    0.9333         8\n",
      "           1     0.9444    1.0000    0.9714        17\n",
      "\n",
      "    accuracy                         0.9600        25\n",
      "   macro avg     0.9722    0.9375    0.9524        25\n",
      "weighted avg     0.9622    0.9600    0.9592        25\n",
      "\n",
      "\n",
      "======= Fold 4 =======\n",
      "Class sample counts: [34 66]\n",
      "Training set length: 100\n",
      "Validation set length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.4800 and previous best 0.0000\n",
      "Fold 4, Epoch 1/20 - Train Loss: 0.6919, Train Acc: 0.5100 - Val Loss: 0.7012, Val Acc: 0.4800\n",
      "New best model found with accuracy 0.6000 and previous best 0.4800\n",
      "Fold 4, Epoch 2/20 - Train Loss: 0.6384, Train Acc: 0.6700 - Val Loss: 0.6573, Val Acc: 0.6000\n",
      "New best model found with accuracy 0.6400 and previous best 0.6000\n",
      "Fold 4, Epoch 3/20 - Train Loss: 0.5650, Train Acc: 0.7500 - Val Loss: 0.5730, Val Acc: 0.6400\n",
      "New best model found with accuracy 0.7200 and previous best 0.6400\n",
      "Fold 4, Epoch 4/20 - Train Loss: 0.4681, Train Acc: 0.8500 - Val Loss: 0.5236, Val Acc: 0.7200\n",
      "New best model found with accuracy 0.7600 and previous best 0.7200\n",
      "Fold 4, Epoch 5/20 - Train Loss: 0.3837, Train Acc: 0.8900 - Val Loss: 0.5022, Val Acc: 0.7600\n",
      "Fold 4, Epoch 6/20 - Train Loss: 0.3027, Train Acc: 0.9300 - Val Loss: 0.6556, Val Acc: 0.6400\n",
      "Fold 4, Epoch 7/20 - Train Loss: 0.3323, Train Acc: 0.9300 - Val Loss: 0.8971, Val Acc: 0.6400\n",
      "Fold 4, Epoch 8/20 - Train Loss: 0.3433, Train Acc: 0.9000 - Val Loss: 0.5683, Val Acc: 0.7600\n",
      "Fold 4, Epoch 9/20 - Train Loss: 0.3611, Train Acc: 0.8900 - Val Loss: 0.6862, Val Acc: 0.7200\n",
      "Fold 4, Epoch 10/20 - Train Loss: 0.3591, Train Acc: 0.8900 - Val Loss: 0.9477, Val Acc: 0.7200\n",
      "Fold 4, Epoch 11/20 - Train Loss: 0.3314, Train Acc: 0.9600 - Val Loss: 0.7535, Val Acc: 0.7600\n",
      "New best model found with accuracy 0.8000 and previous best 0.7600\n",
      "Fold 4, Epoch 12/20 - Train Loss: 0.3859, Train Acc: 0.8700 - Val Loss: 0.5637, Val Acc: 0.8000\n",
      "New best model found with accuracy 0.8400 and previous best 0.8000\n",
      "Fold 4, Epoch 13/20 - Train Loss: 0.3380, Train Acc: 0.8700 - Val Loss: 0.4689, Val Acc: 0.8400\n",
      "Fold 4, Epoch 14/20 - Train Loss: 0.3429, Train Acc: 0.9100 - Val Loss: 0.4817, Val Acc: 0.8400\n",
      "Fold 4, Epoch 15/20 - Train Loss: 0.3412, Train Acc: 0.9200 - Val Loss: 0.5153, Val Acc: 0.8400\n",
      "Fold 4, Epoch 16/20 - Train Loss: 0.3296, Train Acc: 0.9500 - Val Loss: 0.5666, Val Acc: 0.7600\n",
      "Fold 4, Epoch 17/20 - Train Loss: 0.2901, Train Acc: 0.9800 - Val Loss: 0.4961, Val Acc: 0.8000\n",
      "Fold 4, Epoch 18/20 - Train Loss: 0.3232, Train Acc: 0.9400 - Val Loss: 0.4916, Val Acc: 0.8400\n",
      "Fold 4, Epoch 19/20 - Train Loss: 0.3043, Train Acc: 0.9500 - Val Loss: 0.4884, Val Acc: 0.8400\n",
      "Fold 4, Epoch 20/20 - Train Loss: 0.2809, Train Acc: 0.9800 - Val Loss: 0.4853, Val Acc: 0.8400\n",
      "\n",
      "--- Fold 4 Confusion Matrix ---\n",
      "[[ 5  3]\n",
      " [ 1 16]]\n",
      "\n",
      "--- Fold 4 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.6250    0.7143         8\n",
      "           1     0.8421    0.9412    0.8889        17\n",
      "\n",
      "    accuracy                         0.8400        25\n",
      "   macro avg     0.8377    0.7831    0.8016        25\n",
      "weighted avg     0.8393    0.8400    0.8330        25\n",
      "\n",
      "\n",
      "======= Fold 5 =======\n",
      "Class sample counts: [34 66]\n",
      "Training set length: 100\n",
      "Validation set length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with accuracy 0.6000 and previous best 0.0000\n",
      "Fold 5, Epoch 1/20 - Train Loss: 0.6976, Train Acc: 0.4900 - Val Loss: 0.6660, Val Acc: 0.6000\n",
      "New best model found with accuracy 0.7600 and previous best 0.6000\n",
      "Fold 5, Epoch 2/20 - Train Loss: 0.6493, Train Acc: 0.6800 - Val Loss: 0.6021, Val Acc: 0.7600\n",
      "Fold 5, Epoch 3/20 - Train Loss: 0.5979, Train Acc: 0.7200 - Val Loss: 0.5333, Val Acc: 0.7200\n",
      "New best model found with accuracy 0.8000 and previous best 0.7600\n",
      "Fold 5, Epoch 4/20 - Train Loss: 0.4651, Train Acc: 0.8800 - Val Loss: 0.4238, Val Acc: 0.8000\n",
      "Fold 5, Epoch 5/20 - Train Loss: 0.4064, Train Acc: 0.8800 - Val Loss: 0.6309, Val Acc: 0.6800\n",
      "New best model found with accuracy 0.8400 and previous best 0.8000\n",
      "Fold 5, Epoch 6/20 - Train Loss: 0.3829, Train Acc: 0.8900 - Val Loss: 0.4243, Val Acc: 0.8400\n",
      "New best model found with accuracy 0.9200 and previous best 0.8400\n",
      "Fold 5, Epoch 7/20 - Train Loss: 0.2754, Train Acc: 0.9800 - Val Loss: 0.3190, Val Acc: 0.9200\n",
      "Fold 5, Epoch 8/20 - Train Loss: 0.3903, Train Acc: 0.9100 - Val Loss: 0.7052, Val Acc: 0.7600\n",
      "Fold 5, Epoch 9/20 - Train Loss: 0.3416, Train Acc: 0.9100 - Val Loss: 1.0319, Val Acc: 0.5600\n",
      "Fold 5, Epoch 10/20 - Train Loss: 0.3659, Train Acc: 0.9200 - Val Loss: 0.4401, Val Acc: 0.9200\n",
      "New best model found with accuracy 0.9600 and previous best 0.9200\n",
      "Fold 5, Epoch 11/20 - Train Loss: 0.3173, Train Acc: 0.9300 - Val Loss: 0.3382, Val Acc: 0.9600\n",
      "Fold 5, Epoch 12/20 - Train Loss: 0.3242, Train Acc: 0.9100 - Val Loss: 0.3173, Val Acc: 0.9600\n",
      "Fold 5, Epoch 13/20 - Train Loss: 0.3008, Train Acc: 0.9500 - Val Loss: 0.3334, Val Acc: 0.9200\n",
      "Fold 5, Epoch 14/20 - Train Loss: 0.3626, Train Acc: 0.9100 - Val Loss: 0.3393, Val Acc: 0.8800\n",
      "Fold 5, Epoch 15/20 - Train Loss: 0.3300, Train Acc: 0.9400 - Val Loss: 0.3294, Val Acc: 0.9200\n",
      "Fold 5, Epoch 16/20 - Train Loss: 0.3483, Train Acc: 0.9200 - Val Loss: 0.3462, Val Acc: 0.9200\n",
      "Fold 5, Epoch 17/20 - Train Loss: 0.3247, Train Acc: 0.9400 - Val Loss: 0.3421, Val Acc: 0.9200\n",
      "Fold 5, Epoch 18/20 - Train Loss: 0.3044, Train Acc: 0.9500 - Val Loss: 0.3426, Val Acc: 0.9200\n",
      "Fold 5, Epoch 19/20 - Train Loss: 0.2918, Train Acc: 0.9500 - Val Loss: 0.3399, Val Acc: 0.9200\n",
      "Fold 5, Epoch 20/20 - Train Loss: 0.2998, Train Acc: 0.9400 - Val Loss: 0.3483, Val Acc: 0.9200\n",
      "\n",
      "--- Fold 5 Confusion Matrix ---\n",
      "[[ 7  1]\n",
      " [ 1 16]]\n",
      "\n",
      "--- Fold 5 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.8750    0.8750         8\n",
      "           1     0.9412    0.9412    0.9412        17\n",
      "\n",
      "    accuracy                         0.9200        25\n",
      "   macro avg     0.9081    0.9081    0.9081        25\n",
      "weighted avg     0.9200    0.9200    0.9200        25\n",
      "\n",
      "['\\nFold Models:', ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']]\n",
      "['Fold Accuracies:', [0.88, 0.84, 0.96, 0.84, 0.96]]\n",
      "['Mean Accuracy:', np.float64(0.8959999999999999)]\n",
      "['Average Recalls:', {'0': np.float64(0.7861111111111111), '1': np.float64(0.9014705882352942)}]\n"
     ]
    }
   ],
   "source": [
    "kf_models_loose, accs_loose, recalls = run_kfold_training(\n",
    "    data_dir=loose_data_dir,\n",
    "    backbone='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    loss_fn=smooth,\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    num_epochs=20,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=2,\n",
    "    use_best_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a6e0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_accuracies['loose'] = 0.8959999999999999 #np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a58f6",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5de17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ensemble_to_onnx(kf_models_loose, accs_loose, output_path=\"loose_subtype_classification.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ce907",
   "metadata": {},
   "source": [
    "# Accuracy Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a9ccebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency Recalls: {'constipated': 0.5875, 'normal': 0.8474769914312917, 'loose': 0.776}\n",
      "Subtype Accuracies: {'constipated': 0.7830645161290324, 'normal': 0.7222997990056067, 'loose': 0.8959999999999999}\n",
      "Hierarchical Accuracy: 0.5983340290221093\n"
     ]
    }
   ],
   "source": [
    "print(\"Consistency Recalls:\", consistency_recalls)\n",
    "print(\"Subtype Accuracies:\", subtype_accuracies)\n",
    "\n",
    "hierarchical_accuracy = compute_hierarchical_accuracy(\n",
    "    consistency_recalls=consistency_recalls,\n",
    "    subtype_accuracies=subtype_accuracies\n",
    ")\n",
    "print(\"Hierarchical Accuracy:\", hierarchical_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01630b12",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4e76a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
