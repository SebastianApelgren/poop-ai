{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bc1ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62f7fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a97ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_confusion_matrix(cm):\n",
    "    \"\"\"Returns a string of a nicely formatted confusion matrix with indices and highlighted diagonal.\"\"\"\n",
    "    headers = [\"\"] + [f\"Pred {i}\" for i in range(len(cm[0]))]\n",
    "    table = []\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        formatted_row = []\n",
    "        for j, val in enumerate(row):\n",
    "            if i == j:\n",
    "                formatted_row.append(f\"*{val}*\")  # Highlight diagonal\n",
    "            else:\n",
    "                formatted_row.append(str(val))\n",
    "        table.append([f\"True {i}\"] + formatted_row)\n",
    "\n",
    "    return tabulate(table, headers=headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b14f9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = []\n",
    "\n",
    "def log_and_store(*msgs, table_format=False, is_confmat=False):\n",
    "    \"\"\"\n",
    "    Logs plain messages or pretty-prints confusion matrices or tables.\n",
    "    \"\"\"\n",
    "    if is_confmat and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = format_confusion_matrix(msgs[0])\n",
    "    elif table_format and len(msgs) == 1 and isinstance(msgs[0], list):\n",
    "        msg = tabulate(msgs[0], tablefmt=\"grid\")\n",
    "    else:\n",
    "        msg = \" \".join(str(m) for m in msgs)\n",
    "\n",
    "    print(msg)\n",
    "    all_logs.append(msg)\n",
    "\n",
    "def get_logs():\n",
    "    \"\"\"\n",
    "    Returnerar en lista med alla loggade meddelanden.\n",
    "    \"\"\"\n",
    "    return all_logs\n",
    "\n",
    "def clear_logs():\n",
    "    \"\"\"\n",
    "    Tömmer loggen.\n",
    "    \"\"\"\n",
    "    all_logs.clear()\n",
    "\n",
    "def save_logs_to_file(filename):\n",
    "    \"\"\"\n",
    "    Sparar loggade meddelanden till en fil.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for log in all_logs:\n",
    "            f.write(log + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79638fe9",
   "metadata": {},
   "source": [
    "# Advanced Training Pipeline\n",
    "\n",
    "This notebook implements:\n",
    "1. Stronger and more varied augmentation, including class-specific oversampling.\n",
    "2. Model-level adjustments: gradual unfreezing, EfficientNet-B0/B3, label smoothing, focal loss/class-weighted loss.\n",
    "3. Training strategies: early stopping, checkpoint ensembles, and k-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea9da62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../data-pools/data-consistence\"  # Update this path\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd323500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoolDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(class_path, fname), idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "481bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger and more varied augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # random crop + resize\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.RandomApply([transforms.Lambda(lambda img: img.filter(ImageFilter.FIND_EDGES))], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "340ab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing Loss (CrossEntropy with label_smoothing)\n",
    "criterion_smooth = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FocalLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f3691ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\\n    # Load pretrained EfficientNet\\n    if backbone == 'efficientnet_b0':\\n        model = models.efficientnet_b0(pretrained=True)\\n    elif backbone == 'efficientnet_b3':\\n        model = models.efficientnet_b3(pretrained=True)\\n    elif backbone == 'mobilenet_v2':\\n        model = models.mobilenet_v2(pretrained=True)\\n    elif backbone == 'mobilenet_v3_small':\\n        model = models.mobilenet_v3_small(pretrained=True)\\n    else:\\n        raise ValueError('Invalid backbone')\\n\\n    # Replace classifier head\\n    in_features = model.classifier[1].in_features\\n    model.classifier = nn.Sequential(\\n        nn.Linear(in_features, 512),\\n        nn.ReLU(inplace=True),\\n        nn.Dropout(0.4),\\n        nn.Linear(512, num_classes)\\n    )\\n\\n    # Freeze layers if specified\\n    if freeze_until_layer:\\n        for name, param in model.named_parameters():\\n            param.requires_grad = False\\n            if name.startswith(freeze_until_layer):\\n                break\\n        # Unfreeze subsequent layers\\n        unfreeze = False\\n        for name, param in model.named_parameters():\\n            if unfreeze:\\n                param.requires_grad = True\\n            if name.startswith(freeze_until_layer):\\n                unfreeze = True\\n\\n    return model.to(DEVICE)\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_model(backbone='efficientnet_b0', num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    # Load pretrained EfficientNet\n",
    "    if backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "    elif backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    # Replace classifier head\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Freeze layers if specified\n",
    "    if freeze_until_layer:\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                break\n",
    "        # Unfreeze subsequent layers\n",
    "        unfreeze = False\n",
    "        for name, param in model.named_parameters():\n",
    "            if unfreeze:\n",
    "                param.requires_grad = True\n",
    "            if name.startswith(freeze_until_layer):\n",
    "                unfreeze = True\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c33c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, num_classes=NUM_CLASSES, freeze_until_layer=None):\n",
    "    if backbone == 'mobilenet_v3_small':\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        # freeze layers\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        # Replace final classifier\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif backbone == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "        if freeze_until_layer:\n",
    "            for name, param in model.features.named_parameters():\n",
    "                param.requires_grad = False\n",
    "                if freeze_until_layer in name:\n",
    "                    break\n",
    "\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid backbone')\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb02600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return None, None, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84c606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx):\n",
    "\n",
    "    #patience = 3\n",
    "    #counter = 0\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3) # for accuracy\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) # for loss\n",
    "\n",
    "    best_acc     = 0.0\n",
    "    best_loss    = float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # ── One‐Cycle LR schedule ──────────────────────────────────────────────────\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=optimizer.param_groups[0]['lr'] * 10,  # e.g. 10× your base LR\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch = val_corrects / val_total\n",
    "        # step the one‐cycle scheduler each batch‐cycle (done at epoch‐end here)\n",
    "        scheduler.step()\n",
    "\n",
    "        # keep snapshot of best‐ever validation loss (for final restore)\n",
    "        if val_loss_epoch < best_loss:\n",
    "            best_loss    = val_loss_epoch\n",
    "            best_acc     = val_acc_epoch\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f\"Fold {fold_idx}, Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss_epoch:.4f}, Val Acc: {val_acc_epoch:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        #if val_acc_epoch > best_acc:\n",
    "        #    best_acc = val_acc_epoch\n",
    "        #   best_weights = model.state_dict().copy()\n",
    "        #   counter = 0\n",
    "        #else:\n",
    "        #    counter += 1\n",
    "        #    if counter >= patience:\n",
    "        #        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #       break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    # Final validation metrics\n",
    "    _, _, preds, labels = evaluate_model(model, val_loader)\n",
    "    log_and_store(\"\\nClassification Report for Fold {}:\".format(fold_idx))\n",
    "    log_and_store(classification_report(labels, preds, target_names=sorted(os.listdir(DATA_DIR))))\n",
    "\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a45e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../data-pools/data-consistence -name \".DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a1e6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() \n",
    "    else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cf9c6",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c234e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_training(\n",
    "    data_dir,\n",
    "    backbone='mobilenet_v2',\n",
    "    freeze_until_layer=None,\n",
    "    criterion_fn=None,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    k_folds=3,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "\n",
    "    # Class weights for full dataset (optional, for balance insights)\n",
    "    all_labels_full = [label for _, label in full_dataset]\n",
    "    class_counts = np.bincount(all_labels_full)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights_full = [class_weights[label] for label in all_labels_full]\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "    fold_models = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices), 1):\n",
    "        print(f\"\\n======= Fold {fold_idx} =======\")\n",
    "\n",
    "        # Subset + transforms\n",
    "        train_ds = torch.utils.data.Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "        val_ds   = torch.utils.data.Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "        # Weighted sampler\n",
    "        train_labels_fold = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "        class_sample_count_fold = np.array([train_labels_fold.count(i) for i in range(num_classes)])\n",
    "        class_weights_fold = 1.0 / class_sample_count_fold\n",
    "        sample_weights_fold = np.array([class_weights_fold[label] for label in train_labels_fold])\n",
    "        sample_weights_fold = torch.from_numpy(sample_weights_fold.astype(np.double))\n",
    "        sampler_fold = WeightedRandomSampler(sample_weights_fold, num_samples=len(sample_weights_fold), replacement=True)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler_fold)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(backbone=backbone, freeze_until_layer=freeze_until_layer)\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "        # Loss\n",
    "        criterion = criterion_fn if criterion_fn is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train\n",
    "        best_model, best_acc = train_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, fold_idx)\n",
    "        fold_models.append(best_model)\n",
    "        fold_accuracies.append(best_acc)\n",
    "\n",
    "        # Evaluate and log\n",
    "        best_model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                logits = best_model(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(yb.numpy())\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        crpt = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Confusion Matrix ---\")\n",
    "        log_and_store(cm, is_confmat=True)\n",
    "\n",
    "        log_and_store(f\"\\n--- Fold {fold_idx} Classification Report ---\")\n",
    "        log_and_store(crpt)\n",
    "\n",
    "    log_and_store([\"\\nFold Models:\", [f\"Fold {i+1}\" for i in range(len(fold_models))]])\n",
    "    log_and_store([\"Fold Accuracies:\", fold_accuracies])\n",
    "    log_and_store([\"Mean Accuracy:\", np.mean(fold_accuracies)])\n",
    "\n",
    "    return fold_models, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ae6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_split(\n",
    "    data_dir,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "):\n",
    "    print(\"======= Single Split Training =======\")\n",
    "\n",
    "    # Full dataset\n",
    "    full_dataset = StoolDataset(data_dir, transform=None)\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    all_labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Train/val split\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=val_split, random_state=seed, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Create datasets with transforms\n",
    "    train_ds = Subset(StoolDataset(data_dir, transform=train_transforms), train_idx)\n",
    "    val_ds = Subset(StoolDataset(data_dir, transform=val_transforms), val_idx)\n",
    "\n",
    "    # Weighted sampler for class imbalance\n",
    "    train_labels = [train_ds.dataset.samples[i][1] for i in train_idx]\n",
    "    class_sample_counts = np.array([train_labels.count(i) for i in range(NUM_CLASSES)])\n",
    "    print(f\"Class sample counts: {class_sample_counts}\")\n",
    "    class_weights = 1.0 / class_sample_counts\n",
    "    sample_weights = np.array([class_weights[label] for label in train_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights.astype(np.double))\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = create_model(backbone=model_name, freeze_until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    if criterion == 'focal':\n",
    "        loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    elif criterion == 'smooth':\n",
    "        loss_fn = criterion_smooth\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "    # Train\n",
    "    best_model, best_acc = train_validate(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, fold_idx=None)\n",
    "\n",
    "    # Evaluation\n",
    "    best_model.eval()\n",
    "    all_preds, all_labels_eval = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = best_model(xb).argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_eval.extend(yb.numpy())\n",
    "\n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels_eval, all_preds)\n",
    "    cr = classification_report(all_labels_eval, all_preds, digits=4)\n",
    "\n",
    "    log_and_store(\"--- Confusion Matrix ---\")\n",
    "    log_and_store(cm, is_confmat=True)\n",
    "    log_and_store(\"--- Classification Report ---\")\n",
    "    log_and_store(cr)\n",
    "\n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19280109",
   "metadata": {},
   "source": [
    "# Training ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b24a86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logs()  # Clear logs if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d5b2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "backbone = 'efficientnet_b3'  # or 'mobilenet_v2', 'mobilenet_v3_small', efficientnet_b3, efficientnet_b0.\n",
    "freeze_until = 'features.4'  # e.g., 'features.4'\n",
    "criterion = 'focal' # 'focal' or 'smooth'\n",
    "num_epochs = 20\n",
    "batch_size = 16 # This represents the batch size for training and validation which is the number of samples processed before the model is updated.\n",
    "lr = 1e-4  # Learning rate\n",
    "\n",
    "val_split = 0.2  # Fraction of data to use for validation\n",
    "\n",
    "k_folds = 3\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Fold 1 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/20 - Train Loss: 0.4738, Train Acc: 0.4096 - Val Loss: 0.4091, Val Acc: 0.6279\n"
     ]
    }
   ],
   "source": [
    "kf_models, accs = run_kfold_training(\n",
    "    data_dir=DATA_DIR,\n",
    "    backbone='efficientnet_b3',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until_layer=None,  # or 'features.4' for EfficientNet\n",
    "    criterion_fn=FocalLoss(alpha=1, gamma=2),\n",
    "    num_epochs=20,\n",
    "    lr=1e-4,\n",
    "    k_folds=5,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    num_classes=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4979a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [193 101 563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 0.4762, Train Acc: 0.4084 - Val Loss: 0.4256, Val Acc: 0.5535\n",
      "Fold None, Epoch 2/15 - Train Loss: 0.4344, Train Acc: 0.5298 - Val Loss: 0.3814, Val Acc: 0.6512\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.3852, Train Acc: 0.6418 - Val Loss: 0.3441, Val Acc: 0.6884\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.3381, Train Acc: 0.6814 - Val Loss: 0.2909, Val Acc: 0.7488\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.2997, Train Acc: 0.7328 - Val Loss: 0.2556, Val Acc: 0.7581\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.2405, Train Acc: 0.7946 - Val Loss: 0.2285, Val Acc: 0.7907\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.2205, Train Acc: 0.7900 - Val Loss: 0.2078, Val Acc: 0.7907\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.1921, Train Acc: 0.8051 - Val Loss: 0.1850, Val Acc: 0.8186\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.1798, Train Acc: 0.7993 - Val Loss: 0.1792, Val Acc: 0.7953\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.1559, Train Acc: 0.8413 - Val Loss: 0.1565, Val Acc: 0.8372\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.1524, Train Acc: 0.8343 - Val Loss: 0.1553, Val Acc: 0.8186\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.1151, Train Acc: 0.8880 - Val Loss: 0.1608, Val Acc: 0.8047\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.1092, Train Acc: 0.8845 - Val Loss: 0.1648, Val Acc: 0.8326\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.1046, Train Acc: 0.8856 - Val Loss: 0.1750, Val Acc: 0.8047\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.1023, Train Acc: 0.8973 - Val Loss: 0.1556, Val Acc: 0.8326\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated       0.60      0.79      0.68        48\n",
      "       loose       0.86      0.96      0.91        25\n",
      "      normal       0.92      0.80      0.86       142\n",
      "\n",
      "    accuracy                           0.82       215\n",
      "   macro avg       0.79      0.85      0.82       215\n",
      "weighted avg       0.84      0.82      0.82       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 38   0  10]\n",
      " [  1  24   0]\n",
      " [ 24   4 114]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6032    0.7917    0.6847        48\n",
      "           1     0.8571    0.9600    0.9057        25\n",
      "           2     0.9194    0.8028    0.8571       142\n",
      "\n",
      "    accuracy                         0.8186       215\n",
      "   macro avg     0.7932    0.8515    0.8158       215\n",
      "weighted avg     0.8415    0.8186    0.8243       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f386f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [193 101 563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/20 - Train Loss: 1.2543, Train Acc: 0.3302 - Val Loss: 1.1847, Val Acc: 0.3488\n",
      "Fold None, Epoch 2/20 - Train Loss: 0.9705, Train Acc: 0.4854 - Val Loss: 0.9228, Val Acc: 0.4837\n",
      "Fold None, Epoch 3/20 - Train Loss: 0.7362, Train Acc: 0.6009 - Val Loss: 0.6895, Val Acc: 0.6186\n",
      "Fold None, Epoch 4/20 - Train Loss: 0.5661, Train Acc: 0.6558 - Val Loss: 0.5317, Val Acc: 0.7581\n",
      "Fold None, Epoch 5/20 - Train Loss: 0.4494, Train Acc: 0.7165 - Val Loss: 0.4221, Val Acc: 0.7814\n",
      "Fold None, Epoch 6/20 - Train Loss: 0.3860, Train Acc: 0.7095 - Val Loss: 0.3271, Val Acc: 0.8140\n",
      "Fold None, Epoch 7/20 - Train Loss: 0.3130, Train Acc: 0.7538 - Val Loss: 0.2833, Val Acc: 0.8279\n",
      "Fold None, Epoch 8/20 - Train Loss: 0.2707, Train Acc: 0.7701 - Val Loss: 0.2488, Val Acc: 0.8326\n",
      "Fold None, Epoch 9/20 - Train Loss: 0.2357, Train Acc: 0.7853 - Val Loss: 0.2267, Val Acc: 0.8372\n",
      "Fold None, Epoch 10/20 - Train Loss: 0.1952, Train Acc: 0.8203 - Val Loss: 0.2037, Val Acc: 0.8419\n",
      "Fold None, Epoch 11/20 - Train Loss: 0.1707, Train Acc: 0.8448 - Val Loss: 0.2010, Val Acc: 0.8512\n",
      "Fold None, Epoch 12/20 - Train Loss: 0.1624, Train Acc: 0.8530 - Val Loss: 0.1890, Val Acc: 0.8558\n",
      "Fold None, Epoch 13/20 - Train Loss: 0.1357, Train Acc: 0.8506 - Val Loss: 0.1757, Val Acc: 0.8558\n",
      "Fold None, Epoch 14/20 - Train Loss: 0.1465, Train Acc: 0.8576 - Val Loss: 0.1707, Val Acc: 0.8605\n",
      "Fold None, Epoch 15/20 - Train Loss: 0.1032, Train Acc: 0.8950 - Val Loss: 0.1743, Val Acc: 0.8605\n",
      "Fold None, Epoch 16/20 - Train Loss: 0.1213, Train Acc: 0.8763 - Val Loss: 0.1707, Val Acc: 0.8419\n",
      "Fold None, Epoch 17/20 - Train Loss: 0.1124, Train Acc: 0.8821 - Val Loss: 0.1534, Val Acc: 0.8698\n",
      "Fold None, Epoch 18/20 - Train Loss: 0.1096, Train Acc: 0.8740 - Val Loss: 0.1737, Val Acc: 0.8279\n",
      "Fold None, Epoch 19/20 - Train Loss: 0.0871, Train Acc: 0.9020 - Val Loss: 0.1830, Val Acc: 0.8233\n",
      "Fold None, Epoch 20/20 - Train Loss: 0.0734, Train Acc: 0.9230 - Val Loss: 0.1739, Val Acc: 0.8465\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated       0.72      0.79      0.75        48\n",
      "       loose       0.89      0.96      0.92        25\n",
      "      normal       0.93      0.88      0.90       142\n",
      "\n",
      "    accuracy                           0.87       215\n",
      "   macro avg       0.84      0.88      0.86       215\n",
      "weighted avg       0.87      0.87      0.87       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 38   0  10]\n",
      " [  1  24   0]\n",
      " [ 14   3 125]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7170    0.7917    0.7525        48\n",
      "           1     0.8889    0.9600    0.9231        25\n",
      "           2     0.9259    0.8803    0.9025       142\n",
      "\n",
      "    accuracy                         0.8698       215\n",
      "   macro avg     0.8439    0.8773    0.8594       215\n",
      "weighted avg     0.8750    0.8698    0.8714       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b3',\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing. A higher layer means more layers are frozen.\n",
    "    criterion='focal', # 'focal' or 'smooth'\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    num_epochs=20,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [193 101 563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 0.6902, Train Acc: 0.5589 - Val Loss: 0.2752, Val Acc: 0.7535\n",
      "Fold None, Epoch 2/15 - Train Loss: 0.3249, Train Acc: 0.7083 - Val Loss: 0.2250, Val Acc: 0.7721\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.2449, Train Acc: 0.7678 - Val Loss: 0.2186, Val Acc: 0.7860\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.2068, Train Acc: 0.8098 - Val Loss: 0.2094, Val Acc: 0.7907\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.1809, Train Acc: 0.8285 - Val Loss: 0.1840, Val Acc: 0.7907\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.1778, Train Acc: 0.8261 - Val Loss: 0.1815, Val Acc: 0.8093\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.1428, Train Acc: 0.8565 - Val Loss: 0.1714, Val Acc: 0.8186\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.1227, Train Acc: 0.8740 - Val Loss: 0.1689, Val Acc: 0.8093\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.1434, Train Acc: 0.8681 - Val Loss: 0.1710, Val Acc: 0.8186\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.1127, Train Acc: 0.8740 - Val Loss: 0.1728, Val Acc: 0.8093\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.1214, Train Acc: 0.8763 - Val Loss: 0.1624, Val Acc: 0.8279\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.0987, Train Acc: 0.8786 - Val Loss: 0.1800, Val Acc: 0.8140\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.0871, Train Acc: 0.9090 - Val Loss: 0.1739, Val Acc: 0.8093\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.1054, Train Acc: 0.8915 - Val Loss: 0.2256, Val Acc: 0.8000\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.0961, Train Acc: 0.9008 - Val Loss: 0.1982, Val Acc: 0.8326\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated       0.62      0.83      0.71        48\n",
      "       loose       0.85      0.92      0.88        25\n",
      "      normal       0.93      0.81      0.87       142\n",
      "\n",
      "    accuracy                           0.83       215\n",
      "   macro avg       0.80      0.85      0.82       215\n",
      "weighted avg       0.85      0.83      0.83       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 40   0   8]\n",
      " [  2  23   0]\n",
      " [ 23   4 115]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6154    0.8333    0.7080        48\n",
      "           1     0.8519    0.9200    0.8846        25\n",
      "           2     0.9350    0.8099    0.8679       142\n",
      "\n",
      "    accuracy                         0.8279       215\n",
      "   macro avg     0.8007    0.8544    0.8202       215\n",
      "weighted avg     0.8539    0.8279    0.8342       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='mobilenet_v2',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e03cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Single Split Training =======\n",
      "Class sample counts: [193 101 563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sebastianapelgren/code/poop-ai/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold None, Epoch 1/15 - Train Loss: 1.2334, Train Acc: 0.3524 - Val Loss: 0.8817, Val Acc: 0.6419\n",
      "Fold None, Epoch 2/15 - Train Loss: 0.7641, Train Acc: 0.6336 - Val Loss: 0.5232, Val Acc: 0.6977\n",
      "Fold None, Epoch 3/15 - Train Loss: 0.4948, Train Acc: 0.7071 - Val Loss: 0.3415, Val Acc: 0.7349\n",
      "Fold None, Epoch 4/15 - Train Loss: 0.3505, Train Acc: 0.7316 - Val Loss: 0.2793, Val Acc: 0.7674\n",
      "Fold None, Epoch 5/15 - Train Loss: 0.2701, Train Acc: 0.7655 - Val Loss: 0.2319, Val Acc: 0.7860\n",
      "Fold None, Epoch 6/15 - Train Loss: 0.2427, Train Acc: 0.8016 - Val Loss: 0.2142, Val Acc: 0.7907\n",
      "Fold None, Epoch 7/15 - Train Loss: 0.2068, Train Acc: 0.8063 - Val Loss: 0.2036, Val Acc: 0.7907\n",
      "Fold None, Epoch 8/15 - Train Loss: 0.1941, Train Acc: 0.8226 - Val Loss: 0.1814, Val Acc: 0.8047\n",
      "Fold None, Epoch 9/15 - Train Loss: 0.1805, Train Acc: 0.8308 - Val Loss: 0.1893, Val Acc: 0.8140\n",
      "Fold None, Epoch 10/15 - Train Loss: 0.1739, Train Acc: 0.8273 - Val Loss: 0.1806, Val Acc: 0.7860\n",
      "Fold None, Epoch 11/15 - Train Loss: 0.1550, Train Acc: 0.8343 - Val Loss: 0.1615, Val Acc: 0.8233\n",
      "Fold None, Epoch 12/15 - Train Loss: 0.1446, Train Acc: 0.8448 - Val Loss: 0.1595, Val Acc: 0.8047\n",
      "Fold None, Epoch 13/15 - Train Loss: 0.1288, Train Acc: 0.8763 - Val Loss: 0.1748, Val Acc: 0.7953\n",
      "Fold None, Epoch 14/15 - Train Loss: 0.1273, Train Acc: 0.8611 - Val Loss: 0.1740, Val Acc: 0.7953\n",
      "Fold None, Epoch 15/15 - Train Loss: 0.1151, Train Acc: 0.8810 - Val Loss: 0.1667, Val Acc: 0.8000\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " constipated       0.62      0.73      0.67        48\n",
      "       loose       0.78      0.84      0.81        25\n",
      "      normal       0.89      0.82      0.85       142\n",
      "\n",
      "    accuracy                           0.80       215\n",
      "   macro avg       0.76      0.80      0.78       215\n",
      "weighted avg       0.82      0.80      0.81       215\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[ 35   0  13]\n",
      " [  2  21   2]\n",
      " [ 19   6 117]]\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6250    0.7292    0.6731        48\n",
      "           1     0.7778    0.8400    0.8077        25\n",
      "           2     0.8864    0.8239    0.8540       142\n",
      "\n",
      "    accuracy                         0.8047       215\n",
      "   macro avg     0.7630    0.7977    0.7783       215\n",
      "weighted avg     0.8154    0.8047    0.8082       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, best_acc = train_single_split(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_name='efficientnet_b0',  # or 'mobilenet_v3_small', 'efficientnet_b0', 'efficientnet_b3'\n",
    "    freeze_until=None,  # or 'features.4', None for no freezing\n",
    "    criterion='focal',  # or 'smooth'\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    num_epochs=15,\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4e3a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ALL LOGS ====\n",
      "\n",
      "Classification Report for Fold None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      type-1       0.72      0.72      0.72        25\n",
      "      type-2       0.55      0.72      0.62        25\n",
      "      type-3       0.53      0.49      0.51        65\n",
      "      type-4       0.72      0.64      0.68        61\n",
      "      type-5       0.50      0.83      0.62         6\n",
      "      type-6       0.60      0.60      0.60         5\n",
      "      type-7       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.63       202\n",
      "   macro avg       0.63      0.69      0.65       202\n",
      "weighted avg       0.64      0.63      0.63       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = get_logs()\n",
    "\n",
    "print(\"==== ALL LOGS ====\")\n",
    "for log in logs:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66e56a",
   "metadata": {},
   "source": [
    "# To load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "366e5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = models.efficientnet_b0()\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, NUM_CLASSES)\n",
    "    )\n",
    "    state_dict = torch.load(model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd415c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "\n",
    "# model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323635fe",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d8adc",
   "metadata": {},
   "source": [
    "### Save as .pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to stool_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. Define where to save\n",
    "SAVE_PATH = \"../api/stool_model.pth\"\n",
    "\n",
    "# 2. Save the state_dict\n",
    "#torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"Model weights saved to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd490f",
   "metadata": {},
   "source": [
    "### Save as .onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfcdfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX export completed: stool_model.onnx\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Create dummy input for ONNX export (batch_size=1, 3 channels, IMG_SIZE x IMG_SIZE)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,                               # your trained model\n",
    "    dummy_input,                         # input tensor\n",
    "    \"stool_model.onnx\",                  # output file name\n",
    "    export_params=True,                  # store weights inside the model file\n",
    "    opset_version=11,                    # ONNX opset version\n",
    "    do_constant_folding=True,            # fold constant values for optimization\n",
    "    input_names=['input'],               # name for the input layer\n",
    "    output_names=['output'],             # name for the output layer\n",
    "    dynamic_axes={                      # allow variable input sizes\n",
    "        'input': {0: 'batch_size'},     \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ ONNX export completed: stool_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
